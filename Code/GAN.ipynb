{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "579748a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e240e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeDataNearest(sliceData, meanvalue):\n",
    "    imputedata = []\n",
    "    for i in range(len(sliceData)):\n",
    "        a = np.array(sliceData[i])\n",
    "        b = pd.DataFrame(np.array(a))\n",
    "        b = b.replace(-1,np.nan)\n",
    "        c = b.count()\n",
    "        for k in range(a.shape[1]):\n",
    "            if c[k] == 0:\n",
    "                b[k] = meanvalue[k]\n",
    "            if c[k] == 1:\n",
    "                b[k] = b[k].interpolate(method ='ffill',axis=0)\n",
    "                b[k] = b[k].interpolate(method ='bfill',axis=0)\n",
    "        b = b.interpolate(method ='nearest',axis=0,limit_direction ='both')\n",
    "        b = b.interpolate(method ='ffill')\n",
    "        b = b.interpolate(method ='bfill')\n",
    "        b = b.values\n",
    "        imputedata.append(b)\n",
    "    return imputedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eaa5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('E:/WashU/Research/ICU/Data/train/X_train_sliced_norm.pkl','rb')\n",
    "X_train_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/y_train.pkl','rb')\n",
    "y_train = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_delta_mat.pkl','rb')\n",
    "train_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_mask_mat.pkl','rb')\n",
    "train_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/val/X_val_sliced_norm.pkl','rb')\n",
    "X_val_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/y_val.pkl','rb')\n",
    "y_val = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/val_delta_mat.pkl','rb')\n",
    "val_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/val_mask_mat.pkl','rb')\n",
    "val_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/test/X_test_sliced_norm.pkl','rb')\n",
    "X_test_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/test/y_test.pkl','rb')\n",
    "y_test = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/test/test_delta_mat.pkl','rb')\n",
    "test_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/test/test_mask_mat.pkl','rb')\n",
    "test_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/mean_norm.pkl','rb')\n",
    "mean = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4c262f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(imputeDataNearest(X_train_sliced, mean))\n",
    "X_val = np.array(imputeDataNearest(X_val_sliced, mean))\n",
    "train_delta_mat = np.array(train_delta_mat)\n",
    "val_delta_mat = np.array(val_delta_mat)\n",
    "train_mask_mat = np.array(train_mask_mat)\n",
    "val_mask_mat = np.array(val_mask_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb53cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUICell(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs):\n",
    "        super(GRUICell, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_outputs = num_outputs\n",
    "        def normal(shape):\n",
    "            return torch.randn(size=shape) * 0.0001\n",
    "        def three():\n",
    "            return (nn.Parameter(normal((num_inputs, num_hiddens))), \n",
    "                    nn.Parameter(normal((num_hiddens, num_hiddens))), \n",
    "                    nn.Parameter(torch.zeros(num_hiddens)))\n",
    "        self.W_xz, self.W_hz, self.b_z = three() # Parameters of update gate\n",
    "        self.W_xr, self.W_hr, self.b_r = three() # Parameters of reset gate\n",
    "        self.W_xh, self.W_hh, self.b_h = three() # Parameters of candidate hidden state\n",
    "        # Parameters of decay vector\n",
    "        self.W_beta = nn.Parameter(normal((num_inputs, num_hiddens)))\n",
    "        self.b_beta = nn.Parameter(torch.zeros(num_hiddens))\n",
    "        # Parameters of output layer\n",
    "        self.W_hq = nn.Parameter(normal((num_hiddens, num_outputs)))\n",
    "        self.b_q = nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "    def forward(self, X, Delta, H):\n",
    "        beta = torch.exp(torch.minimum(torch.zeros(self.num_hiddens), Delta @ self.W_beta + self.b_beta))\n",
    "        H = beta * H\n",
    "        Z = torch.sigmoid((X @ self.W_xz) + (H @ self.W_hz) + self.b_z)\n",
    "        R = torch.sigmoid((X @ self.W_xr) + (H @ self.W_hr) + self.b_r)\n",
    "        H_tilde = torch.tanh((X @ self.W_xh) + ((R * H) @ self.W_hh) + self.b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        H.detach()\n",
    "        Y = H @ self.W_hq + self.b_q\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13842571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUIModel(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs):\n",
    "        super(GRUIModel, self).__init__()\n",
    "        self.name = 'GRUI'\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.gruicell = GRUICell(num_inputs, num_hiddens, num_outputs)\n",
    "\n",
    "    def forward(self, X, Delta, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[1], self.num_hiddens)\n",
    "        Y = torch.tensor([])\n",
    "        for index in range(X.shape[0]):\n",
    "            Y_new, H = self.gruicell(X[index], Delta[index], H)\n",
    "            Y = torch.cat((Y, Y_new), dim = 0)\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "596cfe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainGenerator(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, drop_prob):\n",
    "        super(PretrainGenerator, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_outputs = num_outputs\n",
    "        self.grui_model = GRUIModel(num_inputs, num_hiddens, num_outputs)\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        def normal(shape):\n",
    "            return torch.randn(size=shape) * 0.0001\n",
    "        \n",
    "        # Parameters of fully connected layer\n",
    "        self.W_fc = nn.Parameter(normal((num_outputs, num_inputs)))\n",
    "        self.b_fc = nn.Parameter(torch.zeros(num_inputs))\n",
    "    \n",
    "    def forward(self, X, Delta, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[1], self.num_hiddens)\n",
    "        \n",
    "        outputs, final_state = self.grui_model(X, Delta, H)\n",
    "        outputs = outputs.view(X.shape[0], X.shape[1], self.num_outputs)\n",
    "        # Full connect\n",
    "        f_dropout = nn.Dropout(p = self.drop_prob)\n",
    "        imputed_result = torch.tensor([])\n",
    "        for i in range(outputs.shape[0]):\n",
    "            out_predict = f_dropout(outputs[i]) @ self.W_fc + self.b_fc\n",
    "            imputed_result = torch.cat((imputed_result, out_predict), dim = 0)\n",
    "        imputed_result = imputed_result.view(X.shape[0], X.shape[1], self.num_inputs)\n",
    "        \n",
    "        return imputed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8fe9c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, slice_gaps, z_dim, drop_prob):\n",
    "        super(Generator, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_outputs = num_outputs\n",
    "        self.grui_model = GRUIModel(num_inputs, num_hiddens, num_outputs)\n",
    "        self.slice_gaps = slice_gaps\n",
    "        self.time_steps = 2880//slice_gaps\n",
    "        self.z_dim = z_dim\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        def normal(shape):\n",
    "            return torch.randn(size=shape) * 0.0001\n",
    "        \n",
    "        # Parameters of random vector to X\n",
    "        self.W_rv2x = nn.Parameter(normal((z_dim, num_inputs)))\n",
    "        self.b_x = nn.Parameter(torch.zeros(num_inputs))\n",
    "        # Parameters of fully connected layer\n",
    "        self.W_fc = nn.Parameter(normal((num_outputs, num_inputs)))\n",
    "        self.b_fc = nn.Parameter(torch.zeros(num_inputs))\n",
    "    \n",
    "    def forward(self, rv, H, batch_size):\n",
    "        if rv is None:\n",
    "            rv = torch.randn((self.time_steps, batch_size, self.z_dim))\n",
    "        X = torch.tensor([])\n",
    "        for i in range(rv.shape[0]):\n",
    "            X = torch.cat((X, rv[i] @ self.W_rv2x + self.b_x), dim = 0)\n",
    "        X = X.view(self.time_steps, batch_size, self.num_inputs)\n",
    "        if H is None:\n",
    "            H = torch.zeros(batch_size, self.num_hiddens)\n",
    "        Delta = self.slice_gaps*torch.ones(self.time_steps, batch_size, self.num_inputs)\n",
    "        \n",
    "        outputs, final_state = self.grui_model(X, Delta, H)\n",
    "        outputs = outputs.view(self.time_steps, batch_size, self.num_outputs)\n",
    "        # Full connect\n",
    "        f_dropout = nn.Dropout(p = self.drop_prob)\n",
    "        imputed_result = torch.tensor([])\n",
    "        for i in range(outputs.shape[0]):\n",
    "            out_predict = f_dropout(outputs[i]) @ self.W_fc + self.b_fc\n",
    "            imputed_result = torch.cat((imputed_result, out_predict), dim = 0)\n",
    "        imputed_result = imputed_result.view(self.time_steps, batch_size, self.num_inputs)\n",
    "        \n",
    "        # batch_normalization???\n",
    "        \n",
    "        return imputed_result, Delta, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8f37b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, drop_prob):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_outputs = num_outputs\n",
    "        self.grui_model = GRUIModel(num_inputs, num_hiddens, num_outputs)\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        def normal(shape):\n",
    "            return torch.randn(size=shape) * 0.0001\n",
    "\n",
    "        # Parameters of fully connected layer\n",
    "        self.W_fc = nn.Parameter(normal((num_outputs, 1)))\n",
    "        self.b_fc = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, X, Delta, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[1], self.num_hiddens)\n",
    "        outputs, final_state = self.grui_model(X, Delta, H)\n",
    "        outputs = outputs.view(X.shape[0], X.shape[1], self.num_outputs)\n",
    "        # Full connect\n",
    "        f_dropout = nn.Dropout(p = self.drop_prob)\n",
    "        real_logits = f_dropout(final_state) @ self.W_fc + self.b_fc\n",
    "        real_probs = torch.sigmoid(real_logits)\n",
    "        \n",
    "        return real_probs, real_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c55415fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRLoss(nn.Module):\n",
    "    '''Masked Reconstruction Loss'''\n",
    "    def __init__(self):\n",
    "        super(MRLoss, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X, M, X_g):\n",
    "        mr_loss = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            mr_loss += torch.norm(X[i] * M[i] - X_g[i] * M[i])\n",
    "        mr_loss = mr_loss / X.shape[0]\n",
    "        return mr_loss\n",
    "\n",
    "class DLoss(nn.Module):\n",
    "    '''Discriminative Loss'''\n",
    "    def __init__(self):\n",
    "        super(DLoss, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, D_real_logits, D_fake_logits):\n",
    "        d_loss_real = - torch.mean(D_real_logits)\n",
    "        d_loss_fake = torch.mean(D_fake_logits)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        return d_loss\n",
    "\n",
    "class GLoss(nn.Module):\n",
    "    '''Loss for Generator'''\n",
    "    def __init__(self):\n",
    "        super(GLoss, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, D_fake_logits):\n",
    "        g_loss = - torch.mean(D_fake_logits)\n",
    "        return g_loss\n",
    "\n",
    "class ImpLoss(nn.Module):\n",
    "    '''Imputation Loss'''\n",
    "    def __init__(self, g_loss_lambda):\n",
    "        super(ImpLoss, self).__init__()\n",
    "        self.g_loss_lambda = g_loss_lambda\n",
    "    \n",
    "    def forward(self, X, M, X_imp, imputed_fake_logits):\n",
    "        imp_loss = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            imp_loss += torch.norm(X[i] * M[i] - X_imp[:,i,:] * M[i]) - self.g_loss_lambda * imputed_fake_logits[i]\n",
    "        imp_loss = imp_loss / X.shape[0]\n",
    "        return imp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ea0f16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y, z):\n",
    "    # Turn into numpy\n",
    "    if torch.is_tensor(x) == True:\n",
    "        x = x.numpy()\n",
    "    if torch.is_tensor(y) == True:\n",
    "        y = y.numpy()\n",
    "    if torch.is_tensor(z) == True:\n",
    "        z = z.numpy()\n",
    "    # Randomly exchange\n",
    "    for i in range(len(x)):\n",
    "        j = int(np.random.random() * (i + 1))\n",
    "        if j <= len(x)-1:\n",
    "            x[i], x[j] = x[j], x[i]\n",
    "            y[i], y[j] = y[j], y[i]\n",
    "            z[i], z[j] = z[j], z[i]\n",
    "\n",
    "    # Turn back to tensor\n",
    "    x = torch.from_numpy(x)\n",
    "    y = torch.from_numpy(y)\n",
    "    z = torch.from_numpy(z)\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "986ff0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "23737854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(model, X, M, Delta, batch_size, num_epoch, lr):\n",
    "    criterion = MRLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "    for epoch in range(num_epoch):\n",
    "        X, M, Delta = shuffle(X, M, Delta)\n",
    "        for step in range(X.shape[0] // batch_size + 1):\n",
    "            if (step + 1) * batch_size <= X_train.shape[0]:\n",
    "                X_batch = X[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "                M_batch = M[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "                Delta_batch = Delta[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "            else:\n",
    "                X_batch = X[int(step * batch_size):]\n",
    "                M_batch = M[int(step * batch_size):]\n",
    "                Delta_batch = Delta[int(step * batch_size):]\n",
    "            outputs = model(X_batch.transpose(0, 1), Delta_batch.transpose(0, 1), None)\n",
    "            X_batch_g = outputs.transpose(0, 1)\n",
    "            loss = criterion(X_batch, M_batch, X_batch_g)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(model, 0.99)\n",
    "            optimizer.step()\n",
    "            # display training status\n",
    "            print('Epoch: [%2d] [%4d/%4d] pretrain_loss: %.8f' % (epoch+1, step+1, X.shape[0] // batch_size + 1, loss))\n",
    "    return model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "59f54dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, M, Delta, batch_size, num_epoch, num_pretrain_epoch, lr, disc_iters):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pretrain_model = PretrainGenerator(X.shape[2], 64, 64, 0.5).to(device)\n",
    "    generator = Generator(X.shape[2], 64, 64, 60, 64, 0.5).to(device)\n",
    "    discriminator = Discriminator(X.shape[2], 64, 64, 0.5).to(device)\n",
    "    \n",
    "    X = torch.from_numpy(X).float()\n",
    "    M = torch.from_numpy(M).float()\n",
    "    Delta = torch.from_numpy(Delta).float()\n",
    "    \n",
    "    pretrained_dict = pretrain(pretrain_model, X, M, Delta, batch_size, num_pretrain_epoch, 0.1)\n",
    "    generator_dict = generator.state_dict()\n",
    "    generator_dict.update(pretrained_dict)\n",
    "    generator.load_state_dict(generator_dict)\n",
    "    \n",
    "    d_criterion = DLoss()\n",
    "    g_criterion = GLoss()\n",
    "    d_optimizer = torch.optim.SGD(discriminator.parameters(), lr)\n",
    "    g_optimizer = torch.optim.SGD(generator.parameters(), lr * disc_iters)\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    for epoch in range(num_pretrain_epoch + 1, num_epoch+1):\n",
    "        X, M, Delta = shuffle(X, M, Delta)\n",
    "        for step in range(X.shape[0] // batch_size + 1):\n",
    "            if (step + 1) * batch_size <= X_train.shape[0]:\n",
    "                X_batch = X[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "                M_batch = M[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "                Delta_batch = Delta[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "            else:\n",
    "                X_batch = X[int(step * batch_size):]\n",
    "                M_batch = M[int(step * batch_size):]\n",
    "                Delta_batch = Delta[int(step * batch_size):]\n",
    "            \n",
    "            # Update Discriminator Networks\n",
    "            outputs, delta, final_state = generator(None, None, batch_size)\n",
    "            d_real_probs, d_real_logits = discriminator(X_batch.transpose(0, 1), Delta_batch.transpose(0, 1), None)\n",
    "            d_fake_probs, d_fake_logits = discriminator(outputs, delta, None)\n",
    "            d_loss = d_criterion(d_real_logits, d_fake_logits)\n",
    "            d_optimizer.zero_grad()\n",
    "            d_loss.backward()\n",
    "            # grad_clipping(discriminator, 1)\n",
    "            d_optimizer.step()\n",
    "            print('Epoch: [%2d] [%4d/%4d] d_loss: %.8f, counter: %4d'% (epoch, step+1, X.shape[0] // batch_size + 1, d_loss, counter))\n",
    "            \n",
    "            # Update Generator Networks\n",
    "            if counter % disc_iters == 0:\n",
    "                outputs, delta, final_state = generator(None, None, batch_size)\n",
    "                d_real_probs, d_real_logits = discriminator(X_batch.transpose(0, 1), Delta_batch.transpose(0, 1), None)\n",
    "                d_fake_probs, d_fake_logits = discriminator(outputs, delta, None)\n",
    "                d_loss = d_criterion(d_real_logits, d_fake_logits)\n",
    "                g_loss = g_criterion(d_fake_logits)\n",
    "                g_optimizer.zero_grad()\n",
    "                g_loss.backward()\n",
    "                grad_clipping(generator, 0.99)\n",
    "                g_optimizer.step()\n",
    "                print('Epoch: [%2d] [%4d/%4d] d_loss: %.8f, g_loss: %.8f, counter: %4d'\\\n",
    "                      % (epoch, step+1, X.shape[0] // batch_size + 1, d_loss, g_loss, counter))\n",
    "            \n",
    "            counter += 1\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3adba48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [   1/  32] pretrain_loss: 10.99676418\n",
      "Epoch: [ 1] [   2/  32] pretrain_loss: 10.55497646\n",
      "Epoch: [ 1] [   3/  32] pretrain_loss: 9.92368317\n",
      "Epoch: [ 1] [   4/  32] pretrain_loss: 9.41481686\n",
      "Epoch: [ 1] [   5/  32] pretrain_loss: 9.02516747\n",
      "Epoch: [ 1] [   6/  32] pretrain_loss: 8.34884262\n",
      "Epoch: [ 1] [   7/  32] pretrain_loss: 8.20034218\n",
      "Epoch: [ 1] [   8/  32] pretrain_loss: 7.75395966\n",
      "Epoch: [ 1] [   9/  32] pretrain_loss: 7.22957993\n",
      "Epoch: [ 1] [  10/  32] pretrain_loss: 6.45806026\n",
      "Epoch: [ 1] [  11/  32] pretrain_loss: 6.42143250\n",
      "Epoch: [ 1] [  12/  32] pretrain_loss: 5.76822138\n",
      "Epoch: [ 1] [  13/  32] pretrain_loss: 6.08444691\n",
      "Epoch: [ 1] [  14/  32] pretrain_loss: 5.29279661\n",
      "Epoch: [ 1] [  15/  32] pretrain_loss: 5.23764181\n",
      "Epoch: [ 1] [  16/  32] pretrain_loss: 5.33481598\n",
      "Epoch: [ 1] [  17/  32] pretrain_loss: 4.21403503\n",
      "Epoch: [ 1] [  18/  32] pretrain_loss: 3.80733418\n",
      "Epoch: [ 1] [  19/  32] pretrain_loss: 4.47826529\n",
      "Epoch: [ 1] [  20/  32] pretrain_loss: 3.93325782\n",
      "Epoch: [ 1] [  21/  32] pretrain_loss: 3.38980246\n",
      "Epoch: [ 1] [  22/  32] pretrain_loss: 3.21390963\n",
      "Epoch: [ 1] [  23/  32] pretrain_loss: 3.70398545\n",
      "Epoch: [ 1] [  24/  32] pretrain_loss: 3.18447709\n",
      "Epoch: [ 1] [  25/  32] pretrain_loss: 3.35054064\n",
      "Epoch: [ 1] [  26/  32] pretrain_loss: 3.28468537\n",
      "Epoch: [ 1] [  27/  32] pretrain_loss: 2.75725460\n",
      "Epoch: [ 1] [  28/  32] pretrain_loss: 2.65644646\n",
      "Epoch: [ 1] [  29/  32] pretrain_loss: 2.83398676\n",
      "Epoch: [ 1] [  30/  32] pretrain_loss: 2.82355070\n",
      "Epoch: [ 1] [  31/  32] pretrain_loss: 2.45258689\n",
      "Epoch: [ 1] [  32/  32] pretrain_loss: 1.69124866\n",
      "Epoch: [ 2] [   1/  32] pretrain_loss: 8.79005527\n",
      "Epoch: [ 2] [   2/  32] pretrain_loss: 9.82811737\n",
      "Epoch: [ 2] [   3/  32] pretrain_loss: 8.35485840\n",
      "Epoch: [ 2] [   4/  32] pretrain_loss: 8.02482700\n",
      "Epoch: [ 2] [   5/  32] pretrain_loss: 7.67121220\n",
      "Epoch: [ 2] [   6/  32] pretrain_loss: 7.73588705\n",
      "Epoch: [ 2] [   7/  32] pretrain_loss: 7.79030418\n",
      "Epoch: [ 2] [   8/  32] pretrain_loss: 7.83151627\n",
      "Epoch: [ 2] [   9/  32] pretrain_loss: 7.58953333\n",
      "Epoch: [ 2] [  10/  32] pretrain_loss: 7.45873976\n",
      "Epoch: [ 2] [  11/  32] pretrain_loss: 7.10858393\n",
      "Epoch: [ 2] [  12/  32] pretrain_loss: 7.13598442\n",
      "Epoch: [ 2] [  13/  32] pretrain_loss: 6.81724548\n",
      "Epoch: [ 2] [  14/  32] pretrain_loss: 6.90319204\n",
      "Epoch: [ 2] [  15/  32] pretrain_loss: 6.66390896\n",
      "Epoch: [ 2] [  16/  32] pretrain_loss: 6.56446981\n",
      "Epoch: [ 2] [  17/  32] pretrain_loss: 6.49091816\n",
      "Epoch: [ 2] [  18/  32] pretrain_loss: 6.65720177\n",
      "Epoch: [ 2] [  19/  32] pretrain_loss: 6.36163616\n",
      "Epoch: [ 2] [  20/  32] pretrain_loss: 6.07429457\n",
      "Epoch: [ 2] [  21/  32] pretrain_loss: 5.85532379\n",
      "Epoch: [ 2] [  22/  32] pretrain_loss: 5.72773027\n",
      "Epoch: [ 2] [  23/  32] pretrain_loss: 5.90521955\n",
      "Epoch: [ 2] [  24/  32] pretrain_loss: 5.72477341\n",
      "Epoch: [ 2] [  25/  32] pretrain_loss: 5.94752932\n",
      "Epoch: [ 2] [  26/  32] pretrain_loss: 6.16862345\n",
      "Epoch: [ 2] [  27/  32] pretrain_loss: 5.89129972\n",
      "Epoch: [ 2] [  28/  32] pretrain_loss: 5.61006784\n",
      "Epoch: [ 2] [  29/  32] pretrain_loss: 5.30580902\n",
      "Epoch: [ 2] [  30/  32] pretrain_loss: 6.02657938\n",
      "Epoch: [ 2] [  31/  32] pretrain_loss: 5.42042017\n",
      "Epoch: [ 2] [  32/  32] pretrain_loss: 5.66898918\n",
      "Epoch: [ 3] [   1/  32] pretrain_loss: 4.61133003\n",
      "Epoch: [ 3] [   2/  32] pretrain_loss: 4.08849239\n",
      "Epoch: [ 3] [   3/  32] pretrain_loss: 3.64080715\n",
      "Epoch: [ 3] [   4/  32] pretrain_loss: 4.76819038\n",
      "Epoch: [ 3] [   5/  32] pretrain_loss: 4.51126480\n",
      "Epoch: [ 3] [   6/  32] pretrain_loss: 4.27039480\n",
      "Epoch: [ 3] [   7/  32] pretrain_loss: 3.84118032\n",
      "Epoch: [ 3] [   8/  32] pretrain_loss: 3.82612228\n",
      "Epoch: [ 3] [   9/  32] pretrain_loss: 4.48714399\n",
      "Epoch: [ 3] [  10/  32] pretrain_loss: 4.40212107\n",
      "Epoch: [ 3] [  11/  32] pretrain_loss: 4.10519552\n",
      "Epoch: [ 3] [  12/  32] pretrain_loss: 4.25673485\n",
      "Epoch: [ 3] [  13/  32] pretrain_loss: 5.31968737\n",
      "Epoch: [ 3] [  14/  32] pretrain_loss: 4.37856770\n",
      "Epoch: [ 3] [  15/  32] pretrain_loss: 3.75684905\n",
      "Epoch: [ 3] [  16/  32] pretrain_loss: 4.33316994\n",
      "Epoch: [ 3] [  17/  32] pretrain_loss: 4.41330433\n",
      "Epoch: [ 3] [  18/  32] pretrain_loss: 4.84108591\n",
      "Epoch: [ 3] [  19/  32] pretrain_loss: 4.82611084\n",
      "Epoch: [ 3] [  20/  32] pretrain_loss: 4.27065086\n",
      "Epoch: [ 3] [  21/  32] pretrain_loss: 4.10202885\n",
      "Epoch: [ 3] [  22/  32] pretrain_loss: 4.39061642\n",
      "Epoch: [ 3] [  23/  32] pretrain_loss: 3.90730619\n",
      "Epoch: [ 3] [  24/  32] pretrain_loss: 4.70207977\n",
      "Epoch: [ 3] [  25/  32] pretrain_loss: 4.18994427\n",
      "Epoch: [ 3] [  26/  32] pretrain_loss: 4.34719801\n",
      "Epoch: [ 3] [  27/  32] pretrain_loss: 4.47472286\n",
      "Epoch: [ 3] [  28/  32] pretrain_loss: 4.47438478\n",
      "Epoch: [ 3] [  29/  32] pretrain_loss: 4.87845278\n",
      "Epoch: [ 3] [  30/  32] pretrain_loss: 4.48400497\n",
      "Epoch: [ 3] [  31/  32] pretrain_loss: 4.33185530\n",
      "Epoch: [ 3] [  32/  32] pretrain_loss: 4.52486134\n",
      "Epoch: [ 4] [   1/  32] pretrain_loss: 5.46843910\n",
      "Epoch: [ 4] [   2/  32] pretrain_loss: 5.37124157\n",
      "Epoch: [ 4] [   3/  32] pretrain_loss: 4.78247166\n",
      "Epoch: [ 4] [   4/  32] pretrain_loss: 4.62284565\n",
      "Epoch: [ 4] [   5/  32] pretrain_loss: 5.39493895\n",
      "Epoch: [ 4] [   6/  32] pretrain_loss: 5.30527592\n",
      "Epoch: [ 4] [   7/  32] pretrain_loss: 4.77771759\n",
      "Epoch: [ 4] [   8/  32] pretrain_loss: 4.55289078\n",
      "Epoch: [ 4] [   9/  32] pretrain_loss: 5.25889635\n",
      "Epoch: [ 4] [  10/  32] pretrain_loss: 4.51428270\n",
      "Epoch: [ 4] [  11/  32] pretrain_loss: 4.98759651\n",
      "Epoch: [ 4] [  12/  32] pretrain_loss: 4.90255451\n",
      "Epoch: [ 4] [  13/  32] pretrain_loss: 5.58973742\n",
      "Epoch: [ 4] [  14/  32] pretrain_loss: 5.11819220\n",
      "Epoch: [ 4] [  15/  32] pretrain_loss: 4.56514883\n",
      "Epoch: [ 4] [  16/  32] pretrain_loss: 5.12311888\n",
      "Epoch: [ 4] [  17/  32] pretrain_loss: 5.03847599\n",
      "Epoch: [ 4] [  18/  32] pretrain_loss: 4.62924576\n",
      "Epoch: [ 4] [  19/  32] pretrain_loss: 4.55224419\n",
      "Epoch: [ 4] [  20/  32] pretrain_loss: 4.76349831\n",
      "Epoch: [ 4] [  21/  32] pretrain_loss: 5.17779875\n",
      "Epoch: [ 4] [  22/  32] pretrain_loss: 5.50517273\n",
      "Epoch: [ 4] [  23/  32] pretrain_loss: 4.98563910\n",
      "Epoch: [ 4] [  24/  32] pretrain_loss: 5.31167793\n",
      "Epoch: [ 4] [  25/  32] pretrain_loss: 4.77914667\n",
      "Epoch: [ 4] [  26/  32] pretrain_loss: 5.11294031\n",
      "Epoch: [ 4] [  27/  32] pretrain_loss: 5.37236357\n",
      "Epoch: [ 4] [  28/  32] pretrain_loss: 4.65196800\n",
      "Epoch: [ 4] [  29/  32] pretrain_loss: 5.05015850\n",
      "Epoch: [ 4] [  30/  32] pretrain_loss: 4.97023773\n",
      "Epoch: [ 4] [  31/  32] pretrain_loss: 4.96888161\n",
      "Epoch: [ 4] [  32/  32] pretrain_loss: 5.92957163\n",
      "Epoch: [ 5] [   1/  32] d_loss: 0.00000020, counter:    1\n",
      "Epoch: [ 5] [   2/  32] d_loss: 0.00000016, counter:    2\n",
      "Epoch: [ 5] [   3/  32] d_loss: 0.00000019, counter:    3\n",
      "Epoch: [ 5] [   4/  32] d_loss: 0.00000013, counter:    4\n",
      "Epoch: [ 5] [   5/  32] d_loss: 0.00000010, counter:    5\n",
      "Epoch: [ 5] [   6/  32] d_loss: 0.00000010, counter:    6\n",
      "Epoch: [ 5] [   7/  32] d_loss: 0.00000008, counter:    7\n",
      "Epoch: [ 5] [   8/  32] d_loss: 0.00000007, counter:    8\n",
      "Epoch: [ 5] [   8/  32] d_loss: 0.00000002, g_loss: -0.00000016, counter:    8\n",
      "Epoch: [ 5] [   9/  32] d_loss: 0.00000010, counter:    9\n",
      "Epoch: [ 5] [  10/  32] d_loss: 0.00000004, counter:   10\n",
      "Epoch: [ 5] [  11/  32] d_loss: 0.00000003, counter:   11\n",
      "Epoch: [ 5] [  12/  32] d_loss: -0.00000003, counter:   12\n",
      "Epoch: [ 5] [  13/  32] d_loss: 0.00000003, counter:   13\n",
      "Epoch: [ 5] [  14/  32] d_loss: -0.00000004, counter:   14\n",
      "Epoch: [ 5] [  15/  32] d_loss: -0.00000004, counter:   15\n",
      "Epoch: [ 5] [  16/  32] d_loss: -0.00000003, counter:   16\n",
      "Epoch: [ 5] [  16/  32] d_loss: -0.00000004, g_loss: -0.00000007, counter:   16\n",
      "Epoch: [ 5] [  17/  32] d_loss: -0.00000004, counter:   17\n",
      "Epoch: [ 5] [  18/  32] d_loss: -0.00000007, counter:   18\n",
      "Epoch: [ 5] [  19/  32] d_loss: -0.00000012, counter:   19\n",
      "Epoch: [ 5] [  20/  32] d_loss: -0.00000004, counter:   20\n",
      "Epoch: [ 5] [  21/  32] d_loss: -0.00000011, counter:   21\n",
      "Epoch: [ 5] [  22/  32] d_loss: -0.00000011, counter:   22\n",
      "Epoch: [ 5] [  23/  32] d_loss: -0.00000010, counter:   23\n",
      "Epoch: [ 5] [  24/  32] d_loss: -0.00000011, counter:   24\n",
      "Epoch: [ 5] [  24/  32] d_loss: -0.00000014, g_loss: 0.00000011, counter:   24\n",
      "Epoch: [ 5] [  25/  32] d_loss: -0.00000014, counter:   25\n",
      "Epoch: [ 5] [  26/  32] d_loss: -0.00000017, counter:   26\n",
      "Epoch: [ 5] [  27/  32] d_loss: -0.00000014, counter:   27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 5] [  28/  32] d_loss: -0.00000018, counter:   28\n",
      "Epoch: [ 5] [  29/  32] d_loss: -0.00000020, counter:   29\n",
      "Epoch: [ 5] [  30/  32] d_loss: -0.00000016, counter:   30\n",
      "Epoch: [ 5] [  31/  32] d_loss: -0.00000022, counter:   31\n",
      "Epoch: [ 5] [  32/  32] d_loss: -0.00000025, counter:   32\n",
      "Epoch: [ 5] [  32/  32] d_loss: -0.00000022, g_loss: 0.00000021, counter:   32\n",
      "Epoch: [ 6] [   1/  32] d_loss: -0.00000029, counter:   33\n",
      "Epoch: [ 6] [   2/  32] d_loss: -0.00000024, counter:   34\n",
      "Epoch: [ 6] [   3/  32] d_loss: -0.00000029, counter:   35\n",
      "Epoch: [ 6] [   4/  32] d_loss: -0.00000029, counter:   36\n",
      "Epoch: [ 6] [   5/  32] d_loss: -0.00000028, counter:   37\n",
      "Epoch: [ 6] [   6/  32] d_loss: -0.00000030, counter:   38\n",
      "Epoch: [ 6] [   7/  32] d_loss: -0.00000033, counter:   39\n",
      "Epoch: [ 6] [   8/  32] d_loss: -0.00000036, counter:   40\n",
      "Epoch: [ 6] [   8/  32] d_loss: -0.00000034, g_loss: 0.00000035, counter:   40\n",
      "Epoch: [ 6] [   9/  32] d_loss: -0.00000039, counter:   41\n",
      "Epoch: [ 6] [  10/  32] d_loss: -0.00000040, counter:   42\n",
      "Epoch: [ 6] [  11/  32] d_loss: -0.00000036, counter:   43\n",
      "Epoch: [ 6] [  12/  32] d_loss: -0.00000040, counter:   44\n",
      "Epoch: [ 6] [  13/  32] d_loss: -0.00000038, counter:   45\n",
      "Epoch: [ 6] [  14/  32] d_loss: -0.00000042, counter:   46\n",
      "Epoch: [ 6] [  15/  32] d_loss: -0.00000043, counter:   47\n",
      "Epoch: [ 6] [  16/  32] d_loss: -0.00000048, counter:   48\n",
      "Epoch: [ 6] [  16/  32] d_loss: -0.00000050, g_loss: 0.00000052, counter:   48\n",
      "Epoch: [ 6] [  17/  32] d_loss: -0.00000047, counter:   49\n",
      "Epoch: [ 6] [  18/  32] d_loss: -0.00000052, counter:   50\n",
      "Epoch: [ 6] [  19/  32] d_loss: -0.00000052, counter:   51\n",
      "Epoch: [ 6] [  20/  32] d_loss: -0.00000052, counter:   52\n",
      "Epoch: [ 6] [  21/  32] d_loss: -0.00000051, counter:   53\n",
      "Epoch: [ 6] [  22/  32] d_loss: -0.00000052, counter:   54\n",
      "Epoch: [ 6] [  23/  32] d_loss: -0.00000060, counter:   55\n",
      "Epoch: [ 6] [  24/  32] d_loss: -0.00000056, counter:   56\n",
      "Epoch: [ 6] [  24/  32] d_loss: -0.00000060, g_loss: 0.00000068, counter:   56\n",
      "Epoch: [ 6] [  25/  32] d_loss: -0.00000062, counter:   57\n",
      "Epoch: [ 6] [  26/  32] d_loss: -0.00000064, counter:   58\n",
      "Epoch: [ 6] [  27/  32] d_loss: -0.00000063, counter:   59\n",
      "Epoch: [ 6] [  28/  32] d_loss: -0.00000062, counter:   60\n",
      "Epoch: [ 6] [  29/  32] d_loss: -0.00000072, counter:   61\n",
      "Epoch: [ 6] [  30/  32] d_loss: -0.00000067, counter:   62\n",
      "Epoch: [ 6] [  31/  32] d_loss: -0.00000073, counter:   63\n",
      "Epoch: [ 6] [  32/  32] d_loss: -0.00000064, counter:   64\n",
      "Epoch: [ 6] [  32/  32] d_loss: -0.00000077, g_loss: 0.00000086, counter:   64\n",
      "Epoch: [ 7] [   1/  32] d_loss: -0.00000074, counter:   65\n",
      "Epoch: [ 7] [   2/  32] d_loss: -0.00000078, counter:   66\n",
      "Epoch: [ 7] [   3/  32] d_loss: -0.00000073, counter:   67\n",
      "Epoch: [ 7] [   4/  32] d_loss: -0.00000084, counter:   68\n",
      "Epoch: [ 7] [   5/  32] d_loss: -0.00000084, counter:   69\n",
      "Epoch: [ 7] [   6/  32] d_loss: -0.00000086, counter:   70\n",
      "Epoch: [ 7] [   7/  32] d_loss: -0.00000085, counter:   71\n",
      "Epoch: [ 7] [   8/  32] d_loss: -0.00000082, counter:   72\n",
      "Epoch: [ 7] [   8/  32] d_loss: -0.00000085, g_loss: 0.00000106, counter:   72\n",
      "Epoch: [ 7] [   9/  32] d_loss: -0.00000093, counter:   73\n",
      "Epoch: [ 7] [  10/  32] d_loss: -0.00000095, counter:   74\n",
      "Epoch: [ 7] [  11/  32] d_loss: -0.00000100, counter:   75\n",
      "Epoch: [ 7] [  12/  32] d_loss: -0.00000101, counter:   76\n",
      "Epoch: [ 7] [  13/  32] d_loss: -0.00000097, counter:   77\n",
      "Epoch: [ 7] [  14/  32] d_loss: -0.00000110, counter:   78\n",
      "Epoch: [ 7] [  15/  32] d_loss: -0.00000109, counter:   79\n",
      "Epoch: [ 7] [  16/  32] d_loss: -0.00000108, counter:   80\n",
      "Epoch: [ 7] [  16/  32] d_loss: -0.00000102, g_loss: 0.00000133, counter:   80\n",
      "Epoch: [ 7] [  17/  32] d_loss: -0.00000108, counter:   81\n",
      "Epoch: [ 7] [  18/  32] d_loss: -0.00000112, counter:   82\n",
      "Epoch: [ 7] [  19/  32] d_loss: -0.00000121, counter:   83\n",
      "Epoch: [ 7] [  20/  32] d_loss: -0.00000122, counter:   84\n",
      "Epoch: [ 7] [  21/  32] d_loss: -0.00000130, counter:   85\n",
      "Epoch: [ 7] [  22/  32] d_loss: -0.00000128, counter:   86\n",
      "Epoch: [ 7] [  23/  32] d_loss: -0.00000126, counter:   87\n",
      "Epoch: [ 7] [  24/  32] d_loss: -0.00000143, counter:   88\n",
      "Epoch: [ 7] [  24/  32] d_loss: -0.00000134, g_loss: 0.00000164, counter:   88\n",
      "Epoch: [ 7] [  25/  32] d_loss: -0.00000143, counter:   89\n",
      "Epoch: [ 7] [  26/  32] d_loss: -0.00000146, counter:   90\n",
      "Epoch: [ 7] [  27/  32] d_loss: -0.00000142, counter:   91\n",
      "Epoch: [ 7] [  28/  32] d_loss: -0.00000141, counter:   92\n",
      "Epoch: [ 7] [  29/  32] d_loss: -0.00000145, counter:   93\n",
      "Epoch: [ 7] [  30/  32] d_loss: -0.00000151, counter:   94\n",
      "Epoch: [ 7] [  31/  32] d_loss: -0.00000161, counter:   95\n",
      "Epoch: [ 7] [  32/  32] d_loss: -0.00000168, counter:   96\n",
      "Epoch: [ 7] [  32/  32] d_loss: -0.00000154, g_loss: 0.00000216, counter:   96\n",
      "Epoch: [ 8] [   1/  32] d_loss: -0.00000167, counter:   97\n",
      "Epoch: [ 8] [   2/  32] d_loss: -0.00000175, counter:   98\n",
      "Epoch: [ 8] [   3/  32] d_loss: -0.00000165, counter:   99\n",
      "Epoch: [ 8] [   4/  32] d_loss: -0.00000181, counter:  100\n",
      "Epoch: [ 8] [   5/  32] d_loss: -0.00000174, counter:  101\n",
      "Epoch: [ 8] [   6/  32] d_loss: -0.00000193, counter:  102\n",
      "Epoch: [ 8] [   7/  32] d_loss: -0.00000202, counter:  103\n",
      "Epoch: [ 8] [   8/  32] d_loss: -0.00000191, counter:  104\n",
      "Epoch: [ 8] [   8/  32] d_loss: -0.00000218, g_loss: 0.00000280, counter:  104\n",
      "Epoch: [ 8] [   9/  32] d_loss: -0.00000207, counter:  105\n",
      "Epoch: [ 8] [  10/  32] d_loss: -0.00000199, counter:  106\n",
      "Epoch: [ 8] [  11/  32] d_loss: -0.00000201, counter:  107\n",
      "Epoch: [ 8] [  12/  32] d_loss: -0.00000219, counter:  108\n",
      "Epoch: [ 8] [  13/  32] d_loss: -0.00000218, counter:  109\n",
      "Epoch: [ 8] [  14/  32] d_loss: -0.00000247, counter:  110\n",
      "Epoch: [ 8] [  15/  32] d_loss: -0.00000226, counter:  111\n",
      "Epoch: [ 8] [  16/  32] d_loss: -0.00000236, counter:  112\n",
      "Epoch: [ 8] [  16/  32] d_loss: -0.00000265, g_loss: 0.00000340, counter:  112\n",
      "Epoch: [ 8] [  17/  32] d_loss: -0.00000250, counter:  113\n",
      "Epoch: [ 8] [  18/  32] d_loss: -0.00000251, counter:  114\n",
      "Epoch: [ 8] [  19/  32] d_loss: -0.00000267, counter:  115\n",
      "Epoch: [ 8] [  20/  32] d_loss: -0.00000253, counter:  116\n",
      "Epoch: [ 8] [  21/  32] d_loss: -0.00000292, counter:  117\n",
      "Epoch: [ 8] [  22/  32] d_loss: -0.00000283, counter:  118\n",
      "Epoch: [ 8] [  23/  32] d_loss: -0.00000264, counter:  119\n",
      "Epoch: [ 8] [  24/  32] d_loss: -0.00000287, counter:  120\n",
      "Epoch: [ 8] [  24/  32] d_loss: -0.00000300, g_loss: 0.00000410, counter:  120\n",
      "Epoch: [ 8] [  25/  32] d_loss: -0.00000290, counter:  121\n",
      "Epoch: [ 8] [  26/  32] d_loss: -0.00000305, counter:  122\n",
      "Epoch: [ 8] [  27/  32] d_loss: -0.00000273, counter:  123\n",
      "Epoch: [ 8] [  28/  32] d_loss: -0.00000341, counter:  124\n",
      "Epoch: [ 8] [  29/  32] d_loss: -0.00000327, counter:  125\n",
      "Epoch: [ 8] [  30/  32] d_loss: -0.00000331, counter:  126\n",
      "Epoch: [ 8] [  31/  32] d_loss: -0.00000336, counter:  127\n",
      "Epoch: [ 8] [  32/  32] d_loss: -0.00000344, counter:  128\n",
      "Epoch: [ 8] [  32/  32] d_loss: -0.00000387, g_loss: 0.00000520, counter:  128\n",
      "Epoch: [ 9] [   1/  32] d_loss: -0.00000366, counter:  129\n",
      "Epoch: [ 9] [   2/  32] d_loss: -0.00000375, counter:  130\n",
      "Epoch: [ 9] [   3/  32] d_loss: -0.00000395, counter:  131\n",
      "Epoch: [ 9] [   4/  32] d_loss: -0.00000372, counter:  132\n",
      "Epoch: [ 9] [   5/  32] d_loss: -0.00000408, counter:  133\n",
      "Epoch: [ 9] [   6/  32] d_loss: -0.00000368, counter:  134\n",
      "Epoch: [ 9] [   7/  32] d_loss: -0.00000445, counter:  135\n",
      "Epoch: [ 9] [   8/  32] d_loss: -0.00000464, counter:  136\n",
      "Epoch: [ 9] [   8/  32] d_loss: -0.00000451, g_loss: 0.00000652, counter:  136\n",
      "Epoch: [ 9] [   9/  32] d_loss: -0.00000463, counter:  137\n",
      "Epoch: [ 9] [  10/  32] d_loss: -0.00000483, counter:  138\n",
      "Epoch: [ 9] [  11/  32] d_loss: -0.00000429, counter:  139\n",
      "Epoch: [ 9] [  12/  32] d_loss: -0.00000442, counter:  140\n",
      "Epoch: [ 9] [  13/  32] d_loss: -0.00000460, counter:  141\n",
      "Epoch: [ 9] [  14/  32] d_loss: -0.00000484, counter:  142\n",
      "Epoch: [ 9] [  15/  32] d_loss: -0.00000503, counter:  143\n",
      "Epoch: [ 9] [  16/  32] d_loss: -0.00000529, counter:  144\n",
      "Epoch: [ 9] [  16/  32] d_loss: -0.00000568, g_loss: 0.00000797, counter:  144\n",
      "Epoch: [ 9] [  17/  32] d_loss: -0.00000528, counter:  145\n",
      "Epoch: [ 9] [  18/  32] d_loss: -0.00000526, counter:  146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 9] [  19/  32] d_loss: -0.00000591, counter:  147\n",
      "Epoch: [ 9] [  20/  32] d_loss: -0.00000609, counter:  148\n",
      "Epoch: [ 9] [  21/  32] d_loss: -0.00000594, counter:  149\n",
      "Epoch: [ 9] [  22/  32] d_loss: -0.00000648, counter:  150\n",
      "Epoch: [ 9] [  23/  32] d_loss: -0.00000626, counter:  151\n",
      "Epoch: [ 9] [  24/  32] d_loss: -0.00000698, counter:  152\n",
      "Epoch: [ 9] [  24/  32] d_loss: -0.00000636, g_loss: 0.00000978, counter:  152\n",
      "Epoch: [ 9] [  25/  32] d_loss: -0.00000692, counter:  153\n",
      "Epoch: [ 9] [  26/  32] d_loss: -0.00000668, counter:  154\n",
      "Epoch: [ 9] [  27/  32] d_loss: -0.00000725, counter:  155\n",
      "Epoch: [ 9] [  28/  32] d_loss: -0.00000756, counter:  156\n",
      "Epoch: [ 9] [  29/  32] d_loss: -0.00000755, counter:  157\n",
      "Epoch: [ 9] [  30/  32] d_loss: -0.00000794, counter:  158\n",
      "Epoch: [ 9] [  31/  32] d_loss: -0.00000827, counter:  159\n",
      "Epoch: [ 9] [  32/  32] d_loss: -0.00000818, counter:  160\n",
      "Epoch: [ 9] [  32/  32] d_loss: -0.00000787, g_loss: 0.00001196, counter:  160\n",
      "Epoch: [10] [   1/  32] d_loss: -0.00000745, counter:  161\n",
      "Epoch: [10] [   2/  32] d_loss: -0.00000884, counter:  162\n",
      "Epoch: [10] [   3/  32] d_loss: -0.00000891, counter:  163\n",
      "Epoch: [10] [   4/  32] d_loss: -0.00000907, counter:  164\n",
      "Epoch: [10] [   5/  32] d_loss: -0.00000907, counter:  165\n",
      "Epoch: [10] [   6/  32] d_loss: -0.00000975, counter:  166\n",
      "Epoch: [10] [   7/  32] d_loss: -0.00000927, counter:  167\n",
      "Epoch: [10] [   8/  32] d_loss: -0.00001020, counter:  168\n",
      "Epoch: [10] [   8/  32] d_loss: -0.00000944, g_loss: 0.00001516, counter:  168\n",
      "Epoch: [10] [   9/  32] d_loss: -0.00001020, counter:  169\n",
      "Epoch: [10] [  10/  32] d_loss: -0.00000983, counter:  170\n",
      "Epoch: [10] [  11/  32] d_loss: -0.00001095, counter:  171\n",
      "Epoch: [10] [  12/  32] d_loss: -0.00001059, counter:  172\n",
      "Epoch: [10] [  13/  32] d_loss: -0.00001179, counter:  173\n",
      "Epoch: [10] [  14/  32] d_loss: -0.00001277, counter:  174\n",
      "Epoch: [10] [  15/  32] d_loss: -0.00001190, counter:  175\n",
      "Epoch: [10] [  16/  32] d_loss: -0.00001350, counter:  176\n",
      "Epoch: [10] [  16/  32] d_loss: -0.00001344, g_loss: 0.00002006, counter:  176\n",
      "Epoch: [10] [  17/  32] d_loss: -0.00001220, counter:  177\n",
      "Epoch: [10] [  18/  32] d_loss: -0.00001475, counter:  178\n",
      "Epoch: [10] [  19/  32] d_loss: -0.00001333, counter:  179\n",
      "Epoch: [10] [  20/  32] d_loss: -0.00001393, counter:  180\n",
      "Epoch: [10] [  21/  32] d_loss: -0.00001499, counter:  181\n",
      "Epoch: [10] [  22/  32] d_loss: -0.00001598, counter:  182\n",
      "Epoch: [10] [  23/  32] d_loss: -0.00001463, counter:  183\n",
      "Epoch: [10] [  24/  32] d_loss: -0.00001531, counter:  184\n",
      "Epoch: [10] [  24/  32] d_loss: -0.00001736, g_loss: 0.00002605, counter:  184\n",
      "Epoch: [10] [  25/  32] d_loss: -0.00001591, counter:  185\n",
      "Epoch: [10] [  26/  32] d_loss: -0.00001688, counter:  186\n",
      "Epoch: [10] [  27/  32] d_loss: -0.00001626, counter:  187\n",
      "Epoch: [10] [  28/  32] d_loss: -0.00001776, counter:  188\n",
      "Epoch: [10] [  29/  32] d_loss: -0.00001773, counter:  189\n",
      "Epoch: [10] [  30/  32] d_loss: -0.00001879, counter:  190\n",
      "Epoch: [10] [  31/  32] d_loss: -0.00001865, counter:  191\n",
      "Epoch: [10] [  32/  32] d_loss: -0.00002223, counter:  192\n",
      "Epoch: [10] [  32/  32] d_loss: -0.00002131, g_loss: 0.00003126, counter:  192\n",
      "Epoch: [11] [   1/  32] d_loss: -0.00002100, counter:  193\n",
      "Epoch: [11] [   2/  32] d_loss: -0.00002215, counter:  194\n",
      "Epoch: [11] [   3/  32] d_loss: -0.00002027, counter:  195\n",
      "Epoch: [11] [   4/  32] d_loss: -0.00002292, counter:  196\n",
      "Epoch: [11] [   5/  32] d_loss: -0.00002423, counter:  197\n",
      "Epoch: [11] [   6/  32] d_loss: -0.00002437, counter:  198\n",
      "Epoch: [11] [   7/  32] d_loss: -0.00002622, counter:  199\n",
      "Epoch: [11] [   8/  32] d_loss: -0.00002566, counter:  200\n",
      "Epoch: [11] [   8/  32] d_loss: -0.00002760, g_loss: 0.00004244, counter:  200\n",
      "Epoch: [11] [   9/  32] d_loss: -0.00002498, counter:  201\n",
      "Epoch: [11] [  10/  32] d_loss: -0.00002783, counter:  202\n",
      "Epoch: [11] [  11/  32] d_loss: -0.00002722, counter:  203\n",
      "Epoch: [11] [  12/  32] d_loss: -0.00003064, counter:  204\n",
      "Epoch: [11] [  13/  32] d_loss: -0.00003053, counter:  205\n",
      "Epoch: [11] [  14/  32] d_loss: -0.00002875, counter:  206\n",
      "Epoch: [11] [  15/  32] d_loss: -0.00003170, counter:  207\n",
      "Epoch: [11] [  16/  32] d_loss: -0.00003131, counter:  208\n",
      "Epoch: [11] [  16/  32] d_loss: -0.00003247, g_loss: 0.00005326, counter:  208\n",
      "Epoch: [11] [  17/  32] d_loss: -0.00003335, counter:  209\n",
      "Epoch: [11] [  18/  32] d_loss: -0.00003341, counter:  210\n",
      "Epoch: [11] [  19/  32] d_loss: -0.00003708, counter:  211\n",
      "Epoch: [11] [  20/  32] d_loss: -0.00003566, counter:  212\n",
      "Epoch: [11] [  21/  32] d_loss: -0.00003877, counter:  213\n",
      "Epoch: [11] [  22/  32] d_loss: -0.00003586, counter:  214\n",
      "Epoch: [11] [  23/  32] d_loss: -0.00003709, counter:  215\n",
      "Epoch: [11] [  24/  32] d_loss: -0.00004242, counter:  216\n",
      "Epoch: [11] [  24/  32] d_loss: -0.00004555, g_loss: 0.00007087, counter:  216\n",
      "Epoch: [11] [  25/  32] d_loss: -0.00003915, counter:  217\n",
      "Epoch: [11] [  26/  32] d_loss: -0.00004436, counter:  218\n",
      "Epoch: [11] [  27/  32] d_loss: -0.00004471, counter:  219\n",
      "Epoch: [11] [  28/  32] d_loss: -0.00004814, counter:  220\n",
      "Epoch: [11] [  29/  32] d_loss: -0.00004458, counter:  221\n",
      "Epoch: [11] [  30/  32] d_loss: -0.00004772, counter:  222\n",
      "Epoch: [11] [  31/  32] d_loss: -0.00004682, counter:  223\n",
      "Epoch: [11] [  32/  32] d_loss: -0.00004880, counter:  224\n",
      "Epoch: [11] [  32/  32] d_loss: -0.00004950, g_loss: 0.00008503, counter:  224\n",
      "Epoch: [12] [   1/  32] d_loss: -0.00005193, counter:  225\n",
      "Epoch: [12] [   2/  32] d_loss: -0.00005212, counter:  226\n",
      "Epoch: [12] [   3/  32] d_loss: -0.00005729, counter:  227\n",
      "Epoch: [12] [   4/  32] d_loss: -0.00005626, counter:  228\n",
      "Epoch: [12] [   5/  32] d_loss: -0.00006146, counter:  229\n",
      "Epoch: [12] [   6/  32] d_loss: -0.00006959, counter:  230\n",
      "Epoch: [12] [   7/  32] d_loss: -0.00006504, counter:  231\n",
      "Epoch: [12] [   8/  32] d_loss: -0.00006819, counter:  232\n",
      "Epoch: [12] [   8/  32] d_loss: -0.00007224, g_loss: 0.00011506, counter:  232\n",
      "Epoch: [12] [   9/  32] d_loss: -0.00006632, counter:  233\n",
      "Epoch: [12] [  10/  32] d_loss: -0.00006562, counter:  234\n",
      "Epoch: [12] [  11/  32] d_loss: -0.00007044, counter:  235\n",
      "Epoch: [12] [  12/  32] d_loss: -0.00007648, counter:  236\n",
      "Epoch: [12] [  13/  32] d_loss: -0.00008254, counter:  237\n",
      "Epoch: [12] [  14/  32] d_loss: -0.00008401, counter:  238\n",
      "Epoch: [12] [  15/  32] d_loss: -0.00008133, counter:  239\n",
      "Epoch: [12] [  16/  32] d_loss: -0.00008468, counter:  240\n",
      "Epoch: [12] [  16/  32] d_loss: -0.00008699, g_loss: 0.00014472, counter:  240\n",
      "Epoch: [12] [  17/  32] d_loss: -0.00008701, counter:  241\n",
      "Epoch: [12] [  18/  32] d_loss: -0.00008787, counter:  242\n",
      "Epoch: [12] [  19/  32] d_loss: -0.00009099, counter:  243\n",
      "Epoch: [12] [  20/  32] d_loss: -0.00010008, counter:  244\n",
      "Epoch: [12] [  21/  32] d_loss: -0.00009887, counter:  245\n",
      "Epoch: [12] [  22/  32] d_loss: -0.00011305, counter:  246\n",
      "Epoch: [12] [  23/  32] d_loss: -0.00010768, counter:  247\n",
      "Epoch: [12] [  24/  32] d_loss: -0.00010538, counter:  248\n",
      "Epoch: [12] [  24/  32] d_loss: -0.00010594, g_loss: 0.00018767, counter:  248\n",
      "Epoch: [12] [  25/  32] d_loss: -0.00010929, counter:  249\n",
      "Epoch: [12] [  26/  32] d_loss: -0.00012268, counter:  250\n",
      "Epoch: [12] [  27/  32] d_loss: -0.00012574, counter:  251\n",
      "Epoch: [12] [  28/  32] d_loss: -0.00013005, counter:  252\n",
      "Epoch: [12] [  29/  32] d_loss: -0.00012133, counter:  253\n",
      "Epoch: [12] [  30/  32] d_loss: -0.00013199, counter:  254\n",
      "Epoch: [12] [  31/  32] d_loss: -0.00013873, counter:  255\n",
      "Epoch: [12] [  32/  32] d_loss: -0.00012857, counter:  256\n",
      "Epoch: [12] [  32/  32] d_loss: -0.00013279, g_loss: 0.00024679, counter:  256\n",
      "Epoch: [13] [   1/  32] d_loss: -0.00014089, counter:  257\n",
      "Epoch: [13] [   2/  32] d_loss: -0.00015780, counter:  258\n",
      "Epoch: [13] [   3/  32] d_loss: -0.00015956, counter:  259\n",
      "Epoch: [13] [   4/  32] d_loss: -0.00015584, counter:  260\n",
      "Epoch: [13] [   5/  32] d_loss: -0.00016751, counter:  261\n",
      "Epoch: [13] [   6/  32] d_loss: -0.00016399, counter:  262\n",
      "Epoch: [13] [   7/  32] d_loss: -0.00017978, counter:  263\n",
      "Epoch: [13] [   8/  32] d_loss: -0.00018796, counter:  264\n",
      "Epoch: [13] [   8/  32] d_loss: -0.00020373, g_loss: 0.00032957, counter:  264\n",
      "Epoch: [13] [   9/  32] d_loss: -0.00020910, counter:  265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13] [  10/  32] d_loss: -0.00019336, counter:  266\n",
      "Epoch: [13] [  11/  32] d_loss: -0.00020185, counter:  267\n",
      "Epoch: [13] [  12/  32] d_loss: -0.00018675, counter:  268\n",
      "Epoch: [13] [  13/  32] d_loss: -0.00020103, counter:  269\n",
      "Epoch: [13] [  14/  32] d_loss: -0.00021437, counter:  270\n",
      "Epoch: [13] [  15/  32] d_loss: -0.00022648, counter:  271\n",
      "Epoch: [13] [  16/  32] d_loss: -0.00023444, counter:  272\n",
      "Epoch: [13] [  16/  32] d_loss: -0.00023204, g_loss: 0.00040559, counter:  272\n",
      "Epoch: [13] [  17/  32] d_loss: -0.00022968, counter:  273\n",
      "Epoch: [13] [  18/  32] d_loss: -0.00027311, counter:  274\n",
      "Epoch: [13] [  19/  32] d_loss: -0.00025795, counter:  275\n",
      "Epoch: [13] [  20/  32] d_loss: -0.00030418, counter:  276\n",
      "Epoch: [13] [  21/  32] d_loss: -0.00025566, counter:  277\n",
      "Epoch: [13] [  22/  32] d_loss: -0.00028852, counter:  278\n",
      "Epoch: [13] [  23/  32] d_loss: -0.00027676, counter:  279\n",
      "Epoch: [13] [  24/  32] d_loss: -0.00028421, counter:  280\n",
      "Epoch: [13] [  24/  32] d_loss: -0.00031307, g_loss: 0.00053869, counter:  280\n",
      "Epoch: [13] [  25/  32] d_loss: -0.00034238, counter:  281\n",
      "Epoch: [13] [  26/  32] d_loss: -0.00030094, counter:  282\n",
      "Epoch: [13] [  27/  32] d_loss: -0.00034330, counter:  283\n",
      "Epoch: [13] [  28/  32] d_loss: -0.00034364, counter:  284\n",
      "Epoch: [13] [  29/  32] d_loss: -0.00032130, counter:  285\n",
      "Epoch: [13] [  30/  32] d_loss: -0.00033994, counter:  286\n",
      "Epoch: [13] [  31/  32] d_loss: -0.00037613, counter:  287\n",
      "Epoch: [13] [  32/  32] d_loss: -0.00042549, counter:  288\n",
      "Epoch: [13] [  32/  32] d_loss: -0.00041564, g_loss: 0.00069432, counter:  288\n",
      "Epoch: [14] [   1/  32] d_loss: -0.00038575, counter:  289\n",
      "Epoch: [14] [   2/  32] d_loss: -0.00039167, counter:  290\n",
      "Epoch: [14] [   3/  32] d_loss: -0.00036867, counter:  291\n",
      "Epoch: [14] [   4/  32] d_loss: -0.00044751, counter:  292\n",
      "Epoch: [14] [   5/  32] d_loss: -0.00046417, counter:  293\n",
      "Epoch: [14] [   6/  32] d_loss: -0.00046490, counter:  294\n",
      "Epoch: [14] [   7/  32] d_loss: -0.00048382, counter:  295\n",
      "Epoch: [14] [   8/  32] d_loss: -0.00051503, counter:  296\n",
      "Epoch: [14] [   8/  32] d_loss: -0.00051071, g_loss: 0.00090490, counter:  296\n",
      "Epoch: [14] [   9/  32] d_loss: -0.00045585, counter:  297\n",
      "Epoch: [14] [  10/  32] d_loss: -0.00052687, counter:  298\n",
      "Epoch: [14] [  11/  32] d_loss: -0.00055039, counter:  299\n",
      "Epoch: [14] [  12/  32] d_loss: -0.00054568, counter:  300\n",
      "Epoch: [14] [  13/  32] d_loss: -0.00056242, counter:  301\n",
      "Epoch: [14] [  14/  32] d_loss: -0.00059933, counter:  302\n",
      "Epoch: [14] [  15/  32] d_loss: -0.00060543, counter:  303\n",
      "Epoch: [14] [  16/  32] d_loss: -0.00064389, counter:  304\n",
      "Epoch: [14] [  16/  32] d_loss: -0.00066444, g_loss: 0.00115421, counter:  304\n",
      "Epoch: [14] [  17/  32] d_loss: -0.00067884, counter:  305\n",
      "Epoch: [14] [  18/  32] d_loss: -0.00073773, counter:  306\n",
      "Epoch: [14] [  19/  32] d_loss: -0.00072825, counter:  307\n",
      "Epoch: [14] [  20/  32] d_loss: -0.00073041, counter:  308\n",
      "Epoch: [14] [  21/  32] d_loss: -0.00073589, counter:  309\n",
      "Epoch: [14] [  22/  32] d_loss: -0.00071985, counter:  310\n",
      "Epoch: [14] [  23/  32] d_loss: -0.00078873, counter:  311\n",
      "Epoch: [14] [  24/  32] d_loss: -0.00089434, counter:  312\n",
      "Epoch: [14] [  24/  32] d_loss: -0.00085164, g_loss: 0.00150047, counter:  312\n",
      "Epoch: [14] [  25/  32] d_loss: -0.00094680, counter:  313\n",
      "Epoch: [14] [  26/  32] d_loss: -0.00093172, counter:  314\n",
      "Epoch: [14] [  27/  32] d_loss: -0.00092947, counter:  315\n",
      "Epoch: [14] [  28/  32] d_loss: -0.00097084, counter:  316\n",
      "Epoch: [14] [  29/  32] d_loss: -0.00100691, counter:  317\n",
      "Epoch: [14] [  30/  32] d_loss: -0.00101947, counter:  318\n",
      "Epoch: [14] [  31/  32] d_loss: -0.00106122, counter:  319\n",
      "Epoch: [14] [  32/  32] d_loss: -0.00112110, counter:  320\n",
      "Epoch: [14] [  32/  32] d_loss: -0.00107716, g_loss: 0.00187715, counter:  320\n",
      "Epoch: [15] [   1/  32] d_loss: -0.00110328, counter:  321\n",
      "Epoch: [15] [   2/  32] d_loss: -0.00117339, counter:  322\n",
      "Epoch: [15] [   3/  32] d_loss: -0.00106697, counter:  323\n",
      "Epoch: [15] [   4/  32] d_loss: -0.00117465, counter:  324\n",
      "Epoch: [15] [   5/  32] d_loss: -0.00126026, counter:  325\n",
      "Epoch: [15] [   6/  32] d_loss: -0.00126003, counter:  326\n",
      "Epoch: [15] [   7/  32] d_loss: -0.00130817, counter:  327\n",
      "Epoch: [15] [   8/  32] d_loss: -0.00131523, counter:  328\n",
      "Epoch: [15] [   8/  32] d_loss: -0.00144598, g_loss: 0.00254331, counter:  328\n",
      "Epoch: [15] [   9/  32] d_loss: -0.00144238, counter:  329\n",
      "Epoch: [15] [  10/  32] d_loss: -0.00145588, counter:  330\n",
      "Epoch: [15] [  11/  32] d_loss: -0.00144430, counter:  331\n",
      "Epoch: [15] [  12/  32] d_loss: -0.00160884, counter:  332\n",
      "Epoch: [15] [  13/  32] d_loss: -0.00165119, counter:  333\n",
      "Epoch: [15] [  14/  32] d_loss: -0.00169609, counter:  334\n",
      "Epoch: [15] [  15/  32] d_loss: -0.00161496, counter:  335\n",
      "Epoch: [15] [  16/  32] d_loss: -0.00170036, counter:  336\n",
      "Epoch: [15] [  16/  32] d_loss: -0.00195633, g_loss: 0.00333649, counter:  336\n",
      "Epoch: [15] [  17/  32] d_loss: -0.00182419, counter:  337\n",
      "Epoch: [15] [  18/  32] d_loss: -0.00179378, counter:  338\n",
      "Epoch: [15] [  19/  32] d_loss: -0.00197587, counter:  339\n",
      "Epoch: [15] [  20/  32] d_loss: -0.00227890, counter:  340\n",
      "Epoch: [15] [  21/  32] d_loss: -0.00217865, counter:  341\n",
      "Epoch: [15] [  22/  32] d_loss: -0.00211882, counter:  342\n",
      "Epoch: [15] [  23/  32] d_loss: -0.00201554, counter:  343\n",
      "Epoch: [15] [  24/  32] d_loss: -0.00239310, counter:  344\n",
      "Epoch: [15] [  24/  32] d_loss: -0.00228720, g_loss: 0.00409551, counter:  344\n",
      "Epoch: [15] [  25/  32] d_loss: -0.00255016, counter:  345\n",
      "Epoch: [15] [  26/  32] d_loss: -0.00251954, counter:  346\n",
      "Epoch: [15] [  27/  32] d_loss: -0.00249226, counter:  347\n",
      "Epoch: [15] [  28/  32] d_loss: -0.00275419, counter:  348\n",
      "Epoch: [15] [  29/  32] d_loss: -0.00299298, counter:  349\n",
      "Epoch: [15] [  30/  32] d_loss: -0.00264919, counter:  350\n",
      "Epoch: [15] [  31/  32] d_loss: -0.00282970, counter:  351\n",
      "Epoch: [15] [  32/  32] d_loss: -0.00252763, counter:  352\n",
      "Epoch: [15] [  32/  32] d_loss: -0.00291744, g_loss: 0.00540749, counter:  352\n",
      "Epoch: [16] [   1/  32] d_loss: -0.00301582, counter:  353\n",
      "Epoch: [16] [   2/  32] d_loss: -0.00289320, counter:  354\n",
      "Epoch: [16] [   3/  32] d_loss: -0.00348178, counter:  355\n",
      "Epoch: [16] [   4/  32] d_loss: -0.00342692, counter:  356\n",
      "Epoch: [16] [   5/  32] d_loss: -0.00387635, counter:  357\n",
      "Epoch: [16] [   6/  32] d_loss: -0.00374834, counter:  358\n",
      "Epoch: [16] [   7/  32] d_loss: -0.00377823, counter:  359\n",
      "Epoch: [16] [   8/  32] d_loss: -0.00385431, counter:  360\n",
      "Epoch: [16] [   8/  32] d_loss: -0.00373289, g_loss: 0.00697534, counter:  360\n",
      "Epoch: [16] [   9/  32] d_loss: -0.00385593, counter:  361\n",
      "Epoch: [16] [  10/  32] d_loss: -0.00397465, counter:  362\n",
      "Epoch: [16] [  11/  32] d_loss: -0.00379859, counter:  363\n",
      "Epoch: [16] [  12/  32] d_loss: -0.00421158, counter:  364\n",
      "Epoch: [16] [  13/  32] d_loss: -0.00399075, counter:  365\n",
      "Epoch: [16] [  14/  32] d_loss: -0.00435517, counter:  366\n",
      "Epoch: [16] [  15/  32] d_loss: -0.00475679, counter:  367\n",
      "Epoch: [16] [  16/  32] d_loss: -0.00427927, counter:  368\n",
      "Epoch: [16] [  16/  32] d_loss: -0.00462341, g_loss: 0.00889190, counter:  368\n",
      "Epoch: [16] [  17/  32] d_loss: -0.00429059, counter:  369\n",
      "Epoch: [16] [  18/  32] d_loss: -0.00460329, counter:  370\n",
      "Epoch: [16] [  19/  32] d_loss: -0.00463050, counter:  371\n",
      "Epoch: [16] [  20/  32] d_loss: -0.00473734, counter:  372\n",
      "Epoch: [16] [  21/  32] d_loss: -0.00534792, counter:  373\n",
      "Epoch: [16] [  22/  32] d_loss: -0.00523338, counter:  374\n",
      "Epoch: [16] [  23/  32] d_loss: -0.00614958, counter:  375\n",
      "Epoch: [16] [  24/  32] d_loss: -0.00605114, counter:  376\n",
      "Epoch: [16] [  24/  32] d_loss: -0.00596166, g_loss: 0.01149314, counter:  376\n",
      "Epoch: [16] [  25/  32] d_loss: -0.00621902, counter:  377\n",
      "Epoch: [16] [  26/  32] d_loss: -0.00591771, counter:  378\n",
      "Epoch: [16] [  27/  32] d_loss: -0.00641333, counter:  379\n",
      "Epoch: [16] [  28/  32] d_loss: -0.00714304, counter:  380\n",
      "Epoch: [16] [  29/  32] d_loss: -0.00681983, counter:  381\n",
      "Epoch: [16] [  30/  32] d_loss: -0.00713859, counter:  382\n",
      "Epoch: [16] [  31/  32] d_loss: -0.00760736, counter:  383\n",
      "Epoch: [16] [  32/  32] d_loss: -0.00813652, counter:  384\n",
      "Epoch: [16] [  32/  32] d_loss: -0.00701855, g_loss: 0.01471974, counter:  384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17] [   1/  32] d_loss: -0.00744905, counter:  385\n",
      "Epoch: [17] [   2/  32] d_loss: -0.00766375, counter:  386\n",
      "Epoch: [17] [   3/  32] d_loss: -0.00725822, counter:  387\n",
      "Epoch: [17] [   4/  32] d_loss: -0.00821858, counter:  388\n",
      "Epoch: [17] [   5/  32] d_loss: -0.00813109, counter:  389\n",
      "Epoch: [17] [   6/  32] d_loss: -0.00834346, counter:  390\n",
      "Epoch: [17] [   7/  32] d_loss: -0.00852259, counter:  391\n",
      "Epoch: [17] [   8/  32] d_loss: -0.00821674, counter:  392\n",
      "Epoch: [17] [   8/  32] d_loss: -0.00829701, g_loss: 0.01783880, counter:  392\n",
      "Epoch: [17] [   9/  32] d_loss: -0.00877223, counter:  393\n",
      "Epoch: [17] [  10/  32] d_loss: -0.00892298, counter:  394\n",
      "Epoch: [17] [  11/  32] d_loss: -0.01012378, counter:  395\n",
      "Epoch: [17] [  12/  32] d_loss: -0.00907361, counter:  396\n",
      "Epoch: [17] [  13/  32] d_loss: -0.00924245, counter:  397\n",
      "Epoch: [17] [  14/  32] d_loss: -0.01074908, counter:  398\n",
      "Epoch: [17] [  15/  32] d_loss: -0.01075248, counter:  399\n",
      "Epoch: [17] [  16/  32] d_loss: -0.01078417, counter:  400\n",
      "Epoch: [17] [  16/  32] d_loss: -0.01039493, g_loss: 0.02205447, counter:  400\n",
      "Epoch: [17] [  17/  32] d_loss: -0.01076768, counter:  401\n",
      "Epoch: [17] [  18/  32] d_loss: -0.01198362, counter:  402\n",
      "Epoch: [17] [  19/  32] d_loss: -0.01252959, counter:  403\n",
      "Epoch: [17] [  20/  32] d_loss: -0.01181537, counter:  404\n",
      "Epoch: [17] [  21/  32] d_loss: -0.01258533, counter:  405\n",
      "Epoch: [17] [  22/  32] d_loss: -0.01179888, counter:  406\n",
      "Epoch: [17] [  23/  32] d_loss: -0.01153324, counter:  407\n",
      "Epoch: [17] [  24/  32] d_loss: -0.01338300, counter:  408\n",
      "Epoch: [17] [  24/  32] d_loss: -0.01492788, g_loss: 0.02898784, counter:  408\n",
      "Epoch: [17] [  25/  32] d_loss: -0.01439289, counter:  409\n",
      "Epoch: [17] [  26/  32] d_loss: -0.01475201, counter:  410\n",
      "Epoch: [17] [  27/  32] d_loss: -0.01406759, counter:  411\n",
      "Epoch: [17] [  28/  32] d_loss: -0.01644268, counter:  412\n",
      "Epoch: [17] [  29/  32] d_loss: -0.01546349, counter:  413\n",
      "Epoch: [17] [  30/  32] d_loss: -0.01296611, counter:  414\n",
      "Epoch: [17] [  31/  32] d_loss: -0.01016894, counter:  415\n",
      "Epoch: [17] [  32/  32] d_loss: -0.01717193, counter:  416\n",
      "Epoch: [17] [  32/  32] d_loss: -0.01476580, g_loss: 0.03507006, counter:  416\n",
      "Epoch: [18] [   1/  32] d_loss: -0.01413652, counter:  417\n",
      "Epoch: [18] [   2/  32] d_loss: -0.01540059, counter:  418\n",
      "Epoch: [18] [   3/  32] d_loss: -0.01703467, counter:  419\n",
      "Epoch: [18] [   4/  32] d_loss: -0.01747143, counter:  420\n",
      "Epoch: [18] [   5/  32] d_loss: -0.01544791, counter:  421\n",
      "Epoch: [18] [   6/  32] d_loss: -0.01578037, counter:  422\n",
      "Epoch: [18] [   7/  32] d_loss: -0.01811126, counter:  423\n",
      "Epoch: [18] [   8/  32] d_loss: -0.01829738, counter:  424\n",
      "Epoch: [18] [   8/  32] d_loss: -0.01841284, g_loss: 0.04375974, counter:  424\n",
      "Epoch: [18] [   9/  32] d_loss: -0.02124682, counter:  425\n",
      "Epoch: [18] [  10/  32] d_loss: -0.01927108, counter:  426\n",
      "Epoch: [18] [  11/  32] d_loss: -0.01865822, counter:  427\n",
      "Epoch: [18] [  12/  32] d_loss: -0.02172953, counter:  428\n",
      "Epoch: [18] [  13/  32] d_loss: -0.01849684, counter:  429\n",
      "Epoch: [18] [  14/  32] d_loss: -0.01768685, counter:  430\n",
      "Epoch: [18] [  15/  32] d_loss: -0.02075538, counter:  431\n",
      "Epoch: [18] [  16/  32] d_loss: -0.02165692, counter:  432\n",
      "Epoch: [18] [  16/  32] d_loss: -0.01982143, g_loss: 0.04983879, counter:  432\n",
      "Epoch: [18] [  17/  32] d_loss: -0.02293037, counter:  433\n",
      "Epoch: [18] [  18/  32] d_loss: -0.02447798, counter:  434\n",
      "Epoch: [18] [  19/  32] d_loss: -0.02401837, counter:  435\n",
      "Epoch: [18] [  20/  32] d_loss: -0.02433458, counter:  436\n",
      "Epoch: [18] [  21/  32] d_loss: -0.02456759, counter:  437\n",
      "Epoch: [18] [  22/  32] d_loss: -0.02507278, counter:  438\n",
      "Epoch: [18] [  23/  32] d_loss: -0.03015094, counter:  439\n",
      "Epoch: [18] [  24/  32] d_loss: -0.02409193, counter:  440\n",
      "Epoch: [18] [  24/  32] d_loss: -0.02446214, g_loss: 0.06054243, counter:  440\n",
      "Epoch: [18] [  25/  32] d_loss: -0.02733549, counter:  441\n",
      "Epoch: [18] [  26/  32] d_loss: -0.02706984, counter:  442\n",
      "Epoch: [18] [  27/  32] d_loss: -0.02530969, counter:  443\n",
      "Epoch: [18] [  28/  32] d_loss: -0.02967481, counter:  444\n",
      "Epoch: [18] [  29/  32] d_loss: -0.03155050, counter:  445\n",
      "Epoch: [18] [  30/  32] d_loss: -0.02839749, counter:  446\n",
      "Epoch: [18] [  31/  32] d_loss: -0.02913414, counter:  447\n",
      "Epoch: [18] [  32/  32] d_loss: -0.03068780, counter:  448\n",
      "Epoch: [18] [  32/  32] d_loss: -0.03488886, g_loss: 0.07290337, counter:  448\n",
      "Epoch: [19] [   1/  32] d_loss: -0.03306981, counter:  449\n",
      "Epoch: [19] [   2/  32] d_loss: -0.03470429, counter:  450\n",
      "Epoch: [19] [   3/  32] d_loss: -0.03606369, counter:  451\n",
      "Epoch: [19] [   4/  32] d_loss: -0.03595153, counter:  452\n",
      "Epoch: [19] [   5/  32] d_loss: -0.03173335, counter:  453\n",
      "Epoch: [19] [   6/  32] d_loss: -0.03194528, counter:  454\n",
      "Epoch: [19] [   7/  32] d_loss: -0.03446699, counter:  455\n",
      "Epoch: [19] [   8/  32] d_loss: -0.03359717, counter:  456\n",
      "Epoch: [19] [   8/  32] d_loss: -0.03797152, g_loss: 0.08726596, counter:  456\n",
      "Epoch: [19] [   9/  32] d_loss: -0.04237884, counter:  457\n",
      "Epoch: [19] [  10/  32] d_loss: -0.04265262, counter:  458\n",
      "Epoch: [19] [  11/  32] d_loss: -0.04431726, counter:  459\n",
      "Epoch: [19] [  12/  32] d_loss: -0.04960669, counter:  460\n",
      "Epoch: [19] [  13/  32] d_loss: -0.04670990, counter:  461\n",
      "Epoch: [19] [  14/  32] d_loss: -0.04570938, counter:  462\n",
      "Epoch: [19] [  15/  32] d_loss: -0.04239470, counter:  463\n",
      "Epoch: [19] [  16/  32] d_loss: -0.05051951, counter:  464\n",
      "Epoch: [19] [  16/  32] d_loss: -0.05096656, g_loss: 0.11027195, counter:  464\n",
      "Epoch: [19] [  17/  32] d_loss: -0.05333202, counter:  465\n",
      "Epoch: [19] [  18/  32] d_loss: -0.04676062, counter:  466\n",
      "Epoch: [19] [  19/  32] d_loss: -0.04587933, counter:  467\n",
      "Epoch: [19] [  20/  32] d_loss: -0.05209845, counter:  468\n",
      "Epoch: [19] [  21/  32] d_loss: -0.05255456, counter:  469\n",
      "Epoch: [19] [  22/  32] d_loss: -0.05481438, counter:  470\n",
      "Epoch: [19] [  23/  32] d_loss: -0.05918726, counter:  471\n",
      "Epoch: [19] [  24/  32] d_loss: -0.06687859, counter:  472\n",
      "Epoch: [19] [  24/  32] d_loss: -0.06261527, g_loss: 0.13295893, counter:  472\n",
      "Epoch: [19] [  25/  32] d_loss: -0.06480071, counter:  473\n",
      "Epoch: [19] [  26/  32] d_loss: -0.06285180, counter:  474\n",
      "Epoch: [19] [  27/  32] d_loss: -0.06060700, counter:  475\n",
      "Epoch: [19] [  28/  32] d_loss: -0.07083849, counter:  476\n",
      "Epoch: [19] [  29/  32] d_loss: -0.06661390, counter:  477\n",
      "Epoch: [19] [  30/  32] d_loss: -0.07669611, counter:  478\n",
      "Epoch: [19] [  31/  32] d_loss: -0.07735207, counter:  479\n",
      "Epoch: [19] [  32/  32] d_loss: -0.06496453, counter:  480\n",
      "Epoch: [19] [  32/  32] d_loss: -0.08327226, g_loss: 0.16016954, counter:  480\n",
      "Epoch: [20] [   1/  32] d_loss: -0.07877815, counter:  481\n",
      "Epoch: [20] [   2/  32] d_loss: -0.07744557, counter:  482\n",
      "Epoch: [20] [   3/  32] d_loss: -0.08436415, counter:  483\n",
      "Epoch: [20] [   4/  32] d_loss: -0.07613017, counter:  484\n",
      "Epoch: [20] [   5/  32] d_loss: -0.09214561, counter:  485\n",
      "Epoch: [20] [   6/  32] d_loss: -0.09051435, counter:  486\n",
      "Epoch: [20] [   7/  32] d_loss: -0.08957584, counter:  487\n",
      "Epoch: [20] [   8/  32] d_loss: -0.08671073, counter:  488\n",
      "Epoch: [20] [   8/  32] d_loss: -0.10871160, g_loss: 0.20272925, counter:  488\n",
      "Epoch: [20] [   9/  32] d_loss: -0.08932074, counter:  489\n",
      "Epoch: [20] [  10/  32] d_loss: -0.09555756, counter:  490\n",
      "Epoch: [20] [  11/  32] d_loss: -0.09675966, counter:  491\n",
      "Epoch: [20] [  12/  32] d_loss: -0.12146131, counter:  492\n",
      "Epoch: [20] [  13/  32] d_loss: -0.07148170, counter:  493\n",
      "Epoch: [20] [  14/  32] d_loss: -0.09824097, counter:  494\n",
      "Epoch: [20] [  15/  32] d_loss: -0.08917932, counter:  495\n",
      "Epoch: [20] [  16/  32] d_loss: -0.09302169, counter:  496\n",
      "Epoch: [20] [  16/  32] d_loss: -0.09399506, g_loss: 0.23025852, counter:  496\n",
      "Epoch: [20] [  17/  32] d_loss: -0.10959494, counter:  497\n",
      "Epoch: [20] [  18/  32] d_loss: -0.09524964, counter:  498\n",
      "Epoch: [20] [  19/  32] d_loss: -0.10268593, counter:  499\n",
      "Epoch: [20] [  20/  32] d_loss: -0.09669355, counter:  500\n",
      "Epoch: [20] [  21/  32] d_loss: -0.11209725, counter:  501\n",
      "Epoch: [20] [  22/  32] d_loss: -0.10884455, counter:  502\n",
      "Epoch: [20] [  23/  32] d_loss: -0.11190765, counter:  503\n",
      "Epoch: [20] [  24/  32] d_loss: -0.12549329, counter:  504\n",
      "Epoch: [20] [  24/  32] d_loss: -0.11729532, g_loss: 0.28004605, counter:  504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20] [  25/  32] d_loss: -0.11142541, counter:  505\n",
      "Epoch: [20] [  26/  32] d_loss: -0.11760435, counter:  506\n",
      "Epoch: [20] [  27/  32] d_loss: -0.10582697, counter:  507\n",
      "Epoch: [20] [  28/  32] d_loss: -0.11768231, counter:  508\n",
      "Epoch: [20] [  29/  32] d_loss: -0.13698235, counter:  509\n",
      "Epoch: [20] [  30/  32] d_loss: -0.12604479, counter:  510\n",
      "Epoch: [20] [  31/  32] d_loss: -0.13328987, counter:  511\n",
      "Epoch: [20] [  32/  32] d_loss: -0.12470990, counter:  512\n",
      "Epoch: [20] [  32/  32] d_loss: -0.12759089, g_loss: 0.31587911, counter:  512\n",
      "Epoch: [21] [   1/  32] d_loss: -0.16327122, counter:  513\n",
      "Epoch: [21] [   2/  32] d_loss: -0.14286219, counter:  514\n",
      "Epoch: [21] [   3/  32] d_loss: -0.14405057, counter:  515\n",
      "Epoch: [21] [   4/  32] d_loss: -0.16329956, counter:  516\n",
      "Epoch: [21] [   5/  32] d_loss: -0.16043656, counter:  517\n",
      "Epoch: [21] [   6/  32] d_loss: -0.17723440, counter:  518\n",
      "Epoch: [21] [   7/  32] d_loss: -0.15676861, counter:  519\n",
      "Epoch: [21] [   8/  32] d_loss: -0.19307764, counter:  520\n",
      "Epoch: [21] [   8/  32] d_loss: -0.17434703, g_loss: 0.38002300, counter:  520\n",
      "Epoch: [21] [   9/  32] d_loss: -0.17440709, counter:  521\n",
      "Epoch: [21] [  10/  32] d_loss: -0.21389978, counter:  522\n",
      "Epoch: [21] [  11/  32] d_loss: -0.16771242, counter:  523\n",
      "Epoch: [21] [  12/  32] d_loss: -0.21854493, counter:  524\n",
      "Epoch: [21] [  13/  32] d_loss: -0.18981028, counter:  525\n",
      "Epoch: [21] [  14/  32] d_loss: -0.23120642, counter:  526\n",
      "Epoch: [21] [  15/  32] d_loss: -0.22449711, counter:  527\n",
      "Epoch: [21] [  16/  32] d_loss: -0.19799948, counter:  528\n",
      "Epoch: [21] [  16/  32] d_loss: -0.22947527, g_loss: 0.46195135, counter:  528\n",
      "Epoch: [21] [  17/  32] d_loss: -0.24767889, counter:  529\n",
      "Epoch: [21] [  18/  32] d_loss: -0.21477580, counter:  530\n",
      "Epoch: [21] [  19/  32] d_loss: -0.21815301, counter:  531\n",
      "Epoch: [21] [  20/  32] d_loss: -0.22422598, counter:  532\n",
      "Epoch: [21] [  21/  32] d_loss: -0.23058748, counter:  533\n",
      "Epoch: [21] [  22/  32] d_loss: -0.23892139, counter:  534\n",
      "Epoch: [21] [  23/  32] d_loss: -0.27906010, counter:  535\n",
      "Epoch: [21] [  24/  32] d_loss: -0.24743870, counter:  536\n",
      "Epoch: [21] [  24/  32] d_loss: -0.23137504, g_loss: 0.49254841, counter:  536\n",
      "Epoch: [21] [  25/  32] d_loss: -0.24501008, counter:  537\n",
      "Epoch: [21] [  26/  32] d_loss: -0.21669349, counter:  538\n",
      "Epoch: [21] [  27/  32] d_loss: -0.31098545, counter:  539\n",
      "Epoch: [21] [  28/  32] d_loss: -0.32108411, counter:  540\n",
      "Epoch: [21] [  29/  32] d_loss: -0.29754210, counter:  541\n",
      "Epoch: [21] [  30/  32] d_loss: -0.30316237, counter:  542\n",
      "Epoch: [21] [  31/  32] d_loss: -0.35701352, counter:  543\n",
      "Epoch: [21] [  32/  32] d_loss: -0.25932503, counter:  544\n",
      "Epoch: [21] [  32/  32] d_loss: -0.22980189, g_loss: 0.56150639, counter:  544\n",
      "Epoch: [22] [   1/  32] d_loss: -0.31632784, counter:  545\n",
      "Epoch: [22] [   2/  32] d_loss: -0.34407920, counter:  546\n",
      "Epoch: [22] [   3/  32] d_loss: -0.33012724, counter:  547\n",
      "Epoch: [22] [   4/  32] d_loss: -0.31163508, counter:  548\n",
      "Epoch: [22] [   5/  32] d_loss: -0.34210712, counter:  549\n",
      "Epoch: [22] [   6/  32] d_loss: -0.39262128, counter:  550\n",
      "Epoch: [22] [   7/  32] d_loss: -0.35742220, counter:  551\n",
      "Epoch: [22] [   8/  32] d_loss: -0.39864489, counter:  552\n",
      "Epoch: [22] [   8/  32] d_loss: -0.36070174, g_loss: 0.73375398, counter:  552\n",
      "Epoch: [22] [   9/  32] d_loss: -0.38762259, counter:  553\n",
      "Epoch: [22] [  10/  32] d_loss: -0.38902733, counter:  554\n",
      "Epoch: [22] [  11/  32] d_loss: -0.35139644, counter:  555\n",
      "Epoch: [22] [  12/  32] d_loss: -0.45810619, counter:  556\n",
      "Epoch: [22] [  13/  32] d_loss: -0.40650576, counter:  557\n",
      "Epoch: [22] [  14/  32] d_loss: -0.47183615, counter:  558\n",
      "Epoch: [22] [  15/  32] d_loss: -0.41535845, counter:  559\n",
      "Epoch: [22] [  16/  32] d_loss: -0.42614335, counter:  560\n",
      "Epoch: [22] [  16/  32] d_loss: -0.44710281, g_loss: 0.89123833, counter:  560\n",
      "Epoch: [22] [  17/  32] d_loss: -0.44650102, counter:  561\n",
      "Epoch: [22] [  18/  32] d_loss: -0.48147452, counter:  562\n",
      "Epoch: [22] [  19/  32] d_loss: -0.42662117, counter:  563\n",
      "Epoch: [22] [  20/  32] d_loss: -0.46015060, counter:  564\n",
      "Epoch: [22] [  21/  32] d_loss: -0.46285886, counter:  565\n",
      "Epoch: [22] [  22/  32] d_loss: -0.45290390, counter:  566\n",
      "Epoch: [22] [  23/  32] d_loss: -0.58143795, counter:  567\n",
      "Epoch: [22] [  24/  32] d_loss: -0.55716842, counter:  568\n",
      "Epoch: [22] [  24/  32] d_loss: -0.49571151, g_loss: 0.97467446, counter:  568\n",
      "Epoch: [22] [  25/  32] d_loss: -0.57528818, counter:  569\n",
      "Epoch: [22] [  26/  32] d_loss: -0.60534579, counter:  570\n",
      "Epoch: [22] [  27/  32] d_loss: -0.60356307, counter:  571\n",
      "Epoch: [22] [  28/  32] d_loss: -0.62209332, counter:  572\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19796\\429429800.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_mask_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_delta_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19796\\1195543389.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X, M, Delta, batch_size, num_epoch, num_pretrain_epoch, lr, disc_iters)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m# Update Discriminator Networks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0md_real_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_real_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDelta_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0md_fake_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_fake_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19796\\2854884378.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, rv, H, batch_size)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mDelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_gaps\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrui_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Full connect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19796\\3745696697.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X, Delta, H)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mY_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgruicell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDelta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19796\\3169845226.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X, Delta, H)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hiddens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDelta\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_beta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_beta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_xz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_hz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_xr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_hr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mH_tilde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_xh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_hh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator, discriminator = train(X_val, val_mask_mat, val_delta_mat, 128, 30, 4, 0.01, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2b1fb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(generator, discriminator, X, M, z_dim, batch_size, lr, g_loss_lambda, impute_iters):\n",
    "    batch_id = 1\n",
    "    impute_times = 0\n",
    "    counter = 0\n",
    "    \n",
    "    X = torch.from_numpy(X).float()\n",
    "    M = torch.from_numpy(M).float()\n",
    "    \n",
    "    X_imputed = []\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for step in range(X.shape[0] // batch_size + 1):\n",
    "        if (step + 1) * batch_size <= X_train.shape[0]:\n",
    "            X_batch = X[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "            M_batch = M[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "            Delta_batch = Delta[int(step * batch_size):int((step + 1) * batch_size)]\n",
    "        else:\n",
    "            X_batch = X[int(step * batch_size):]\n",
    "            M_batch = M[int(step * batch_size):]\n",
    "            Delta_batch = Delta[int(step * batch_size):]\n",
    "        \n",
    "        generator_dict = generator.state_dict()\n",
    "        gen = Generator(X.shape[2], 64, 64, 60, 64, 0).to(device)\n",
    "        gen_dict = gen.state_dict()\n",
    "        gen_dict.update(generator_dict)\n",
    "        gen.load_state_dict(gen_dict)\n",
    "\n",
    "        criterion = ImpLoss(g_loss_lambda)\n",
    "        optimizer = torch.optim.SGD(gen.parameters(), lr)\n",
    "        \n",
    "        Z = torch.randn((X.shape[1], batch_size, z_dim)) * 0.1\n",
    "        init_state = None\n",
    "        for i in range(impute_iters):\n",
    "            outputs, delta, final_state = gen(Z, init_state, batch_size)\n",
    "            init_state = final_state.detach()\n",
    "            imputed_fake_probs, imputed_fake_logits = discriminator(outputs, delta, None)\n",
    "            loss = criterion(X_batch, M_batch, outputs, imputed_fake_logits)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(generator, 0.99)\n",
    "            optimizer.step()\n",
    "            impute_times += 1\n",
    "            counter += 1\n",
    "            if counter % 5 == 0:\n",
    "                print(\"Batch ID: [%2d] [%2d/%2d] Imputation Loss: %.8f\" % (batch_id, impute_times, impute_iters, loss))\n",
    "        for j in range(X_batch.shape[0]):\n",
    "            X_imputed.append((X_batch[j] * M_batch[j] + outputs[:,j,:] * (1 - M_batch[j])).detach().numpy())\n",
    "        batch_id += 1\n",
    "        impute_times = 0\n",
    "    \n",
    "    with open('E:/WashU/Research/ICU/Data/val/X_val_sliced_norm_GAN.pkl', 'wb') as f:\n",
    "        pickle.dump(X_imputed, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8b03c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: [ 1] [ 5/50] Imputation Loss: 13.86453247\n",
      "Batch ID: [ 1] [10/50] Imputation Loss: 6.51693058\n",
      "Batch ID: [ 1] [15/50] Imputation Loss: 3.04967880\n",
      "Batch ID: [ 1] [20/50] Imputation Loss: 1.82743025\n",
      "Batch ID: [ 1] [25/50] Imputation Loss: 0.93843120\n",
      "Batch ID: [ 1] [30/50] Imputation Loss: 0.48287624\n",
      "Batch ID: [ 1] [35/50] Imputation Loss: 0.24892420\n",
      "Batch ID: [ 1] [40/50] Imputation Loss: -0.67785907\n",
      "Batch ID: [ 1] [45/50] Imputation Loss: -1.11262524\n",
      "Batch ID: [ 1] [50/50] Imputation Loss: -2.33946323\n",
      "Batch ID: [ 2] [ 5/50] Imputation Loss: 13.90427399\n",
      "Batch ID: [ 2] [10/50] Imputation Loss: 6.31135130\n",
      "Batch ID: [ 2] [15/50] Imputation Loss: 3.09396243\n",
      "Batch ID: [ 2] [20/50] Imputation Loss: 1.32242930\n",
      "Batch ID: [ 2] [25/50] Imputation Loss: 1.22556150\n",
      "Batch ID: [ 2] [30/50] Imputation Loss: -0.50423497\n",
      "Batch ID: [ 2] [35/50] Imputation Loss: -1.20657337\n",
      "Batch ID: [ 2] [40/50] Imputation Loss: -0.80862945\n",
      "Batch ID: [ 2] [45/50] Imputation Loss: -1.46083891\n",
      "Batch ID: [ 2] [50/50] Imputation Loss: -1.60094869\n",
      "Batch ID: [ 3] [ 5/50] Imputation Loss: 14.39725876\n",
      "Batch ID: [ 3] [10/50] Imputation Loss: 6.57852650\n",
      "Batch ID: [ 3] [15/50] Imputation Loss: 2.71220970\n",
      "Batch ID: [ 3] [20/50] Imputation Loss: 2.10423827\n",
      "Batch ID: [ 3] [25/50] Imputation Loss: 0.54036278\n",
      "Batch ID: [ 3] [30/50] Imputation Loss: 0.41309458\n",
      "Batch ID: [ 3] [35/50] Imputation Loss: 0.00437122\n",
      "Batch ID: [ 3] [40/50] Imputation Loss: -0.68773973\n",
      "Batch ID: [ 3] [45/50] Imputation Loss: -0.71570826\n",
      "Batch ID: [ 3] [50/50] Imputation Loss: -2.21870613\n",
      "Batch ID: [ 4] [ 5/50] Imputation Loss: 14.19073296\n",
      "Batch ID: [ 4] [10/50] Imputation Loss: 6.55904627\n",
      "Batch ID: [ 4] [15/50] Imputation Loss: 3.36637640\n",
      "Batch ID: [ 4] [20/50] Imputation Loss: 1.37223101\n",
      "Batch ID: [ 4] [25/50] Imputation Loss: 0.26256013\n",
      "Batch ID: [ 4] [30/50] Imputation Loss: -0.19224408\n",
      "Batch ID: [ 4] [35/50] Imputation Loss: -0.05708298\n",
      "Batch ID: [ 4] [40/50] Imputation Loss: -1.19631469\n",
      "Batch ID: [ 4] [45/50] Imputation Loss: -0.88452637\n",
      "Batch ID: [ 4] [50/50] Imputation Loss: -1.72085035\n",
      "Batch ID: [ 5] [ 5/50] Imputation Loss: 14.25827408\n",
      "Batch ID: [ 5] [10/50] Imputation Loss: 6.94527674\n",
      "Batch ID: [ 5] [15/50] Imputation Loss: 3.97692251\n",
      "Batch ID: [ 5] [20/50] Imputation Loss: 1.59213400\n",
      "Batch ID: [ 5] [25/50] Imputation Loss: 0.78937972\n",
      "Batch ID: [ 5] [30/50] Imputation Loss: -0.08490093\n",
      "Batch ID: [ 5] [35/50] Imputation Loss: 0.16133042\n",
      "Batch ID: [ 5] [40/50] Imputation Loss: -0.60838193\n",
      "Batch ID: [ 5] [45/50] Imputation Loss: -0.51947159\n",
      "Batch ID: [ 5] [50/50] Imputation Loss: -1.09657276\n",
      "Batch ID: [ 6] [ 5/50] Imputation Loss: 14.34246349\n",
      "Batch ID: [ 6] [10/50] Imputation Loss: 6.81773281\n",
      "Batch ID: [ 6] [15/50] Imputation Loss: 3.18456459\n",
      "Batch ID: [ 6] [20/50] Imputation Loss: 1.65549994\n",
      "Batch ID: [ 6] [25/50] Imputation Loss: 0.86002356\n",
      "Batch ID: [ 6] [30/50] Imputation Loss: 1.30968344\n",
      "Batch ID: [ 6] [35/50] Imputation Loss: -0.17063689\n",
      "Batch ID: [ 6] [40/50] Imputation Loss: -0.58976138\n",
      "Batch ID: [ 6] [45/50] Imputation Loss: 0.05495849\n",
      "Batch ID: [ 6] [50/50] Imputation Loss: -1.39220476\n",
      "Batch ID: [ 7] [ 5/50] Imputation Loss: 14.81180000\n",
      "Batch ID: [ 7] [10/50] Imputation Loss: 6.47241020\n",
      "Batch ID: [ 7] [15/50] Imputation Loss: 3.18023968\n",
      "Batch ID: [ 7] [20/50] Imputation Loss: 1.66508043\n",
      "Batch ID: [ 7] [25/50] Imputation Loss: 1.34607458\n",
      "Batch ID: [ 7] [30/50] Imputation Loss: -0.06505113\n",
      "Batch ID: [ 7] [35/50] Imputation Loss: -0.59432107\n",
      "Batch ID: [ 7] [40/50] Imputation Loss: -0.82066816\n",
      "Batch ID: [ 7] [45/50] Imputation Loss: -1.56664073\n",
      "Batch ID: [ 7] [50/50] Imputation Loss: -1.23084676\n",
      "Batch ID: [ 8] [ 5/50] Imputation Loss: 13.95831203\n",
      "Batch ID: [ 8] [10/50] Imputation Loss: 6.68401003\n",
      "Batch ID: [ 8] [15/50] Imputation Loss: 3.15144420\n",
      "Batch ID: [ 8] [20/50] Imputation Loss: 2.03806853\n",
      "Batch ID: [ 8] [25/50] Imputation Loss: 0.32082012\n",
      "Batch ID: [ 8] [30/50] Imputation Loss: -0.22665104\n",
      "Batch ID: [ 8] [35/50] Imputation Loss: 0.26152641\n",
      "Batch ID: [ 8] [40/50] Imputation Loss: -1.21131206\n",
      "Batch ID: [ 8] [45/50] Imputation Loss: -1.90681195\n",
      "Batch ID: [ 8] [50/50] Imputation Loss: -1.96886921\n",
      "Batch ID: [ 9] [ 5/50] Imputation Loss: 13.66682816\n",
      "Batch ID: [ 9] [10/50] Imputation Loss: 5.84239388\n",
      "Batch ID: [ 9] [15/50] Imputation Loss: 2.36387992\n",
      "Batch ID: [ 9] [20/50] Imputation Loss: 2.03271866\n",
      "Batch ID: [ 9] [25/50] Imputation Loss: 0.64876533\n",
      "Batch ID: [ 9] [30/50] Imputation Loss: -0.42522985\n",
      "Batch ID: [ 9] [35/50] Imputation Loss: -0.81658298\n",
      "Batch ID: [ 9] [40/50] Imputation Loss: -1.22414243\n",
      "Batch ID: [ 9] [45/50] Imputation Loss: -1.48845148\n",
      "Batch ID: [ 9] [50/50] Imputation Loss: -1.81357062\n",
      "Batch ID: [10] [ 5/50] Imputation Loss: 14.08939362\n",
      "Batch ID: [10] [10/50] Imputation Loss: 6.57325125\n",
      "Batch ID: [10] [15/50] Imputation Loss: 3.51593018\n",
      "Batch ID: [10] [20/50] Imputation Loss: 1.47108877\n",
      "Batch ID: [10] [25/50] Imputation Loss: 0.38300714\n",
      "Batch ID: [10] [30/50] Imputation Loss: -0.06391995\n",
      "Batch ID: [10] [35/50] Imputation Loss: -0.01712208\n",
      "Batch ID: [10] [40/50] Imputation Loss: -0.91645026\n",
      "Batch ID: [10] [45/50] Imputation Loss: -1.09448838\n",
      "Batch ID: [10] [50/50] Imputation Loss: -1.25589657\n",
      "Batch ID: [11] [ 5/50] Imputation Loss: 13.80894470\n",
      "Batch ID: [11] [10/50] Imputation Loss: 6.85183191\n",
      "Batch ID: [11] [15/50] Imputation Loss: 3.35994816\n",
      "Batch ID: [11] [20/50] Imputation Loss: 1.31714296\n",
      "Batch ID: [11] [25/50] Imputation Loss: 1.23662174\n",
      "Batch ID: [11] [30/50] Imputation Loss: 0.63276052\n",
      "Batch ID: [11] [35/50] Imputation Loss: -0.34521720\n",
      "Batch ID: [11] [40/50] Imputation Loss: -0.57924455\n",
      "Batch ID: [11] [45/50] Imputation Loss: -0.82728684\n",
      "Batch ID: [11] [50/50] Imputation Loss: -1.62978518\n",
      "Batch ID: [12] [ 5/50] Imputation Loss: 13.90835953\n",
      "Batch ID: [12] [10/50] Imputation Loss: 7.23923969\n",
      "Batch ID: [12] [15/50] Imputation Loss: 3.93432903\n",
      "Batch ID: [12] [20/50] Imputation Loss: 2.05724478\n",
      "Batch ID: [12] [25/50] Imputation Loss: 1.39009476\n",
      "Batch ID: [12] [30/50] Imputation Loss: 1.13391984\n",
      "Batch ID: [12] [35/50] Imputation Loss: -0.36699760\n",
      "Batch ID: [12] [40/50] Imputation Loss: 0.31319711\n",
      "Batch ID: [12] [45/50] Imputation Loss: -0.71189433\n",
      "Batch ID: [12] [50/50] Imputation Loss: -1.52590704\n",
      "Batch ID: [13] [ 5/50] Imputation Loss: 14.47270489\n",
      "Batch ID: [13] [10/50] Imputation Loss: 6.65637398\n",
      "Batch ID: [13] [15/50] Imputation Loss: 2.94886923\n",
      "Batch ID: [13] [20/50] Imputation Loss: 1.13649881\n",
      "Batch ID: [13] [25/50] Imputation Loss: 0.81590199\n",
      "Batch ID: [13] [30/50] Imputation Loss: 0.36371726\n",
      "Batch ID: [13] [35/50] Imputation Loss: -0.45546073\n",
      "Batch ID: [13] [40/50] Imputation Loss: -0.06601458\n",
      "Batch ID: [13] [45/50] Imputation Loss: -1.54944861\n",
      "Batch ID: [13] [50/50] Imputation Loss: -1.22708559\n",
      "Batch ID: [14] [ 5/50] Imputation Loss: 13.86578178\n",
      "Batch ID: [14] [10/50] Imputation Loss: 6.85000229\n",
      "Batch ID: [14] [15/50] Imputation Loss: 2.44758773\n",
      "Batch ID: [14] [20/50] Imputation Loss: 1.60860503\n",
      "Batch ID: [14] [25/50] Imputation Loss: 0.22414990\n",
      "Batch ID: [14] [30/50] Imputation Loss: 0.67809504\n",
      "Batch ID: [14] [35/50] Imputation Loss: -0.38250268\n",
      "Batch ID: [14] [40/50] Imputation Loss: -0.59782845\n",
      "Batch ID: [14] [45/50] Imputation Loss: -1.39091873\n",
      "Batch ID: [14] [50/50] Imputation Loss: -1.45941949\n",
      "Batch ID: [15] [ 5/50] Imputation Loss: 14.52155304\n",
      "Batch ID: [15] [10/50] Imputation Loss: 6.30549479\n",
      "Batch ID: [15] [15/50] Imputation Loss: 3.03391838\n",
      "Batch ID: [15] [20/50] Imputation Loss: 1.35295188\n",
      "Batch ID: [15] [25/50] Imputation Loss: 1.39240861\n",
      "Batch ID: [15] [30/50] Imputation Loss: 0.75758898\n",
      "Batch ID: [15] [35/50] Imputation Loss: -0.71322173\n",
      "Batch ID: [15] [40/50] Imputation Loss: 0.42863989\n",
      "Batch ID: [15] [45/50] Imputation Loss: -1.08566070\n",
      "Batch ID: [15] [50/50] Imputation Loss: -1.14717507\n",
      "Batch ID: [16] [ 5/50] Imputation Loss: 13.58626270\n",
      "Batch ID: [16] [10/50] Imputation Loss: 6.92637491\n",
      "Batch ID: [16] [15/50] Imputation Loss: 3.21253252\n",
      "Batch ID: [16] [20/50] Imputation Loss: 2.21626878\n",
      "Batch ID: [16] [25/50] Imputation Loss: 0.68098092\n",
      "Batch ID: [16] [30/50] Imputation Loss: 0.38942015\n",
      "Batch ID: [16] [35/50] Imputation Loss: 0.76208907\n",
      "Batch ID: [16] [40/50] Imputation Loss: 0.12767634\n",
      "Batch ID: [16] [45/50] Imputation Loss: -0.55095232\n",
      "Batch ID: [16] [50/50] Imputation Loss: -1.45584774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: [17] [ 5/50] Imputation Loss: 14.83633900\n",
      "Batch ID: [17] [10/50] Imputation Loss: 6.69341326\n",
      "Batch ID: [17] [15/50] Imputation Loss: 4.02208519\n",
      "Batch ID: [17] [20/50] Imputation Loss: 1.99319696\n",
      "Batch ID: [17] [25/50] Imputation Loss: 1.53960979\n",
      "Batch ID: [17] [30/50] Imputation Loss: 0.21147019\n",
      "Batch ID: [17] [35/50] Imputation Loss: 0.72578216\n",
      "Batch ID: [17] [40/50] Imputation Loss: -0.89246786\n",
      "Batch ID: [17] [45/50] Imputation Loss: -0.85776055\n",
      "Batch ID: [17] [50/50] Imputation Loss: -0.93940181\n",
      "Batch ID: [18] [ 5/50] Imputation Loss: 14.12462330\n",
      "Batch ID: [18] [10/50] Imputation Loss: 6.39558125\n",
      "Batch ID: [18] [15/50] Imputation Loss: 3.34516835\n",
      "Batch ID: [18] [20/50] Imputation Loss: 2.32554054\n",
      "Batch ID: [18] [25/50] Imputation Loss: 0.85587901\n",
      "Batch ID: [18] [30/50] Imputation Loss: 0.65858197\n",
      "Batch ID: [18] [35/50] Imputation Loss: -0.02751294\n",
      "Batch ID: [18] [40/50] Imputation Loss: -1.31867886\n",
      "Batch ID: [18] [45/50] Imputation Loss: -0.95203859\n",
      "Batch ID: [18] [50/50] Imputation Loss: -0.76663262\n",
      "Batch ID: [19] [ 5/50] Imputation Loss: 14.48578358\n",
      "Batch ID: [19] [10/50] Imputation Loss: 7.14285517\n",
      "Batch ID: [19] [15/50] Imputation Loss: 3.95909905\n",
      "Batch ID: [19] [20/50] Imputation Loss: 1.97829926\n",
      "Batch ID: [19] [25/50] Imputation Loss: 0.80951649\n",
      "Batch ID: [19] [30/50] Imputation Loss: 0.83008844\n",
      "Batch ID: [19] [35/50] Imputation Loss: -1.38572049\n",
      "Batch ID: [19] [40/50] Imputation Loss: -0.88453954\n",
      "Batch ID: [19] [45/50] Imputation Loss: -0.44330782\n",
      "Batch ID: [19] [50/50] Imputation Loss: -1.02897346\n",
      "Batch ID: [20] [ 5/50] Imputation Loss: 14.54430866\n",
      "Batch ID: [20] [10/50] Imputation Loss: 6.70533466\n",
      "Batch ID: [20] [15/50] Imputation Loss: 3.24104071\n",
      "Batch ID: [20] [20/50] Imputation Loss: 1.80766582\n",
      "Batch ID: [20] [25/50] Imputation Loss: 1.26320028\n",
      "Batch ID: [20] [30/50] Imputation Loss: -0.02241857\n",
      "Batch ID: [20] [35/50] Imputation Loss: -1.38342929\n",
      "Batch ID: [20] [40/50] Imputation Loss: -0.47742641\n",
      "Batch ID: [20] [45/50] Imputation Loss: -1.63645554\n",
      "Batch ID: [20] [50/50] Imputation Loss: -1.97463167\n",
      "Batch ID: [21] [ 5/50] Imputation Loss: 14.15350914\n",
      "Batch ID: [21] [10/50] Imputation Loss: 6.59725046\n",
      "Batch ID: [21] [15/50] Imputation Loss: 3.09703588\n",
      "Batch ID: [21] [20/50] Imputation Loss: 1.14455116\n",
      "Batch ID: [21] [25/50] Imputation Loss: 1.15506697\n",
      "Batch ID: [21] [30/50] Imputation Loss: 1.28176117\n",
      "Batch ID: [21] [35/50] Imputation Loss: 0.03826977\n",
      "Batch ID: [21] [40/50] Imputation Loss: -0.35414958\n",
      "Batch ID: [21] [45/50] Imputation Loss: -0.60454977\n",
      "Batch ID: [21] [50/50] Imputation Loss: -1.03428531\n",
      "Batch ID: [22] [ 5/50] Imputation Loss: 14.11390305\n",
      "Batch ID: [22] [10/50] Imputation Loss: 6.39962292\n",
      "Batch ID: [22] [15/50] Imputation Loss: 2.93645644\n",
      "Batch ID: [22] [20/50] Imputation Loss: 1.63244069\n",
      "Batch ID: [22] [25/50] Imputation Loss: 1.37223315\n",
      "Batch ID: [22] [30/50] Imputation Loss: -0.12363587\n",
      "Batch ID: [22] [35/50] Imputation Loss: -0.09383352\n",
      "Batch ID: [22] [40/50] Imputation Loss: -0.82412612\n",
      "Batch ID: [22] [45/50] Imputation Loss: -0.98768049\n",
      "Batch ID: [22] [50/50] Imputation Loss: -1.35187781\n",
      "Batch ID: [23] [ 5/50] Imputation Loss: 14.37247467\n",
      "Batch ID: [23] [10/50] Imputation Loss: 7.02713919\n",
      "Batch ID: [23] [15/50] Imputation Loss: 3.45456576\n",
      "Batch ID: [23] [20/50] Imputation Loss: 2.59360075\n",
      "Batch ID: [23] [25/50] Imputation Loss: 0.93650728\n",
      "Batch ID: [23] [30/50] Imputation Loss: 0.55267727\n",
      "Batch ID: [23] [35/50] Imputation Loss: -0.23465228\n",
      "Batch ID: [23] [40/50] Imputation Loss: -0.70033115\n",
      "Batch ID: [23] [45/50] Imputation Loss: -0.20995831\n",
      "Batch ID: [23] [50/50] Imputation Loss: -0.15677118\n",
      "Batch ID: [24] [ 5/50] Imputation Loss: 13.64997101\n",
      "Batch ID: [24] [10/50] Imputation Loss: 6.76938534\n",
      "Batch ID: [24] [15/50] Imputation Loss: 3.16996050\n",
      "Batch ID: [24] [20/50] Imputation Loss: 1.62269545\n",
      "Batch ID: [24] [25/50] Imputation Loss: 0.92686474\n",
      "Batch ID: [24] [30/50] Imputation Loss: 1.49150741\n",
      "Batch ID: [24] [35/50] Imputation Loss: 0.40292811\n",
      "Batch ID: [24] [40/50] Imputation Loss: -1.17945719\n",
      "Batch ID: [24] [45/50] Imputation Loss: -0.76849800\n",
      "Batch ID: [24] [50/50] Imputation Loss: -1.67581189\n",
      "Batch ID: [25] [ 5/50] Imputation Loss: 14.01554775\n",
      "Batch ID: [25] [10/50] Imputation Loss: 6.15631819\n",
      "Batch ID: [25] [15/50] Imputation Loss: 3.40494752\n",
      "Batch ID: [25] [20/50] Imputation Loss: 0.94810349\n",
      "Batch ID: [25] [25/50] Imputation Loss: 1.50542462\n",
      "Batch ID: [25] [30/50] Imputation Loss: -0.66003287\n",
      "Batch ID: [25] [35/50] Imputation Loss: -0.26782930\n",
      "Batch ID: [25] [40/50] Imputation Loss: -1.04521430\n",
      "Batch ID: [25] [45/50] Imputation Loss: -1.82063735\n",
      "Batch ID: [25] [50/50] Imputation Loss: -1.90444255\n",
      "Batch ID: [26] [ 5/50] Imputation Loss: 13.59228706\n",
      "Batch ID: [26] [10/50] Imputation Loss: 6.63087177\n",
      "Batch ID: [26] [15/50] Imputation Loss: 3.13766766\n",
      "Batch ID: [26] [20/50] Imputation Loss: 1.54108500\n",
      "Batch ID: [26] [25/50] Imputation Loss: 0.56272066\n",
      "Batch ID: [26] [30/50] Imputation Loss: 0.12687352\n",
      "Batch ID: [26] [35/50] Imputation Loss: -0.41906092\n",
      "Batch ID: [26] [40/50] Imputation Loss: -1.11231780\n",
      "Batch ID: [26] [45/50] Imputation Loss: -1.33024800\n",
      "Batch ID: [26] [50/50] Imputation Loss: -0.93956435\n",
      "Batch ID: [27] [ 5/50] Imputation Loss: 13.88442135\n",
      "Batch ID: [27] [10/50] Imputation Loss: 6.76165199\n",
      "Batch ID: [27] [15/50] Imputation Loss: 3.61662459\n",
      "Batch ID: [27] [20/50] Imputation Loss: 1.77628422\n",
      "Batch ID: [27] [25/50] Imputation Loss: 0.85136545\n",
      "Batch ID: [27] [30/50] Imputation Loss: 0.78018653\n",
      "Batch ID: [27] [35/50] Imputation Loss: 0.09010416\n",
      "Batch ID: [27] [40/50] Imputation Loss: -0.05612098\n",
      "Batch ID: [27] [45/50] Imputation Loss: -0.30106175\n",
      "Batch ID: [27] [50/50] Imputation Loss: -0.54911208\n",
      "Batch ID: [28] [ 5/50] Imputation Loss: 14.43652153\n",
      "Batch ID: [28] [10/50] Imputation Loss: 7.06340742\n",
      "Batch ID: [28] [15/50] Imputation Loss: 3.40691686\n",
      "Batch ID: [28] [20/50] Imputation Loss: 2.56432271\n",
      "Batch ID: [28] [25/50] Imputation Loss: 1.58204103\n",
      "Batch ID: [28] [30/50] Imputation Loss: 0.55908918\n",
      "Batch ID: [28] [35/50] Imputation Loss: 0.46912858\n",
      "Batch ID: [28] [40/50] Imputation Loss: -0.40627819\n",
      "Batch ID: [28] [45/50] Imputation Loss: -0.66529608\n",
      "Batch ID: [28] [50/50] Imputation Loss: -0.33487332\n",
      "Batch ID: [29] [ 5/50] Imputation Loss: 14.48007584\n",
      "Batch ID: [29] [10/50] Imputation Loss: 6.98780012\n",
      "Batch ID: [29] [15/50] Imputation Loss: 4.30609274\n",
      "Batch ID: [29] [20/50] Imputation Loss: 2.07453918\n",
      "Batch ID: [29] [25/50] Imputation Loss: 1.46097624\n",
      "Batch ID: [29] [30/50] Imputation Loss: -0.22883759\n",
      "Batch ID: [29] [35/50] Imputation Loss: -0.25507396\n",
      "Batch ID: [29] [40/50] Imputation Loss: 0.00916759\n",
      "Batch ID: [29] [45/50] Imputation Loss: -0.85433185\n",
      "Batch ID: [29] [50/50] Imputation Loss: -1.65781379\n",
      "Batch ID: [30] [ 5/50] Imputation Loss: 14.34071255\n",
      "Batch ID: [30] [10/50] Imputation Loss: 6.68034029\n",
      "Batch ID: [30] [15/50] Imputation Loss: 3.41211867\n",
      "Batch ID: [30] [20/50] Imputation Loss: 1.12213528\n",
      "Batch ID: [30] [25/50] Imputation Loss: 0.26208088\n",
      "Batch ID: [30] [30/50] Imputation Loss: 0.70475900\n",
      "Batch ID: [30] [35/50] Imputation Loss: -0.08134350\n",
      "Batch ID: [30] [40/50] Imputation Loss: -0.70871782\n",
      "Batch ID: [30] [45/50] Imputation Loss: -1.39465213\n",
      "Batch ID: [30] [50/50] Imputation Loss: -0.81555247\n",
      "Batch ID: [31] [ 5/50] Imputation Loss: 14.34397316\n",
      "Batch ID: [31] [10/50] Imputation Loss: 7.43273306\n",
      "Batch ID: [31] [15/50] Imputation Loss: 3.37730026\n",
      "Batch ID: [31] [20/50] Imputation Loss: 2.85410380\n",
      "Batch ID: [31] [25/50] Imputation Loss: 1.08571374\n",
      "Batch ID: [31] [30/50] Imputation Loss: 0.94394732\n",
      "Batch ID: [31] [35/50] Imputation Loss: 0.36461911\n",
      "Batch ID: [31] [40/50] Imputation Loss: 0.24902412\n",
      "Batch ID: [31] [45/50] Imputation Loss: -0.62075067\n",
      "Batch ID: [31] [50/50] Imputation Loss: -1.04658425\n",
      "Batch ID: [32] [ 5/50] Imputation Loss: 14.23214436\n",
      "Batch ID: [32] [10/50] Imputation Loss: 6.67250776\n",
      "Batch ID: [32] [15/50] Imputation Loss: 3.54348016\n",
      "Batch ID: [32] [20/50] Imputation Loss: 2.20333910\n",
      "Batch ID: [32] [25/50] Imputation Loss: 1.95051432\n",
      "Batch ID: [32] [30/50] Imputation Loss: 0.87389892\n",
      "Batch ID: [32] [35/50] Imputation Loss: -1.15235734\n",
      "Batch ID: [32] [40/50] Imputation Loss: -0.58201444\n",
      "Batch ID: [32] [45/50] Imputation Loss: -1.61190057\n",
      "Batch ID: [32] [50/50] Imputation Loss: -2.23825240\n"
     ]
    }
   ],
   "source": [
    "imputation(generator, discriminator, X_val, val_mask_mat, 64, 128, 0.1, 5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e82e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0f72ddf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('W_fc',\n",
       "              tensor([[ 2.0291e-05, -2.0713e-05,  2.2791e-05,  ...,  3.2886e-05,\n",
       "                       -1.4263e-05,  5.0891e-05],\n",
       "                      [ 1.6621e-05,  1.0936e-05, -1.3899e-04,  ..., -4.6635e-05,\n",
       "                       -5.6700e-05, -3.7246e-06],\n",
       "                      [-1.7414e-04,  4.7840e-05,  4.9730e-05,  ..., -2.9710e-04,\n",
       "                       -7.0029e-05,  1.4733e-04],\n",
       "                      ...,\n",
       "                      [ 1.5519e-04,  2.2104e-04, -7.2388e-05,  ..., -1.0975e-04,\n",
       "                       -5.4459e-05,  1.0716e-04],\n",
       "                      [-1.2450e-04,  1.6016e-04,  1.0652e-04,  ...,  5.1830e-06,\n",
       "                       -2.0737e-05,  1.5034e-05],\n",
       "                      [ 7.8309e-05,  5.5059e-05,  4.5348e-05,  ..., -9.2336e-05,\n",
       "                        8.0715e-05,  3.3145e-05]])),\n",
       "             ('b_fc',\n",
       "              tensor([ 6.1708e-01, -2.8518e-05,  0.0000e+00,  1.1380e-04,  1.2502e-04,\n",
       "                      -1.4223e-04,  1.0287e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                       0.0000e+00,  0.0000e+00,  5.3123e-02,  0.0000e+00,  3.3825e-02,\n",
       "                       0.0000e+00,  0.0000e+00,  9.9487e-01,  1.3952e-01,  5.3821e-01,\n",
       "                       5.2582e-01,  2.3565e-01,  1.8280e-01,  0.0000e+00,  1.7115e-01,\n",
       "                       0.0000e+00,  7.6864e-01,  2.4778e-01,  3.3947e-01,  3.8257e-01,\n",
       "                       0.0000e+00,  0.0000e+00,  0.0000e+00,  1.9325e-01,  1.7745e-01,\n",
       "                       0.0000e+00,  0.0000e+00,  8.9101e-01,  0.0000e+00,  0.0000e+00,\n",
       "                       1.5202e-02,  5.4751e-02,  0.0000e+00])),\n",
       "             ('grui_model.gruicell.W_xz',\n",
       "              tensor([[ 2.1322e-05, -5.7650e-05, -1.2352e-04,  ..., -1.3572e-04,\n",
       "                       -4.9168e-05, -2.3255e-06],\n",
       "                      [-2.1334e-04, -9.2403e-05,  9.6319e-05,  ...,  1.4241e-06,\n",
       "                        8.5125e-05, -7.1910e-06],\n",
       "                      [-6.8209e-05,  3.1686e-05,  1.6493e-04,  ..., -1.4266e-04,\n",
       "                       -3.7933e-05,  1.2849e-04],\n",
       "                      ...,\n",
       "                      [ 1.3941e-04, -7.9188e-05,  5.7970e-05,  ...,  1.5760e-05,\n",
       "                        8.3070e-06,  8.9985e-05],\n",
       "                      [ 8.7942e-05, -5.9208e-05, -1.1933e-04,  ...,  7.7360e-05,\n",
       "                        1.4941e-04, -2.4861e-05],\n",
       "                      [-1.6832e-04,  3.4796e-05, -6.1071e-05,  ...,  8.3936e-05,\n",
       "                        1.5881e-04,  1.9881e-05]])),\n",
       "             ('grui_model.gruicell.W_hz',\n",
       "              tensor([[ 1.6198e-04,  1.2010e-04,  1.6299e-04,  ...,  3.2219e-05,\n",
       "                       -8.6539e-05,  1.2050e-05],\n",
       "                      [-7.6685e-06, -8.5553e-05, -1.8349e-05,  ..., -2.5125e-04,\n",
       "                        5.1212e-05,  1.4191e-04],\n",
       "                      [ 5.9504e-05,  2.4596e-05, -4.0342e-05,  ...,  6.1279e-05,\n",
       "                       -1.2526e-04,  4.3570e-05],\n",
       "                      ...,\n",
       "                      [-6.1590e-05,  1.6817e-04, -1.1306e-04,  ..., -8.7036e-05,\n",
       "                       -9.2337e-05, -6.1369e-06],\n",
       "                      [-1.2697e-04, -1.0441e-04,  1.0051e-04,  ...,  9.2171e-05,\n",
       "                        8.2943e-05, -6.4666e-05],\n",
       "                      [ 1.7679e-04, -4.2370e-05,  1.4338e-04,  ..., -6.8007e-05,\n",
       "                       -1.1194e-04,  6.3553e-06]])),\n",
       "             ('grui_model.gruicell.b_z',\n",
       "              tensor([-9.3800e-12, -4.6042e-12,  1.2430e-11,  3.2218e-11, -2.8627e-11,\n",
       "                      -3.4533e-13,  3.1967e-12,  8.9226e-12, -6.9844e-12, -1.1415e-12,\n",
       "                      -6.0319e-12, -3.8574e-11, -2.5455e-12, -1.7446e-12,  3.1497e-11,\n",
       "                       4.6168e-12, -2.0060e-12,  7.3411e-13,  1.6042e-13,  3.0314e-11,\n",
       "                       3.0404e-13, -8.4227e-11, -1.8711e-11,  1.2302e-11, -1.3200e-11,\n",
       "                      -1.5614e-12, -1.4843e-12, -6.0018e-13,  1.1301e-11,  2.0242e-12,\n",
       "                       6.8687e-13,  1.7920e-12,  3.8659e-12, -4.7196e-13, -8.1848e-12,\n",
       "                      -3.8861e-12,  1.2934e-12, -1.7723e-11, -1.6392e-11, -4.3220e-11,\n",
       "                      -5.7133e-12,  2.8629e-12,  6.2323e-12,  3.6533e-14,  5.7245e-12,\n",
       "                       1.4916e-13,  3.2829e-12,  1.1845e-12,  2.9942e-12, -1.2393e-12,\n",
       "                       4.5818e-12, -3.5407e-12, -3.7776e-12, -5.0452e-12, -1.3399e-11,\n",
       "                      -1.0052e-12, -9.9249e-12,  6.1618e-12, -4.3608e-13, -2.4011e-14,\n",
       "                       3.7477e-12, -2.0546e-13, -1.2994e-11, -8.1580e-14])),\n",
       "             ('grui_model.gruicell.W_xr',\n",
       "              tensor([[-1.3635e-05,  2.4739e-05, -6.2010e-05,  ...,  1.9152e-04,\n",
       "                        1.6401e-04, -3.6680e-05],\n",
       "                      [-2.5406e-05,  1.0486e-04,  2.4223e-04,  ...,  1.0071e-04,\n",
       "                        3.2736e-06, -1.1435e-04],\n",
       "                      [-1.8328e-05,  4.2789e-05,  2.2855e-05,  ...,  6.9584e-05,\n",
       "                        4.7243e-05,  9.1362e-05],\n",
       "                      ...,\n",
       "                      [-2.0143e-04,  3.3609e-05, -1.7024e-05,  ..., -3.2479e-05,\n",
       "                        1.0929e-04, -1.4597e-04],\n",
       "                      [-1.7104e-05,  1.2480e-04, -5.6285e-05,  ...,  2.7002e-04,\n",
       "                       -2.1353e-05,  1.2180e-04],\n",
       "                      [-7.0846e-05, -5.2216e-05, -6.6374e-05,  ...,  4.5895e-05,\n",
       "                        1.6622e-05, -4.9915e-06]])),\n",
       "             ('grui_model.gruicell.W_hr',\n",
       "              tensor([[ 1.6787e-05,  2.3664e-04,  2.9720e-04,  ..., -1.2564e-04,\n",
       "                       -2.3687e-05, -8.8738e-05],\n",
       "                      [-5.7832e-05,  9.5022e-05,  8.9615e-05,  ...,  6.9417e-05,\n",
       "                       -1.2146e-04,  1.7340e-04],\n",
       "                      [-3.6135e-05, -6.3144e-05,  1.4724e-05,  ...,  1.0045e-04,\n",
       "                       -1.8364e-04,  6.7233e-05],\n",
       "                      ...,\n",
       "                      [ 5.6981e-06,  1.7973e-04, -3.6693e-05,  ...,  5.4607e-05,\n",
       "                        3.3005e-05,  3.1778e-05],\n",
       "                      [ 5.3420e-05, -1.0160e-04, -1.6937e-05,  ..., -7.3022e-05,\n",
       "                        9.6650e-05,  4.8221e-05],\n",
       "                      [ 1.9632e-04,  1.3737e-04,  7.5899e-05,  ...,  1.9892e-06,\n",
       "                       -3.4254e-05, -7.8958e-05]])),\n",
       "             ('grui_model.gruicell.b_r',\n",
       "              tensor([ 1.0380e-14,  5.4605e-15, -6.7478e-17,  5.8988e-15,  1.3260e-14,\n",
       "                      -2.1601e-16, -1.7134e-16, -3.5565e-16, -9.4556e-16, -4.0333e-15,\n",
       "                      -3.0942e-15, -9.0893e-15, -2.1658e-15, -9.8432e-15, -2.5957e-14,\n",
       "                      -4.9472e-17, -2.7423e-16, -4.5650e-16,  3.8543e-15,  3.4968e-14,\n",
       "                       2.2135e-15,  1.0168e-14, -3.5304e-15,  1.4829e-14, -3.0529e-14,\n",
       "                       2.9227e-16,  3.3363e-15,  1.9409e-16,  9.2107e-15,  2.6975e-15,\n",
       "                       2.4914e-16,  1.4854e-14,  2.7347e-15,  2.0657e-16,  9.3762e-15,\n",
       "                      -4.3546e-15, -2.2249e-16, -2.3392e-14,  4.0651e-16,  3.0842e-16,\n",
       "                      -3.5440e-15,  1.1763e-14, -3.7389e-15, -6.0578e-16,  1.5687e-15,\n",
       "                      -3.5180e-15, -3.2033e-15, -5.7316e-16, -3.9201e-15, -2.8314e-15,\n",
       "                       1.7228e-14,  2.5947e-15,  4.2858e-15,  4.4962e-15,  2.6759e-15,\n",
       "                       1.3209e-16, -1.4013e-14,  1.7877e-14,  8.1274e-16, -3.8331e-15,\n",
       "                       1.2262e-14, -4.5212e-16,  1.2063e-14, -1.5494e-16])),\n",
       "             ('grui_model.gruicell.W_xh',\n",
       "              tensor([[-5.4995e-06, -4.4021e-05, -8.1141e-05,  ...,  1.1061e-04,\n",
       "                        8.6768e-05,  5.8059e-05],\n",
       "                      [-4.8198e-05,  1.2517e-04, -1.2077e-04,  ...,  1.3461e-04,\n",
       "                        7.1541e-05, -3.6416e-05],\n",
       "                      [-1.3377e-04,  5.7201e-06, -7.0391e-05,  ...,  1.5562e-05,\n",
       "                       -1.6631e-05, -7.1212e-05],\n",
       "                      ...,\n",
       "                      [-1.2148e-04,  1.1869e-05, -8.8859e-06,  ...,  1.7352e-04,\n",
       "                       -5.5450e-05,  9.4505e-05],\n",
       "                      [-5.8881e-05, -2.0913e-05, -1.8857e-04,  ...,  4.1086e-05,\n",
       "                       -2.3491e-05,  2.0460e-05],\n",
       "                      [-8.2266e-05, -5.7750e-05, -3.0897e-05,  ...,  1.5527e-04,\n",
       "                        5.0568e-05, -2.0533e-05]])),\n",
       "             ('grui_model.gruicell.W_hh',\n",
       "              tensor([[-8.9133e-05,  1.4621e-04,  9.0606e-05,  ...,  1.9045e-05,\n",
       "                        2.3091e-05,  5.8642e-06],\n",
       "                      [ 4.0331e-06, -2.4073e-05, -1.1204e-04,  ...,  6.6596e-05,\n",
       "                        1.4530e-04,  1.0244e-05],\n",
       "                      [-8.4428e-05,  3.7521e-05,  1.4139e-04,  ...,  9.7693e-06,\n",
       "                       -9.2771e-06,  8.3507e-05],\n",
       "                      ...,\n",
       "                      [ 5.8800e-05,  6.6987e-05, -5.3150e-05,  ...,  2.1629e-05,\n",
       "                        3.2518e-05,  6.4039e-05],\n",
       "                      [-1.3697e-04,  1.6306e-04,  1.6534e-04,  ...,  8.1560e-05,\n",
       "                        5.4211e-05,  7.1460e-05],\n",
       "                      [ 3.2184e-05, -1.2494e-04, -5.2329e-05,  ..., -8.8316e-05,\n",
       "                       -7.3180e-05, -1.0264e-04]])),\n",
       "             ('grui_model.gruicell.b_h',\n",
       "              tensor([ 3.3459e-07,  2.8409e-08, -1.1662e-07, -5.4193e-07,  1.9632e-07,\n",
       "                       2.0402e-07,  2.1743e-07, -1.7808e-07, -6.5444e-08,  1.7152e-08,\n",
       "                      -1.6647e-08,  1.6126e-07, -4.2159e-07, -2.8135e-07, -3.7986e-07,\n",
       "                      -1.6360e-07, -2.1486e-07, -1.7928e-07,  7.5778e-08,  1.3446e-07,\n",
       "                       1.7843e-07,  5.3837e-07,  2.3389e-07, -1.6546e-07,  5.6151e-08,\n",
       "                      -7.4510e-08,  2.4090e-07,  1.8169e-08, -1.8788e-07, -3.6408e-07,\n",
       "                      -2.3776e-08,  8.5612e-08,  3.9404e-08, -6.4451e-08, -2.0262e-07,\n",
       "                       8.3334e-08, -3.5527e-07,  4.9391e-07, -3.7453e-07, -3.6731e-07,\n",
       "                      -2.8009e-07,  1.7732e-07, -5.4644e-07, -4.4211e-09, -9.2234e-08,\n",
       "                       1.9812e-07, -6.9459e-08,  2.3084e-08, -8.1574e-08,  4.7702e-08,\n",
       "                      -1.6121e-07,  1.2659e-07,  2.0016e-08,  3.4491e-08,  4.9828e-07,\n",
       "                       7.1395e-08,  6.2722e-08,  8.8540e-08,  1.8228e-08, -1.6286e-07,\n",
       "                       6.6510e-09, -8.1015e-08, -1.2334e-07,  2.4577e-07])),\n",
       "             ('grui_model.gruicell.W_beta',\n",
       "              tensor([[ 1.4964e-04,  8.5758e-05, -5.5008e-05,  ...,  8.9485e-05,\n",
       "                       -3.9531e-05, -5.3028e-05],\n",
       "                      [-3.7549e-05, -1.2649e-04,  7.9107e-05,  ...,  1.9722e-05,\n",
       "                        1.9288e-04, -6.8121e-05],\n",
       "                      [-1.3736e-05, -6.4531e-05,  2.3160e-05,  ..., -5.4300e-05,\n",
       "                        2.0744e-04, -8.4923e-05],\n",
       "                      ...,\n",
       "                      [ 1.0042e-04, -1.5046e-04, -9.6076e-05,  ..., -1.0812e-04,\n",
       "                       -1.9135e-04, -1.2765e-04],\n",
       "                      [ 6.7345e-05,  1.2348e-04, -2.3067e-04,  ..., -9.4666e-05,\n",
       "                       -1.0642e-04, -1.4806e-05],\n",
       "                      [-5.9239e-05, -2.2441e-04, -2.9283e-04,  ...,  1.2206e-04,\n",
       "                        1.2920e-04,  1.0979e-04]])),\n",
       "             ('grui_model.gruicell.b_beta',\n",
       "              tensor([ 0.0000e+00,  0.0000e+00, -5.5875e-12, -2.9965e-12,  3.0201e-11,\n",
       "                       0.0000e+00, -1.7825e-12,  0.0000e+00,  2.5116e-12, -1.5563e-12,\n",
       "                      -7.9216e-12, -3.3182e-11,  0.0000e+00,  1.2653e-12, -6.9728e-11,\n",
       "                       0.0000e+00, -6.4497e-13,  0.0000e+00,  1.1206e-11, -2.8586e-11,\n",
       "                       0.0000e+00,  1.2755e-10,  3.9008e-11,  0.0000e+00,  6.6061e-12,\n",
       "                       3.8747e-12, -1.2925e-12, -3.8018e-13,  0.0000e+00, -8.5846e-12,\n",
       "                      -8.6394e-13, -1.3909e-12,  3.1321e-12,  3.7053e-13,  0.0000e+00,\n",
       "                       0.0000e+00,  0.0000e+00,  0.0000e+00,  8.8552e-11,  7.8072e-12,\n",
       "                       2.6553e-11,  0.0000e+00,  0.0000e+00,  5.2115e-13, -4.0971e-12,\n",
       "                       0.0000e+00,  0.0000e+00,  3.1150e-13,  0.0000e+00, -6.4223e-12,\n",
       "                      -5.6885e-11,  1.2513e-11, -1.0530e-11,  0.0000e+00,  0.0000e+00,\n",
       "                      -4.8855e-12,  1.3341e-11, -2.0992e-11,  1.2288e-12,  0.0000e+00,\n",
       "                       1.2451e-11,  2.2901e-12,  8.2831e-12,  0.0000e+00])),\n",
       "             ('grui_model.gruicell.W_hq',\n",
       "              tensor([[-3.2994e-05,  1.5934e-05, -1.1052e-04,  ..., -9.7328e-05,\n",
       "                        5.1794e-05,  7.0867e-05],\n",
       "                      [-1.0709e-05,  3.0427e-05, -2.0971e-05,  ..., -1.3160e-05,\n",
       "                        4.6137e-05, -2.5417e-04],\n",
       "                      [-2.0600e-04, -1.0835e-04,  1.1263e-05,  ...,  9.7573e-05,\n",
       "                        1.0304e-04,  8.7386e-05],\n",
       "                      ...,\n",
       "                      [-1.0418e-04, -3.9402e-06,  9.6240e-05,  ...,  7.5460e-06,\n",
       "                       -1.0337e-04, -2.8791e-04],\n",
       "                      [ 1.4998e-04,  8.4847e-05, -7.4406e-05,  ...,  1.3751e-04,\n",
       "                       -1.8354e-05,  1.1308e-05],\n",
       "                      [ 9.4627e-05, -1.6945e-05, -4.0729e-05,  ...,  1.8878e-04,\n",
       "                       -2.8894e-05, -9.8996e-05]])),\n",
       "             ('grui_model.gruicell.b_q',\n",
       "              tensor([-1.8556e-04, -5.4759e-05, -5.8255e-04, -4.1248e-05, -1.4446e-04,\n",
       "                      -4.6312e-04, -6.8404e-04,  1.0283e-05, -4.9098e-04,  4.0505e-04,\n",
       "                      -3.6341e-04,  8.5006e-04, -8.5333e-04, -5.5478e-04,  1.0420e-03,\n",
       "                       5.9223e-04,  7.8261e-04,  4.3363e-04,  6.0605e-05,  3.3618e-04,\n",
       "                       9.0231e-05, -1.9386e-04,  5.4177e-04,  2.4028e-04, -1.2545e-04,\n",
       "                      -2.3369e-04, -5.7877e-04, -4.9177e-04, -2.4597e-04, -1.4580e-04,\n",
       "                       6.8511e-04,  1.3104e-05,  3.9761e-04,  1.2751e-04, -6.8205e-04,\n",
       "                       1.6732e-04,  7.7700e-05,  6.4660e-04, -5.4629e-04,  3.7061e-05,\n",
       "                      -9.5710e-05,  3.0181e-04,  4.5701e-04,  1.1746e-04,  4.9066e-05,\n",
       "                      -2.6413e-04, -7.6321e-06, -6.5816e-05, -1.3964e-04, -2.9402e-04,\n",
       "                      -7.9741e-04, -1.5215e-04, -1.0845e-04,  7.9579e-05, -4.5288e-04,\n",
       "                      -2.3211e-05, -2.3947e-04, -2.0340e-05, -5.9570e-04, -1.0588e-04,\n",
       "                       3.5741e-04, -1.8707e-05, -2.3878e-04,  4.5614e-04]))])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "02d5b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [   1/  32] pretrain_loss: 10.27311802\n",
      "Epoch: [ 1] [   2/  32] pretrain_loss: 9.66712379\n",
      "Epoch: [ 1] [   3/  32] pretrain_loss: 9.06840038\n",
      "Epoch: [ 1] [   4/  32] pretrain_loss: 8.47798061\n",
      "Epoch: [ 1] [   5/  32] pretrain_loss: 7.92711306\n",
      "Epoch: [ 1] [   6/  32] pretrain_loss: 7.32745314\n",
      "Epoch: [ 1] [   7/  32] pretrain_loss: 6.77063084\n",
      "Epoch: [ 1] [   8/  32] pretrain_loss: 6.22888565\n",
      "Epoch: [ 1] [   9/  32] pretrain_loss: 5.70473194\n",
      "Epoch: [ 1] [  10/  32] pretrain_loss: 5.20105457\n",
      "Epoch: [ 1] [  11/  32] pretrain_loss: 4.72102547\n",
      "Epoch: [ 1] [  12/  32] pretrain_loss: 4.26782799\n",
      "Epoch: [ 1] [  13/  32] pretrain_loss: 3.84420991\n",
      "Epoch: [ 1] [  14/  32] pretrain_loss: 3.53320193\n",
      "Epoch: [ 1] [  15/  32] pretrain_loss: 3.08936334\n",
      "Epoch: [ 1] [  16/  32] pretrain_loss: 2.84161854\n",
      "Epoch: [ 1] [  17/  32] pretrain_loss: 2.44299221\n",
      "Epoch: [ 1] [  18/  32] pretrain_loss: 2.15234733\n",
      "Epoch: [ 1] [  19/  32] pretrain_loss: 1.95744276\n",
      "Epoch: [ 1] [  20/  32] pretrain_loss: 1.71622384\n",
      "Epoch: [ 1] [  21/  32] pretrain_loss: 1.43054545\n",
      "Epoch: [ 1] [  22/  32] pretrain_loss: 1.25654709\n",
      "Epoch: [ 1] [  23/  32] pretrain_loss: 1.11248147\n",
      "Epoch: [ 1] [  24/  32] pretrain_loss: 0.98279262\n",
      "Epoch: [ 1] [  25/  32] pretrain_loss: 0.86361843\n",
      "Epoch: [ 1] [  26/  32] pretrain_loss: 0.87363958\n",
      "Epoch: [ 1] [  27/  32] pretrain_loss: 0.80992711\n",
      "Epoch: [ 1] [  28/  32] pretrain_loss: 0.73847246\n",
      "Epoch: [ 1] [  29/  32] pretrain_loss: 0.85215187\n",
      "Epoch: [ 1] [  30/  32] pretrain_loss: 0.69967902\n",
      "Epoch: [ 1] [  31/  32] pretrain_loss: 0.71464050\n",
      "Epoch: [ 1] [  32/  32] pretrain_loss: 0.67168361\n",
      "Epoch: [ 2] [   1/  32] pretrain_loss: 0.68756586\n",
      "Epoch: [ 2] [   2/  32] pretrain_loss: 0.65147567\n",
      "Epoch: [ 2] [   3/  32] pretrain_loss: 0.66849548\n",
      "Epoch: [ 2] [   4/  32] pretrain_loss: 0.63701606\n",
      "Epoch: [ 2] [   5/  32] pretrain_loss: 0.65505612\n",
      "Epoch: [ 2] [   6/  32] pretrain_loss: 0.62673110\n",
      "Epoch: [ 2] [   7/  32] pretrain_loss: 0.64559078\n",
      "Epoch: [ 2] [   8/  32] pretrain_loss: 0.61944526\n",
      "Epoch: [ 2] [   9/  32] pretrain_loss: 0.63892859\n",
      "Epoch: [ 2] [  10/  32] pretrain_loss: 0.61429763\n",
      "Epoch: [ 2] [  11/  32] pretrain_loss: 0.63424170\n",
      "Epoch: [ 2] [  12/  32] pretrain_loss: 0.61066818\n",
      "Epoch: [ 2] [  13/  32] pretrain_loss: 0.63094640\n",
      "Epoch: [ 2] [  14/  32] pretrain_loss: 0.60811049\n",
      "Epoch: [ 2] [  15/  32] pretrain_loss: 0.62862915\n",
      "Epoch: [ 2] [  16/  32] pretrain_loss: 0.60630983\n",
      "Epoch: [ 2] [  17/  32] pretrain_loss: 0.62699896\n",
      "Epoch: [ 2] [  18/  32] pretrain_loss: 0.60504198\n",
      "Epoch: [ 2] [  19/  32] pretrain_loss: 0.62585336\n",
      "Epoch: [ 2] [  20/  32] pretrain_loss: 0.60414952\n",
      "Epoch: [ 2] [  21/  32] pretrain_loss: 0.62504596\n",
      "Epoch: [ 2] [  22/  32] pretrain_loss: 0.60352242\n",
      "Epoch: [ 2] [  23/  32] pretrain_loss: 0.62447858\n",
      "Epoch: [ 2] [  24/  32] pretrain_loss: 0.60308009\n",
      "Epoch: [ 2] [  25/  32] pretrain_loss: 0.62407827\n",
      "Epoch: [ 2] [  26/  32] pretrain_loss: 0.60276806\n",
      "Epoch: [ 2] [  27/  32] pretrain_loss: 0.62379736\n",
      "Epoch: [ 2] [  28/  32] pretrain_loss: 0.60254860\n",
      "Epoch: [ 2] [  29/  32] pretrain_loss: 0.62359923\n",
      "Epoch: [ 2] [  30/  32] pretrain_loss: 0.60239404\n",
      "Epoch: [ 2] [  31/  32] pretrain_loss: 0.62345934\n",
      "Epoch: [ 2] [  32/  32] pretrain_loss: 0.60228491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('W_fc',\n",
       "              tensor([[ 1.5201e-05, -2.1131e-05,  1.8640e-05,  ...,  2.8007e-05,\n",
       "                        7.0239e-05, -5.8796e-05],\n",
       "                      [ 7.3752e-06,  1.5036e-05,  5.2856e-05,  ..., -4.4628e-05,\n",
       "                        2.4365e-04,  9.2550e-05],\n",
       "                      [-2.4576e-04,  3.6707e-05,  6.5416e-05,  ..., -3.3574e-05,\n",
       "                       -1.0504e-04,  1.0109e-04],\n",
       "                      ...,\n",
       "                      [-2.1998e-04,  4.0912e-05, -8.5859e-05,  ...,  1.8211e-05,\n",
       "                       -1.0557e-04,  1.0375e-04],\n",
       "                      [-1.0855e-04, -1.3562e-04, -2.3607e-05,  ...,  4.6210e-05,\n",
       "                        9.9475e-05,  7.4551e-05],\n",
       "                      [ 4.6493e-05, -2.5215e-05, -1.5866e-04,  ..., -6.6874e-05,\n",
       "                       -4.0098e-05, -2.3900e-04]])),\n",
       "             ('b_fc',\n",
       "              tensor([ 6.0699e-01, -9.8817e-04,  2.6927e-03,  7.7233e-07,  3.6978e-02,\n",
       "                       1.1600e-06,  9.6313e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                       0.0000e+00,  0.0000e+00,  5.2664e-02,  0.0000e+00,  3.3532e-02,\n",
       "                       1.1015e-03,  2.4016e-04,  9.9487e-01,  1.3831e-01,  5.3356e-01,\n",
       "                       5.2531e-01,  2.3565e-01,  1.8122e-01,  0.0000e+00,  1.6967e-01,\n",
       "                       1.3285e-03,  7.6199e-01,  2.4778e-01,  3.3947e-01,  3.8257e-01,\n",
       "                       3.1884e-04,  3.3434e-04,  9.5309e-04,  1.9158e-01,  1.7745e-01,\n",
       "                       6.7482e-04,  2.0140e-03,  8.9101e-01,  0.0000e+00,  0.0000e+00,\n",
       "                       1.5202e-02,  5.4278e-02,  9.1372e-04])),\n",
       "             ('grui_model.gruicell.W_xz',\n",
       "              tensor([[ 2.0098e-05,  1.2416e-04,  1.5450e-04,  ..., -6.8480e-05,\n",
       "                        2.0610e-05, -1.5060e-04],\n",
       "                      [ 1.3225e-04, -2.5598e-04, -1.0425e-04,  ..., -7.1131e-05,\n",
       "                       -5.8555e-05,  1.0702e-04],\n",
       "                      [-5.6541e-05,  7.2048e-05, -1.5543e-05,  ...,  1.5050e-04,\n",
       "                       -5.2495e-05, -1.3801e-04],\n",
       "                      ...,\n",
       "                      [ 5.7445e-05, -2.3659e-04, -2.7257e-05,  ...,  2.5986e-04,\n",
       "                       -6.4306e-06, -1.7944e-05],\n",
       "                      [-2.6815e-05, -2.1851e-09,  1.3970e-04,  ...,  6.8672e-05,\n",
       "                        7.4602e-05,  1.5098e-04],\n",
       "                      [-1.9093e-04,  1.2191e-04,  1.4208e-04,  ...,  7.7135e-05,\n",
       "                       -5.1228e-05, -8.4753e-05]])),\n",
       "             ('grui_model.gruicell.W_hz',\n",
       "              tensor([[ 1.2813e-04, -4.5575e-05, -1.7159e-05,  ..., -1.3369e-05,\n",
       "                       -4.1027e-05,  5.3772e-05],\n",
       "                      [ 9.4222e-05, -1.0665e-04, -6.2770e-05,  ...,  1.2737e-04,\n",
       "                       -3.3619e-05, -3.3872e-06],\n",
       "                      [ 9.4613e-05, -2.3937e-04,  5.9955e-05,  ..., -1.8814e-04,\n",
       "                        6.3590e-06,  1.7505e-04],\n",
       "                      ...,\n",
       "                      [-8.3075e-05,  1.1658e-04, -1.4545e-05,  ..., -1.1408e-04,\n",
       "                       -6.6181e-05, -9.4783e-06],\n",
       "                      [ 1.3175e-04, -1.1663e-05,  1.5605e-04,  ...,  2.5930e-04,\n",
       "                       -9.2609e-06,  1.4523e-05],\n",
       "                      [ 2.1515e-05, -1.9370e-04, -4.8591e-05,  ...,  6.6910e-06,\n",
       "                        2.8540e-06, -5.2945e-06]])),\n",
       "             ('grui_model.gruicell.b_z',\n",
       "              tensor([ 7.3350e-13,  5.2239e-12,  5.2968e-12, -2.5915e-12, -3.7559e-12,\n",
       "                       1.0979e-11, -2.8764e-11,  6.6008e-11,  8.5337e-12, -1.0952e-13,\n",
       "                       3.2872e-12,  2.9357e-12,  4.6394e-12, -3.5203e-12,  7.9120e-13,\n",
       "                       2.7263e-13,  6.1483e-13, -6.9019e-13,  1.1498e-12,  2.6688e-13,\n",
       "                       1.4733e-11, -2.3321e-12,  1.7481e-13,  1.8836e-12, -4.2291e-13,\n",
       "                      -1.6597e-11,  4.0482e-12,  1.2016e-12,  5.2006e-13,  4.2885e-12,\n",
       "                      -3.1065e-12, -7.4541e-13, -4.9799e-12, -1.4642e-13, -5.9180e-12,\n",
       "                       1.4896e-12, -7.7165e-13,  1.8620e-12, -1.0120e-11, -3.2589e-12,\n",
       "                      -6.5295e-12, -7.1662e-12, -4.2814e-12, -1.7543e-12,  2.7731e-11,\n",
       "                      -9.6594e-13, -1.6758e-11,  2.1445e-12,  1.0837e-11,  5.5996e-12,\n",
       "                      -1.1939e-11, -3.8527e-13,  8.3192e-13,  1.8364e-13, -7.8328e-12,\n",
       "                       3.8419e-13, -1.7987e-15, -1.1718e-12,  6.0662e-14,  2.1560e-11,\n",
       "                      -5.3804e-13,  1.2462e-11,  1.3449e-11, -2.8488e-11])),\n",
       "             ('grui_model.gruicell.W_xr',\n",
       "              tensor([[ 4.7853e-05,  8.9081e-05,  2.4319e-05,  ...,  1.0522e-04,\n",
       "                       -6.6290e-05,  1.2388e-05],\n",
       "                      [-1.2113e-04, -7.8766e-05, -1.5682e-04,  ..., -6.4032e-05,\n",
       "                        1.1811e-04,  2.7214e-05],\n",
       "                      [ 8.4423e-05,  1.3610e-04,  4.8220e-05,  ...,  5.0985e-06,\n",
       "                       -7.2118e-05, -2.4105e-05],\n",
       "                      ...,\n",
       "                      [ 4.9078e-05,  4.9855e-05, -7.7101e-06,  ..., -1.8843e-04,\n",
       "                        4.9276e-05, -1.1151e-04],\n",
       "                      [-8.2582e-05,  6.8123e-05,  1.3565e-04,  ...,  6.7105e-05,\n",
       "                        2.9603e-05, -1.5240e-04],\n",
       "                      [ 4.2243e-05,  3.0909e-05, -4.5239e-05,  ..., -2.3787e-05,\n",
       "                       -6.2322e-05,  2.2236e-04]])),\n",
       "             ('grui_model.gruicell.W_hr',\n",
       "              tensor([[-9.6121e-05, -3.5745e-07,  7.4837e-05,  ...,  3.6109e-05,\n",
       "                       -1.6083e-05, -1.2846e-05],\n",
       "                      [ 2.3711e-05,  2.0934e-07,  1.6669e-05,  ...,  6.8572e-05,\n",
       "                       -3.3982e-05,  6.4020e-05],\n",
       "                      [ 4.1512e-05, -2.9699e-04, -2.8112e-06,  ..., -2.6049e-04,\n",
       "                        1.8039e-04, -8.9128e-05],\n",
       "                      ...,\n",
       "                      [ 1.3316e-05,  1.2737e-04,  3.9374e-05,  ...,  3.8053e-05,\n",
       "                        4.5262e-05, -5.8115e-05],\n",
       "                      [-3.9467e-06, -6.3248e-05, -1.3097e-05,  ...,  6.0627e-05,\n",
       "                       -4.7694e-05,  1.5277e-05],\n",
       "                      [ 1.1287e-04,  4.0786e-05,  1.8283e-04,  ...,  2.4174e-05,\n",
       "                       -6.1709e-05,  7.1135e-05]])),\n",
       "             ('grui_model.gruicell.b_r',\n",
       "              tensor([ 4.6744e-16, -2.5084e-15, -2.3865e-15,  2.8345e-16, -3.4745e-15,\n",
       "                       6.5097e-16, -5.3543e-16, -1.4203e-15, -8.7585e-16, -2.0743e-16,\n",
       "                      -8.9870e-18, -5.4781e-16, -1.1178e-14,  3.1655e-15, -1.1309e-15,\n",
       "                      -6.6445e-18,  1.7724e-15,  1.8407e-15, -1.0101e-15, -2.9685e-15,\n",
       "                      -4.7160e-15, -6.9044e-16,  6.0607e-18, -1.0449e-14,  2.4355e-15,\n",
       "                       1.1843e-15, -5.2356e-16, -1.6437e-15, -2.3247e-15, -9.8243e-15,\n",
       "                      -9.0706e-16, -1.2290e-16,  8.8555e-16, -1.9420e-17,  2.8862e-15,\n",
       "                      -1.7410e-15,  2.3751e-15, -3.9530e-15,  1.6127e-15,  5.7922e-15,\n",
       "                      -1.9826e-15, -1.4780e-15,  8.9888e-15,  3.3337e-15, -1.8393e-15,\n",
       "                      -6.8627e-16, -7.7783e-15, -2.0375e-15, -7.5828e-15,  9.2970e-15,\n",
       "                       8.8319e-15,  2.2495e-15,  1.1922e-17,  1.5011e-16, -1.7769e-15,\n",
       "                      -3.7239e-17, -2.9996e-15, -1.4241e-15,  7.2992e-16,  6.7872e-15,\n",
       "                       7.6071e-16,  2.4200e-16, -6.0873e-15, -4.8572e-15])),\n",
       "             ('grui_model.gruicell.W_xh',\n",
       "              tensor([[-1.1142e-04, -2.7395e-05, -1.2482e-04,  ...,  7.5729e-05,\n",
       "                       -3.7468e-05,  6.5821e-05],\n",
       "                      [-1.5458e-04,  1.9361e-04,  1.6789e-04,  ...,  1.3962e-04,\n",
       "                       -4.1457e-05,  1.2056e-04],\n",
       "                      [-1.4263e-05, -5.3453e-05, -1.6123e-04,  ...,  1.5917e-04,\n",
       "                        5.0430e-05,  1.1311e-04],\n",
       "                      ...,\n",
       "                      [-4.0343e-05,  1.0090e-04, -5.0796e-05,  ...,  5.6444e-05,\n",
       "                        2.9671e-04,  1.0103e-04],\n",
       "                      [ 3.2684e-05,  2.3472e-05, -7.4821e-05,  ..., -1.0316e-04,\n",
       "                       -7.4286e-05,  1.2230e-04],\n",
       "                      [-3.6535e-06, -6.8252e-05,  7.5218e-05,  ...,  2.2306e-05,\n",
       "                       -4.9143e-05,  3.2928e-05]])),\n",
       "             ('grui_model.gruicell.W_hh',\n",
       "              tensor([[ 2.0625e-05, -1.3550e-06, -1.1679e-04,  ...,  6.3590e-06,\n",
       "                        4.6080e-05,  1.3643e-04],\n",
       "                      [ 8.2751e-05, -1.1381e-04,  6.3783e-05,  ..., -7.7498e-05,\n",
       "                       -8.7372e-05,  6.6807e-05],\n",
       "                      [-1.1639e-05,  1.4098e-05, -4.0412e-05,  ...,  9.7641e-05,\n",
       "                       -1.0801e-05, -5.5485e-05],\n",
       "                      ...,\n",
       "                      [-2.8372e-05, -1.3018e-04,  4.1821e-05,  ...,  9.4152e-05,\n",
       "                        1.4206e-05, -1.1865e-05],\n",
       "                      [ 6.7281e-05, -5.4871e-05, -3.5549e-06,  ..., -1.1808e-05,\n",
       "                        1.0092e-04, -4.6128e-05],\n",
       "                      [-1.4550e-05, -1.4958e-04, -8.9810e-05,  ...,  2.9174e-04,\n",
       "                        2.1242e-05, -3.2538e-05]])),\n",
       "             ('grui_model.gruicell.b_h',\n",
       "              tensor([ 1.8589e-07, -7.9489e-08,  1.8911e-08,  9.6670e-08,  5.6280e-07,\n",
       "                       2.5653e-07,  1.8305e-07, -3.6700e-07, -2.4650e-07, -2.4514e-07,\n",
       "                      -2.2719e-08, -6.2146e-08, -2.0615e-07, -8.9454e-08,  1.8059e-07,\n",
       "                       9.5841e-08,  5.1886e-07,  4.8780e-08, -2.9671e-07, -3.1710e-07,\n",
       "                       1.9154e-07, -1.3514e-07,  1.6993e-07,  1.8917e-08,  7.9673e-08,\n",
       "                      -3.1090e-07, -7.5254e-08, -2.2614e-08,  3.1887e-08, -2.2742e-07,\n",
       "                      -4.8238e-08,  1.5967e-07,  2.2470e-07,  1.0822e-07,  2.4816e-07,\n",
       "                       4.1017e-08,  1.5593e-07,  1.3367e-07,  3.1735e-07,  2.5338e-07,\n",
       "                       1.5785e-07, -2.2202e-07,  5.1329e-07,  3.7093e-07, -2.2192e-07,\n",
       "                       2.2745e-08, -7.6507e-08, -2.0068e-07,  1.3170e-07,  2.1611e-07,\n",
       "                      -1.7441e-07,  2.1318e-07, -7.2779e-08, -3.3072e-07,  2.1675e-07,\n",
       "                       2.8726e-08, -2.0912e-07,  2.6582e-09,  1.1764e-07,  1.9526e-07,\n",
       "                      -8.0501e-09,  1.8702e-07,  3.4189e-07, -3.0857e-07])),\n",
       "             ('grui_model.gruicell.W_beta',\n",
       "              tensor([[ 1.2868e-04,  3.8599e-05,  6.1870e-05,  ..., -1.9492e-05,\n",
       "                       -8.2833e-05, -8.9438e-05],\n",
       "                      [ 5.8868e-06, -1.9715e-06, -6.4395e-05,  ..., -1.9788e-04,\n",
       "                       -5.7177e-05, -1.1265e-04],\n",
       "                      [-8.1049e-05,  8.2602e-05,  1.7074e-04,  ...,  1.0898e-04,\n",
       "                        1.5076e-04,  1.1167e-04],\n",
       "                      ...,\n",
       "                      [-5.8332e-05, -8.1242e-05,  1.9168e-04,  ...,  2.0396e-04,\n",
       "                        4.2788e-05, -7.3051e-05],\n",
       "                      [ 8.0847e-06,  1.6442e-04,  1.1941e-04,  ..., -1.0303e-04,\n",
       "                        6.8808e-06,  1.1451e-04],\n",
       "                      [ 4.2430e-06,  1.6201e-05,  2.4771e-06,  ..., -1.5787e-04,\n",
       "                        3.0916e-05,  1.0711e-05]])),\n",
       "             ('grui_model.gruicell.b_beta',\n",
       "              tensor([ 0.0000e+00, -1.3110e-11,  1.0045e-11, -7.2379e-13,  1.6713e-14,\n",
       "                      -5.0883e-11,  3.2978e-11, -3.1011e-11,  2.3209e-14, -1.5800e-13,\n",
       "                       7.7890e-12, -1.3334e-13,  0.0000e+00,  1.9199e-11,  0.0000e+00,\n",
       "                       5.1737e-12,  0.0000e+00,  3.2050e-18,  0.0000e+00,  0.0000e+00,\n",
       "                      -1.6336e-11,  1.5925e-12,  0.0000e+00, -4.0596e-13,  1.7973e-11,\n",
       "                       1.3130e-11, -1.8621e-12,  8.4041e-12, -8.4866e-12,  0.0000e+00,\n",
       "                       0.0000e+00,  1.1439e-12,  6.9492e-12,  4.6125e-14, -6.2555e-15,\n",
       "                       0.0000e+00,  1.7523e-11, -2.9510e-11,  2.9722e-11, -3.8243e-14,\n",
       "                       6.4760e-12,  8.1275e-12,  3.9874e-12,  0.0000e+00, -2.2703e-11,\n",
       "                      -1.8815e-12,  6.6464e-12, -6.2608e-11, -7.4463e-12,  2.1143e-12,\n",
       "                       2.1644e-11,  3.1912e-11,  0.0000e+00, -3.3586e-14,  7.6605e-12,\n",
       "                      -1.6288e-13,  0.0000e+00, -1.5252e-12,  0.0000e+00, -1.6089e-11,\n",
       "                      -8.0912e-13, -1.3024e-11, -4.7573e-11,  4.7898e-11])),\n",
       "             ('grui_model.gruicell.W_hq',\n",
       "              tensor([[ 3.4940e-05,  6.3369e-05,  3.8444e-05,  ..., -7.5763e-06,\n",
       "                       -4.0530e-05,  5.7950e-05],\n",
       "                      [-1.7938e-05,  9.4284e-05,  2.5566e-04,  ...,  7.6716e-05,\n",
       "                       -3.2784e-05, -1.5705e-06],\n",
       "                      [-6.7024e-05, -1.2514e-04, -6.8516e-06,  ..., -6.7393e-05,\n",
       "                        1.9394e-05, -2.2856e-05],\n",
       "                      ...,\n",
       "                      [-2.2080e-04, -1.3508e-06, -1.6584e-04,  ...,  4.9690e-05,\n",
       "                        1.5606e-04,  3.8404e-05],\n",
       "                      [-3.3672e-05,  1.5795e-04, -2.1626e-05,  ...,  1.6467e-05,\n",
       "                       -5.2125e-05,  3.1310e-04],\n",
       "                      [-9.0849e-05, -1.4730e-04,  1.7212e-04,  ...,  1.1975e-05,\n",
       "                        2.0297e-05,  8.3851e-05]])),\n",
       "             ('grui_model.gruicell.b_q',\n",
       "              tensor([ 3.5221e-04,  3.8441e-04, -4.0640e-04,  6.8419e-05, -3.5885e-05,\n",
       "                       5.6924e-06, -7.4304e-05, -7.3233e-04,  4.9716e-04,  1.8583e-04,\n",
       "                      -2.8466e-04,  1.7092e-04, -5.9326e-04, -1.0267e-03,  2.1786e-05,\n",
       "                      -2.9279e-04, -7.9444e-05,  7.8070e-04,  8.5554e-05, -2.1850e-04,\n",
       "                      -1.6824e-04, -5.1969e-04,  3.6177e-04, -2.5688e-04, -2.8990e-04,\n",
       "                      -6.6022e-04,  3.2796e-04,  2.6877e-04,  3.3957e-04, -6.0250e-04,\n",
       "                       8.0221e-04, -4.5023e-04,  2.8654e-06, -1.6504e-04,  8.6678e-05,\n",
       "                       2.6730e-04,  3.5342e-05, -4.1405e-04, -6.1003e-05,  3.4626e-04,\n",
       "                      -4.6225e-04,  1.1344e-04, -5.0947e-04, -2.7715e-04, -9.2945e-05,\n",
       "                      -4.5640e-04, -4.6178e-04,  1.4984e-04, -9.5484e-04,  2.2365e-04,\n",
       "                       8.6345e-05, -2.0929e-04, -8.4573e-05, -3.4158e-04, -5.8894e-04,\n",
       "                      -2.4624e-04,  1.5190e-04, -6.0669e-04, -4.6913e-05,  6.5279e-04,\n",
       "                       3.1527e-04, -3.6283e-04, -1.2394e-04, -1.9932e-05]))])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PretrainGenerator(X_train.shape[2], 64, 64, 0.5)\n",
    "pretrain(model, X_train, train_mask_mat, train_delta_mat, 128, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e2d7d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000],\n",
       "        [0.5000]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(X_resampled.shape[2], 64, 64, 60, 64, 0.5)\n",
    "imputed_result, Delta = generator(None, None, 2)\n",
    "\n",
    "discriminator = Discriminator(X_resampled.shape[2], 64, 64, 0.5)\n",
    "real_prob = discriminator(imputed_result, Delta, None)\n",
    "real_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a369d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33436f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 2, 43])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a19d6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.8283e+01, -1.0478e+02, -1.7709e+01,  8.2495e+01, -4.3884e+00],\n",
       "         [-1.2151e+01,  1.3844e+01,  2.1678e+01,  9.0560e+00, -4.6305e+01]],\n",
       "\n",
       "        [[-1.0245e+01,  1.3643e-01,  6.3071e+00,  8.2732e+00,  2.7988e+00],\n",
       "         [ 3.1679e+01, -1.5437e+01, -2.6020e+01, -6.4427e+01, -4.0347e+01]],\n",
       "\n",
       "        [[-1.3189e+01, -1.2936e+01,  4.2751e+01, -1.3718e+02, -7.9695e+01],\n",
       "         [ 5.1605e+01,  7.9189e+01, -3.5383e+01,  3.8415e+01,  1.7778e+01]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 30*torch.randn((3,2,4))\n",
    "b = torch.tensor([])\n",
    "for i in range(a.shape[0]):\n",
    "    b = torch.cat((b,a[i]@torch.randn((4,5))),0)\n",
    "b.view(3,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd57d17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8225,  0.2152, -1.6502, -1.0723],\n",
       "         [ 1.0081,  1.8549,  0.2984, -0.1364]],\n",
       "\n",
       "        [[-0.7153, -0.3975,  0.1183,  1.3032],\n",
       "         [-1.3603,  1.0030, -0.2714, -1.6327]],\n",
       "\n",
       "        [[ 0.4245,  0.1874,  0.1894, -0.5705],\n",
       "         [-1.3413,  0.0165, -0.9891, -0.6424]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((3,2,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86eefb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8225,  0.2152, -1.6502, -1.0723],\n",
       "         [-0.7153, -0.3975,  0.1183,  1.3032],\n",
       "         [ 0.4245,  0.1874,  0.1894, -0.5705]],\n",
       "\n",
       "        [[ 1.0081,  1.8549,  0.2984, -0.1364],\n",
       "         [-1.3603,  1.0030, -0.2714, -1.6327],\n",
       "         [-1.3413,  0.0165, -0.9891, -0.6424]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7384457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1815, -0.5087,  0.1022, -0.0793,  1.6921],\n",
       "         [-0.2830,  1.1934,  0.2826,  0.4353, -0.6111],\n",
       "         [ 0.1957, -1.1001,  1.1122,  0.2993,  1.4969],\n",
       "         [ 1.3750, -0.9169, -0.4234,  0.6335,  0.5345]],\n",
       "\n",
       "        [[ 0.1815, -0.5087,  0.1022, -0.0793,  1.6921],\n",
       "         [-0.2830,  1.1934,  0.2826,  0.4353, -0.6111],\n",
       "         [ 0.1957, -1.1001,  1.1122,  0.2993,  1.4969],\n",
       "         [ 1.3750, -0.9169, -0.4234,  0.6335,  0.5345]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([])\n",
    "torch.cat((a,a),0).view(2,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b210560",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Dropout(p=0.2)\n",
    "input = torch.randn(20, 16)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a46b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.random.random() * (10 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb48467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
