{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeDataMean(scliedData, MaskMat, meanvalue):\n",
    "    imputedata = []\n",
    "    for i in range(len(scliedData)):\n",
    "        a = np.array(scliedData[i])\n",
    "        b = np.array(scliedData[i]) * np.array(MaskMat[i])\n",
    "        e = b.sum(axis=0)\n",
    "        c = np.array(MaskMat[0])\n",
    "        d = c.sum(axis=0)\n",
    "        d[d==0]=1\n",
    "        mean = b.sum(axis=0)/d\n",
    "        for j in range(a.shape[1]):\n",
    "            if np.all(a[:,j] == -1):\n",
    "                a[:,j]= meanvalue[j]\n",
    "            else:\n",
    "                k = a[:,j]\n",
    "                k[k==-1]= e[j]\n",
    "        imputedata.append(a)\n",
    "    return imputedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeDataNearest(sliceData, meanvalue):\n",
    "    imputedata = []\n",
    "    for i in range(len(sliceData)):\n",
    "        a = np.array(sliceData[i])\n",
    "        b = pd.DataFrame(np.array(a))\n",
    "        b = b.replace(-1,np.nan)\n",
    "        c = b.count()\n",
    "        for k in range(a.shape[1]):\n",
    "            if c[k] == 0:\n",
    "                b[k] = meanvalue[k]\n",
    "            if c[k] == 1:\n",
    "                b[k] = b[k].interpolate(method ='ffill',axis=0)\n",
    "                b[k] = b[k].interpolate(method ='bfill',axis=0)\n",
    "        b = b.interpolate(method ='nearest',axis=0,limit_direction ='both')\n",
    "        b = b.interpolate(method ='ffill')\n",
    "        b = b.interpolate(method ='bfill')\n",
    "        b = b.values\n",
    "        imputedata.append(b)\n",
    "    return imputedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeLast(sliceData, meanvalue):\n",
    "    imputedata = []\n",
    "    for i in range(len(sliceData)):\n",
    "        a = np.array(sliceData[i])\n",
    "        for j in range(a.shape[1]):\n",
    "            if np.all(a[:,j] == -1):\n",
    "                a[:,j]= meanvalue[j]\n",
    "        b = pd.DataFrame(np.array(a))\n",
    "        b = b.replace(-1,np.nan)\n",
    "        b = b.interpolate(method ='ffill',axis=0)\n",
    "        b = b.interpolate(method ='bfill',axis=0)\n",
    "        b = b.values\n",
    "        imputedata.append(b)\n",
    "    return imputedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('E:/WashU/Research/ICU/Data/train/X_train_sliced_norm.pkl','rb')\n",
    "X_train_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/y_train.pkl','rb')\n",
    "y_train = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_delta_mat.pkl','rb')\n",
    "train_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_mask_mat.pkl','rb')\n",
    "train_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/val/X_val_sliced_norm.pkl','rb')\n",
    "X_val_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/y_val.pkl','rb')\n",
    "y_val = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/val_delta_mat.pkl','rb')\n",
    "val_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/val_mask_mat.pkl','rb')\n",
    "val_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/test/X_test_sliced_norm.pkl','rb')\n",
    "X_test_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/test/y_test.pkl','rb')\n",
    "y_test = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/test/test_delta_mat.pkl','rb')\n",
    "test_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/test/test_mask_mat.pkl','rb')\n",
    "test_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/mean_norm.pkl','rb')\n",
    "mean = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(imputeDataMean(X_train_sliced, train_mask_mat, mean))\n",
    "X_val = np.array(imputeDataMean(X_val_sliced, val_mask_mat, mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "X_resampled = []\n",
    "y_resampled = []\n",
    "y_one_index = np.argwhere(y_train==1).reshape(-1)\n",
    "for i in np.argwhere(y_train==0).reshape(-1):\n",
    "    X_resampled.append(X_train[i])\n",
    "    y_resampled.append(y_train[i])\n",
    "    sample_index = np.random.randint(0, len(y_one_index)-1)\n",
    "    X_resampled.append(X_train[y_one_index[sample_index]])\n",
    "    y_resampled.append(y_train[y_one_index[sample_index]])\n",
    "X_resampled = np.array(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs):\n",
    "        super(GRUCell, self).__init__()\n",
    "        def normal(shape):\n",
    "            return torch.randn(size=shape)*0.0001\n",
    "        def three():\n",
    "            return (nn.Parameter(normal((num_inputs, num_hiddens))), \n",
    "                    nn.Parameter(normal((num_hiddens, num_hiddens))), \n",
    "                    nn.Parameter(torch.zeros(num_hiddens)))\n",
    "        self.W_xz, self.W_hz, self.b_z = three() # Parameters of update gate\n",
    "        self.W_xr, self.W_hr, self.b_r = three() # Parameters of reset gate\n",
    "        self.W_xh, self.W_hh, self.b_h = three() # Parameters of candidate hidden state\n",
    "        # Parameters of output layer\n",
    "        self.W_hq = nn.Parameter(normal((num_hiddens, num_outputs)))\n",
    "        self.b_q = nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "    def forward(self, X, H):\n",
    "        Z = torch.sigmoid((X @ self.W_xz) + (H @ self.W_hz) + self.b_z)\n",
    "        R = torch.sigmoid((X @ self.W_xr) + (H @ self.W_hr) + self.b_r)\n",
    "        H_tilde = torch.tanh((X @ self.W_xh) + ((R * H) @ self.W_hh) + self.b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        H.detach()\n",
    "        Y = torch.sigmoid(H @ self.W_hq + self.b_q)\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, imputeMethod, scaleMethod, resampleMethod):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.name = 'GRU'\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.grucell = GRUCell(num_inputs, num_hiddens, num_outputs)\n",
    "        self.imputeMethod = imputeMethod\n",
    "        self.scaleMethod = scaleMethod\n",
    "        self.resampleMethod = resampleMethod\n",
    "\n",
    "    def forward(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.num_hiddens)\n",
    "        X = torch.from_numpy(X.transpose(1, 0, 2)).float()\n",
    "        for x in X:\n",
    "            Y, H = self.grucell(x, H)\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru_model(model, X_train, y_train, X_val, y_val, batch_size, lr, num_epoch=25):\n",
    "    train_loss_all, train_acc_all = [], []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    threshold = torch.tensor([0.5])\n",
    "    \n",
    "    train_num = X_train.shape[0]\n",
    "    val_num = X_val.shape[0]\n",
    "    y_train = torch.from_numpy(np.array(y_train)).type(torch.LongTensor)\n",
    "    y_val = torch.from_numpy(np.array(y_val)).type(torch.LongTensor)\n",
    "    \n",
    "    # Compute the AUC of validation set\n",
    "    output, _ = model(X_val, None)\n",
    "    print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"-\" * 40)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        \n",
    "        # training stage\n",
    "        train_loss, train_corrects = 0, 0\n",
    "        test_loss, test_corrects = 0, 0\n",
    "        \n",
    "        for step in range(math.ceil(train_num//batch_size)+1):\n",
    "            if (step+1)*batch_size <= X_train.shape[0]:\n",
    "                X = X_train[int(step*batch_size):int((step+1)*batch_size)]\n",
    "                y = y_train[int(step*batch_size):int((step+1)*batch_size)]\n",
    "            else:\n",
    "                X = X_train[int(step*batch_size):]\n",
    "                y = y_train[int(step*batch_size):]\n",
    "            \n",
    "            output, _ = model(X, None)\n",
    "            y_hat = torch.cat((1-output,output),dim=1)\n",
    "            loss = criterion(y_hat, y)\n",
    "            y_predict = (output > threshold).float() * 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(model, 1)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(y)\n",
    "            train_corrects += torch.sum(y_predict.squeeze() == y)\n",
    "        \n",
    "        # Compute the mean of loss and accuracy for every epoch\n",
    "        train_loss_all.append(train_loss / train_num)\n",
    "        train_acc_all.append(train_corrects.double().item() / train_num)\n",
    "        \n",
    "        print(\"Train Loss: {:.4f} Train Acc{:.4f}\".format(train_loss_all[-1], train_acc_all[-1]))\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            # Compute the AUC of validation set\n",
    "            output, _ = model(X_val, None)\n",
    "            print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "    \n",
    "    # save\n",
    "    torch.save(model.state_dict(), 'E:/WashU/Research/ICU/modelParams/{}_{}_{}_{}_{}_{}_{}_{}.pth'.format(model.imputeMethod, \n",
    "                                                                                                          model.scaleMethod, \n",
    "                                                                                                          model.resampleMethod, \n",
    "                                                                                                          model.name, \n",
    "                                                                                                          model.num_hiddens, \n",
    "                                                                                                          batch_size, \n",
    "                                                                                                          lr, \n",
    "                                                                                                          num_epoch))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Auc: 0.5347\n",
      "----------------------------------------\n",
      "Epoch 1/5\n",
      "Train Loss: 0.6792 Train Acc0.5838\n",
      "----------------------------------------\n",
      "Epoch 2/5\n",
      "Train Loss: 0.6740 Train Acc0.5972\n",
      "----------------------------------------\n",
      "Epoch 3/5\n",
      "Train Loss: 0.6720 Train Acc0.5998\n",
      "----------------------------------------\n",
      "Epoch 4/5\n",
      "Train Loss: 0.6711 Train Acc0.6003\n",
      "----------------------------------------\n",
      "Epoch 5/5\n",
      "Train Loss: 0.6697 Train Acc0.6028\n",
      "Val Auc: 0.6424\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUModel(num_inputs=X_train.shape[2], num_hiddens=512, num_outputs=1, imputeMethod='Mean', scaleMethod='Norm', resampleMethod='RandomBalance').to(device)\n",
    "model = train_gru_model(model, X_resampled, y_resampled, X_val, y_val, batch_size=32, lr=0.1, num_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('E:/WashU/Research/ICU/Data/train/X_train_sliced_norm_GAN.pkl','rb')\n",
    "X_train_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/y_train.pkl','rb')\n",
    "y_train = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_delta_mat.pkl','rb')\n",
    "train_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_mask_mat.pkl','rb')\n",
    "train_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/val/X_val_sliced_norm_GAN.pkl','rb')\n",
    "X_val_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/y_val.pkl','rb')\n",
    "y_val = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/val_delta_mat.pkl','rb')\n",
    "val_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/val/val_mask_mat.pkl','rb')\n",
    "val_mask_mat = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_sliced[:3600])\n",
    "X_val = np.array(X_train_sliced[3600:])\n",
    "train_delta = np.array(train_delta_mat[:3600])\n",
    "val_delta = np.array(train_delta_mat[3600:])\n",
    "Y_train = np.array(y_train[:3600])\n",
    "Y_val = np.array(y_train[3600:])\n",
    "X_resampled = []\n",
    "y_resampled = []\n",
    "delta_resampled = []\n",
    "y_one_index = np.argwhere(Y_train==1).reshape(-1)\n",
    "for i in np.argwhere(Y_train==0).reshape(-1):\n",
    "    X_resampled.append(X_train[i])\n",
    "    y_resampled.append(Y_train[i])\n",
    "    delta_resampled.append(train_delta[i])\n",
    "    sample_index = np.random.randint(0, len(y_one_index)-1)\n",
    "    X_resampled.append(X_train[y_one_index[sample_index]])\n",
    "    y_resampled.append(Y_train[y_one_index[sample_index]])\n",
    "    delta_resampled.append(train_delta[y_one_index[sample_index]])\n",
    "X_resampled = np.array(X_resampled)\n",
    "delta_resampled = np.array(delta_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUICell(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs):\n",
    "        super(GRUICell, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_outputs = num_outputs\n",
    "        def normal(shape):\n",
    "            return torch.randn(size=shape)*0.0001\n",
    "        def three():\n",
    "            return (nn.Parameter(normal((num_inputs, num_hiddens))), \n",
    "                    nn.Parameter(normal((num_hiddens, num_hiddens))), \n",
    "                    nn.Parameter(torch.zeros(num_hiddens)))\n",
    "        self.W_xz, self.W_hz, self.b_z = three() # Parameters of update gate\n",
    "        self.W_xr, self.W_hr, self.b_r = three() # Parameters of reset gate\n",
    "        self.W_xh, self.W_hh, self.b_h = three() # Parameters of candidate hidden state\n",
    "        # Parameters of decay vector\n",
    "        self.W_beta = nn.Parameter(normal((num_inputs, num_hiddens)))\n",
    "        self.b_beta = nn.Parameter(torch.zeros(num_hiddens))\n",
    "        # Parameters of output layer\n",
    "        self.W_hq = nn.Parameter(normal((num_hiddens, num_outputs)))\n",
    "        self.b_q = nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "    def forward(self, X, Delta, H):\n",
    "        beta = torch.exp(torch.minimum(torch.zeros(self.num_hiddens), Delta @ self.W_beta + self.b_beta))\n",
    "        H = beta * H\n",
    "        Z = torch.sigmoid((X @ self.W_xz) + (H @ self.W_hz) + self.b_z)\n",
    "        R = torch.sigmoid((X @ self.W_xr) + (H @ self.W_hr) + self.b_r)\n",
    "        H_tilde = torch.tanh((X @ self.W_xh) + ((R * H) @ self.W_hh) + self.b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        H.detach()\n",
    "        Y = torch.sigmoid(H @ self.W_hq + self.b_q)\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUIModel(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, imputeMethod, scaleMethod, resampleMethod):\n",
    "        super(GRUIModel, self).__init__()\n",
    "        self.name = 'GRUI'\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.gruicell = GRUICell(num_inputs, num_hiddens, num_outputs)\n",
    "        self.imputeMethod = imputeMethod\n",
    "        self.scaleMethod = scaleMethod\n",
    "        self.resampleMethod = resampleMethod\n",
    "\n",
    "    def forward(self, X, Delta, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[1], self.num_hiddens)\n",
    "        for index in range(X.shape[0]):\n",
    "            Y, H = self.gruicell(X[index], Delta[index], H)\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grui_model(model, X_train, y_train, train_delta_mat, X_val, y_val, val_delta_mat, batch_size, lr, num_epoch=25):\n",
    "    train_loss_all, train_acc_all = [], []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    threshold = torch.tensor([0.5])\n",
    "    \n",
    "    train_num = X_train.shape[0]\n",
    "    val_num = X_val.shape[0]\n",
    "    X_train = torch.from_numpy(X_train.transpose(1, 0, 2)).float()\n",
    "    X_val = torch.from_numpy(X_val.transpose(1, 0, 2)).float()\n",
    "    train_delta_mat = torch.from_numpy(train_delta_mat.transpose(1, 0, 2)).float()\n",
    "    val_delta_mat = torch.from_numpy(val_delta_mat.transpose(1, 0, 2)).float()\n",
    "    y_train = torch.from_numpy(np.array(y_train)).type(torch.LongTensor)\n",
    "    y_val = torch.from_numpy(np.array(y_val)).type(torch.LongTensor)\n",
    "    \n",
    "    # Compute the AUC of validation set\n",
    "    output, _ = model(X_val, val_delta_mat, None)\n",
    "    print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"-\" * 40)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        \n",
    "        # training stage\n",
    "        train_loss, train_corrects = 0, 0\n",
    "        test_loss, test_corrects = 0, 0\n",
    "        \n",
    "        for step in range(train_num//batch_size+1):\n",
    "            if (step+1)*batch_size <= train_num:\n",
    "                X = X_train[:, int(step*batch_size):int((step+1)*batch_size), :]\n",
    "                y = y_train[int(step*batch_size):int((step+1)*batch_size)]\n",
    "                Delta = train_delta_mat[:, int(step*batch_size):int((step+1)*batch_size), :]\n",
    "            else:\n",
    "                X = X_train[:, int(step*batch_size):, :]\n",
    "                y = y_train[int(step*batch_size):]\n",
    "                Delta = train_delta_mat[:, int(step*batch_size):, :]\n",
    "            \n",
    "            output, _ = model(X, Delta, None)\n",
    "            y_hat = torch.cat((1-output,output),dim=1)\n",
    "            loss = criterion(y_hat, y)\n",
    "            y_predict = (output > threshold).float() * 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(model, 1)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(y)\n",
    "            train_corrects += torch.sum(y_predict.squeeze() == y)\n",
    "        \n",
    "        # Compute the mean of loss and accuracy for every epoch\n",
    "        train_loss_all.append(train_loss / train_num)\n",
    "        train_acc_all.append(train_corrects.double().item() / train_num)\n",
    "        \n",
    "        print(\"Train Loss: {:.4f} Train Acc{:.4f}\".format(train_loss_all[-1], train_acc_all[-1]))\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            # Compute the AUC of validation set\n",
    "            output, _ = model(X_val, val_delta_mat, None)\n",
    "            print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "    \n",
    "    # save\n",
    "    torch.save(model.state_dict(), 'E:/WashU/Research/ICU/modelParams/{}_{}_{}_{}_{}_{}_{}_{}.pth'.format(model.imputeMethod, \n",
    "                                                                                                          model.scaleMethod, \n",
    "                                                                                                          model.resampleMethod, \n",
    "                                                                                                          model.name, \n",
    "                                                                                                          model.num_hiddens, \n",
    "                                                                                                          batch_size, \n",
    "                                                                                                          lr, \n",
    "                                                                                                          num_epoch))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Auc: 0.5097\n",
      "----------------------------------------\n",
      "Epoch 1/50\n",
      "Train Loss: 0.6931 Train Acc0.6130\n",
      "----------------------------------------\n",
      "Epoch 2/50\n",
      "Train Loss: 0.6931 Train Acc0.6229\n",
      "----------------------------------------\n",
      "Epoch 3/50\n",
      "Train Loss: 0.6931 Train Acc0.5706\n",
      "----------------------------------------\n",
      "Epoch 4/50\n",
      "Train Loss: 0.6930 Train Acc0.5229\n",
      "----------------------------------------\n",
      "Epoch 5/50\n",
      "Train Loss: 0.6928 Train Acc0.5937\n",
      "Val Auc: 0.7122\n",
      "----------------------------------------\n",
      "Epoch 6/50\n",
      "Train Loss: 0.6922 Train Acc0.6202\n",
      "----------------------------------------\n",
      "Epoch 7/50\n",
      "Train Loss: 0.6901 Train Acc0.6255\n",
      "----------------------------------------\n",
      "Epoch 8/50\n",
      "Train Loss: 0.6830 Train Acc0.6391\n",
      "----------------------------------------\n",
      "Epoch 9/50\n",
      "Train Loss: 0.6670 Train Acc0.6473\n",
      "----------------------------------------\n",
      "Epoch 10/50\n",
      "Train Loss: 0.6480 Train Acc0.6508\n",
      "Val Auc: 0.7326\n",
      "----------------------------------------\n",
      "Epoch 11/50\n",
      "Train Loss: 0.6333 Train Acc0.6639\n",
      "----------------------------------------\n",
      "Epoch 12/50\n",
      "Train Loss: 0.6229 Train Acc0.6665\n",
      "----------------------------------------\n",
      "Epoch 13/50\n",
      "Train Loss: 0.6140 Train Acc0.6759\n",
      "----------------------------------------\n",
      "Epoch 14/50\n",
      "Train Loss: 0.6063 Train Acc0.6859\n",
      "----------------------------------------\n",
      "Epoch 15/50\n",
      "Train Loss: 0.6002 Train Acc0.6944\n",
      "Val Auc: 0.7828\n",
      "----------------------------------------\n",
      "Epoch 16/50\n",
      "Train Loss: 0.5965 Train Acc0.7003\n",
      "----------------------------------------\n",
      "Epoch 17/50\n",
      "Train Loss: 0.5939 Train Acc0.7024\n",
      "----------------------------------------\n",
      "Epoch 18/50\n",
      "Train Loss: 0.5921 Train Acc0.7016\n",
      "----------------------------------------\n",
      "Epoch 19/50\n",
      "Train Loss: 0.5907 Train Acc0.7022\n",
      "----------------------------------------\n",
      "Epoch 20/50\n",
      "Train Loss: 0.5896 Train Acc0.7036\n",
      "Val Auc: 0.7764\n",
      "----------------------------------------\n",
      "Epoch 21/50\n",
      "Train Loss: 0.5887 Train Acc0.7046\n",
      "----------------------------------------\n",
      "Epoch 22/50\n",
      "Train Loss: 0.5879 Train Acc0.7069\n",
      "----------------------------------------\n",
      "Epoch 23/50\n",
      "Train Loss: 0.5873 Train Acc0.7085\n",
      "----------------------------------------\n",
      "Epoch 24/50\n",
      "Train Loss: 0.5867 Train Acc0.7093\n",
      "----------------------------------------\n",
      "Epoch 25/50\n",
      "Train Loss: 0.5863 Train Acc0.7111\n",
      "Val Auc: 0.7739\n",
      "----------------------------------------\n",
      "Epoch 26/50\n",
      "Train Loss: 0.5859 Train Acc0.7130\n",
      "----------------------------------------\n",
      "Epoch 27/50\n",
      "Train Loss: 0.5855 Train Acc0.7135\n",
      "----------------------------------------\n",
      "Epoch 28/50\n",
      "Train Loss: 0.5852 Train Acc0.7127\n",
      "----------------------------------------\n",
      "Epoch 29/50\n",
      "Train Loss: 0.5848 Train Acc0.7135\n",
      "----------------------------------------\n",
      "Epoch 30/50\n",
      "Train Loss: 0.5846 Train Acc0.7138\n",
      "Val Auc: 0.7731\n",
      "----------------------------------------\n",
      "Epoch 31/50\n",
      "Train Loss: 0.5843 Train Acc0.7146\n",
      "----------------------------------------\n",
      "Epoch 32/50\n",
      "Train Loss: 0.5841 Train Acc0.7148\n",
      "----------------------------------------\n",
      "Epoch 33/50\n",
      "Train Loss: 0.5838 Train Acc0.7151\n",
      "----------------------------------------\n",
      "Epoch 34/50\n",
      "Train Loss: 0.5836 Train Acc0.7156\n",
      "----------------------------------------\n",
      "Epoch 35/50\n",
      "Train Loss: 0.5834 Train Acc0.7154\n",
      "Val Auc: 0.7723\n",
      "----------------------------------------\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34864\\2357685748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGRUIModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimputeMethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'GAN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaleMethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Norm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampleMethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'RandomBalance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_grui_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34864\\2799727400.py\u001b[0m in \u001b[0;36mtrain_grui_model\u001b[1;34m(model, X_train, y_train, train_delta_mat, X_val, y_val, val_delta_mat, batch_size, lr, num_epoch)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mgrad_clipping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUIModel(num_inputs=X_train.shape[2], num_hiddens=64, num_outputs=1, imputeMethod='GAN', scaleMethod='Norm', resampleMethod='RandomBalance').to(device)\n",
    "model = train_grui_model(model, X_resampled, y_resampled, delta_resampled, X_val, Y_val, val_delta, batch_size=32, lr=0.1, num_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Auc: 0.7927\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25076\\1175626226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Val Auc: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test Auc: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25076\\427196864.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X, H)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mH\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hiddens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrucell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "output, _ = model(X_val, None)\n",
    "print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "output, _ = model(X_test, None)\n",
    "print('test Auc: {:.4f}'.format(metrics.roc_auc_score(y_test, output.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3706972639011474\n"
     ]
    }
   ],
   "source": [
    "y_predict, _ = model(X_val, val_delta_mat, None)\n",
    "threshold = torch.tensor([0.5])\n",
    "y_predict = (y_predict > threshold).float() * 1\n",
    "# score1\n",
    "TP = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "for i in range (len(y_val)):\n",
    "    if (y_val[i] == 1) & (y_predict.detach().numpy()[i] == 1):\n",
    "        TP = TP + 1\n",
    "    if (y_val[i] == 1) & (y_predict.detach().numpy()[i] == 0):\n",
    "        FN = FN + 1\n",
    "    if (y_val[i] == 0) & (y_predict.detach().numpy()[i] == 1):\n",
    "        FP = FP + 1\n",
    "    if (y_val[i] == 0) & (y_predict.detach().numpy()[i] == 0):\n",
    "        TN = TN + 1\n",
    "print(min(TP/(TP+FN),TP/(TP+FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34864\\3691878404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_delta_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y_predict, _ = model(X_val, val_delta_mat, None)\n",
    "a = y_predict.detach().numpy()\n",
    "b = np.reshape(np.array(y_val),(np.array(y_val).size,1))\n",
    "a[a > 0.99] = 0.99\n",
    "a[a < 0.01] = 0.01\n",
    "c = np.append(a, b, axis=1)\n",
    "c =c[np.argsort(c[:,0])]\n",
    "score2 = 0\n",
    "for i in range (9):\n",
    "    d = c[400*i:(400*i+399),:]\n",
    "    pi_g = np.mean(d[:,0])\n",
    "    N_g = 400\n",
    "    O_g = np.count_nonzero(d[:,1])\n",
    "    e = d[:,0]\n",
    "    e[e<0.5]=0\n",
    "    E_g = np.count_nonzero(e)\n",
    "    score2 = score2 + (O_g - E_g)*(O_g - E_g)/(N_g * pi_g * (1-pi_g) + 0.001)\n",
    "d = c[3600:3992,:]\n",
    "pi_g = np.mean(d[:,0])\n",
    "N_g = 393\n",
    "O_g = np.count_nonzero(d[:,1])\n",
    "e = d[:,0]\n",
    "e[e<0.5]=0\n",
    "E_g = np.count_nonzero(e)\n",
    "score2 = score2 + (O_g - E_g)*(O_g - E_g)/(N_g * pi_g * (1-pi_g) + 0.001)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "class ReadImputedPhysionetData:\n",
    "    def __init__(self, dataPath ):\n",
    "        #一个文件一个batch，但需要注意，x,y,delta之间的匹配\n",
    "        #例子： batch1y,batch1x,batch1delta\n",
    "        #batchid从1开始\n",
    "        self.files = os.listdir(dataPath)\n",
    "        self.dataPath=dataPath\n",
    "        self.count=int(len(self.files)/3)\n",
    "        \n",
    "    def load(self):\n",
    "        count=int(self.count)\n",
    "        self.x=[]\n",
    "        self.y=[]\n",
    "        self.delta=[]\n",
    "        self.x_lengths=[]\n",
    "        self.m=[]\n",
    "        for i in range(1,count+1):\n",
    "            file_x=open(os.path.join(self.dataPath,\"batch\"+str(i)+\"x\"))\n",
    "            file_y=open(os.path.join(self.dataPath,\"batch\"+str(i)+\"y\"))\n",
    "            file_delta=open(os.path.join(self.dataPath,\"batch\"+str(i)+\"delta\"))\n",
    "            this_x,this_lengths=self.readx(file_x)\n",
    "            self.x.extend(this_x)\n",
    "            self.x_lengths.extend(this_lengths)\n",
    "            self.y.extend(self.ready(file_y))\n",
    "            this_delta,this_m=self.readdelta(file_delta)\n",
    "            self.delta.extend(this_delta)\n",
    "            self.m.extend(this_m)\n",
    "            file_x.close()\n",
    "            file_y.close()\n",
    "            file_delta.close()\n",
    "        self.maxLength=len(self.x[0])\n",
    "        \n",
    "        \n",
    "    def readx(self,x):\n",
    "        this_x=[]\n",
    "        this_lengths=[]\n",
    "        count=1\n",
    "        for line in x.readlines():\n",
    "            if count==1:\n",
    "                words=line.strip().split(\",\")\n",
    "                for w in words:\n",
    "                    if w=='':\n",
    "                        continue\n",
    "                    this_lengths.append(int(w))\n",
    "            else:\n",
    "                if \"end\" in line:\n",
    "                    continue\n",
    "                if \"begin\" in line:\n",
    "                    d=[]\n",
    "                    this_x.append(d)\n",
    "                else:\n",
    "                    words=line.strip().split(\",\")\n",
    "                    if words[0]=='':\n",
    "                        continue\n",
    "                    oneclass=[]\n",
    "                    for w in words:\n",
    "                        if w=='':\n",
    "                            continue\n",
    "                        oneclass.append(float(w))\n",
    "                    this_x[-1].append(oneclass)\n",
    "            count+=1\n",
    "        return this_x,this_lengths\n",
    "    \n",
    "    def ready(self,y):\n",
    "        this_y=[]\n",
    "        for line in y.readlines():\n",
    "            d=[]\n",
    "            words=line.strip().split(\",\")\n",
    "            for w in words:\n",
    "                if w=='':\n",
    "                    continue\n",
    "                d.append(int(w))\n",
    "            this_y.append(d)\n",
    "        return this_y\n",
    "    \n",
    "    def readdelta(self,delta):\n",
    "        this_delta=[]\n",
    "        this_m=[]\n",
    "        for line in delta.readlines():\n",
    "            if \"end\" in line:\n",
    "                continue\n",
    "            if \"begin\" in line:\n",
    "                d=[]\n",
    "                this_delta.append(d)\n",
    "                t=[]\n",
    "                this_m.append(t)\n",
    "            else:\n",
    "                words=line.strip().split(\",\")\n",
    "                oneclass=[]\n",
    "                onem=[]\n",
    "                for i in range(len(words)):\n",
    "                    w=words[i]\n",
    "                    if w=='':\n",
    "                        continue\n",
    "                    oneclass.append(float(w))\n",
    "                    if i==0 or float(w) >0:\n",
    "                        onem.append(1.0)\n",
    "                    else:\n",
    "                        onem.append(0.0)\n",
    "                this_delta[-1].append(oneclass)\n",
    "                this_m[-1].append(onem)\n",
    "        return this_delta,this_m\n",
    "    \n",
    "    def shuffle(self,batchSize=128,isShuffle=False):\n",
    "        self.batchSize=batchSize\n",
    "        if isShuffle:\n",
    "            c = list(zip(self.x,self.y,self.m,self.delta,self.x_lengths))\n",
    "            random.shuffle(c)\n",
    "            self.x,self.y,self.m,self.delta,self.x_lengths=zip(*c)\n",
    "            \n",
    "    def nextBatch(self):\n",
    "        i=1\n",
    "        while i*self.batchSize<=len(self.x):\n",
    "            x=[]\n",
    "            y=[]\n",
    "            m=[]\n",
    "            delta=[]\n",
    "            x_lengths=[]\n",
    "            for j in range((i-1)*self.batchSize,i*self.batchSize):\n",
    "                x.append(self.x[j])\n",
    "                y.append(self.y[j])\n",
    "                m.append(self.m[j])\n",
    "                delta.append(self.delta[j])\n",
    "                x_lengths.append(self.x_lengths[j])\n",
    "            i+=1\n",
    "            yield  x,y,[0.0]*len(self.x[0][0]),m,delta,x_lengths,x,0,0,0\n",
    "\n",
    "dt=ReadImputedPhysionetData(\"E:/WashU/Research/Multivariate-Time-Series-Imputation-with-Generative-Adversarial-Networks/Gan_Imputation/imputation_train_results/WGAN_no_mask/30_8_128_64_0.001_400_True_True_True_0.15_0.5\")\n",
    "dt.load()\n",
    "dt_test=ReadImputedPhysionetData(\"E:/WashU/Research/Multivariate-Time-Series-Imputation-with-Generative-Adversarial-Networks/Gan_Imputation/imputation_test_results/WGAN_no_mask/30_8_128_64_0.001_400_True_True_True_0.15_0.5\")\n",
    "dt_test.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(dt.x)\n",
    "X_train.reshape((X_train.shape[0],X_train.shape[1],41))\n",
    "y_train = np.array(dt.y[::2])[:,1]\n",
    "delta_train = []\n",
    "for i in range(len(dt.delta)):\n",
    "    delta_train.append(np.array(dt.delta[0][1:-1:2]))\n",
    "delta_train = np.array(delta_train)\n",
    "X_test = np.array(dt_test.x)\n",
    "X_test.reshape((X_test.shape[0],X_test.shape[1],41))\n",
    "y_test = np.array(dt_test.y[::2])[:,1]\n",
    "delta_test = []\n",
    "for i in range(len(dt_test.delta)):\n",
    "    delta_test.append(np.array(dt_test.delta[0][1:-1:2]))\n",
    "delta_test = np.array(delta_test)\n",
    "X_resampled = []\n",
    "y_resampled = []\n",
    "delta_resampled = []\n",
    "y_one_index = np.argwhere(y_train==1).reshape(-1)\n",
    "for i in np.argwhere(y_train==0).reshape(-1):\n",
    "    X_resampled.append(X_train[i])\n",
    "    y_resampled.append(y_train[i])\n",
    "    delta_resampled.append(delta_train[i])\n",
    "    sample_index = np.random.randint(0, len(y_one_index)-1)\n",
    "    X_resampled.append(X_train[y_one_index[sample_index]])\n",
    "    y_resampled.append(y_train[y_one_index[sample_index]])\n",
    "    delta_resampled.append(delta_train[y_one_index[sample_index]])\n",
    "X_resampled = np.array(X_resampled)\n",
    "delta_resampled = np.array(delta_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grui_model(model, X_train, y_train, train_delta_mat, X_val, y_val, val_delta_mat, batch_size, lr, num_epoch=25):\n",
    "    train_loss_all, train_acc_all = [], []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    threshold = torch.tensor([0.5])\n",
    "    \n",
    "    train_num = X_train.shape[0]\n",
    "    val_num = X_val.shape[0]\n",
    "    X_train = torch.from_numpy(X_train.transpose(1, 0, 2)).float()\n",
    "    X_val = torch.from_numpy(X_val.transpose(1, 0, 2)).float()\n",
    "    train_delta_mat = torch.from_numpy(train_delta_mat.transpose(1, 0, 2)).float()\n",
    "    val_delta_mat = torch.from_numpy(val_delta_mat.transpose(1, 0, 2)).float()\n",
    "    y_train = torch.from_numpy(np.array(y_train)).type(torch.LongTensor)\n",
    "    y_val = torch.from_numpy(np.array(y_val)).type(torch.LongTensor)\n",
    "    \n",
    "    # Compute the AUC of validation set\n",
    "    output, _ = model(X_val, val_delta_mat, None)\n",
    "    print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"-\" * 40)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        \n",
    "        # training stage\n",
    "        train_loss, train_corrects = 0, 0\n",
    "        test_loss, test_corrects = 0, 0\n",
    "        \n",
    "        for step in range(math.ceil(train_num/batch_size)):\n",
    "            if (step+1)*batch_size <= train_num:\n",
    "                X = X_train[:, int(step*batch_size):int((step+1)*batch_size), :]\n",
    "                y = y_train[int(step*batch_size):int((step+1)*batch_size)]\n",
    "                Delta = train_delta_mat[:, int(step*batch_size):int((step+1)*batch_size), :]\n",
    "            else:\n",
    "                X = X_train[:, int(step*batch_size):, :]\n",
    "                y = y_train[int(step*batch_size):]\n",
    "                Delta = train_delta_mat[:, int(step*batch_size):, :]\n",
    "            \n",
    "            output, _ = model(X, Delta, None)\n",
    "            y_hat = torch.cat((1-output,output),dim=1)\n",
    "            loss = criterion(y_hat, y)\n",
    "            y_predict = (output > threshold).float() * 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(model, 1)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(y)\n",
    "            train_corrects += torch.sum(y_predict.squeeze() == y)\n",
    "        \n",
    "        # Compute the mean of loss and accuracy for every epoch\n",
    "        train_loss_all.append(train_loss / train_num)\n",
    "        train_acc_all.append(train_corrects.double().item() / train_num)\n",
    "        \n",
    "        print(\"Train Loss: {:.4f} Train Acc{:.4f}\".format(train_loss_all[-1], train_acc_all[-1]))\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            # Compute the AUC of validation set\n",
    "            output, _ = model(X_val, val_delta_mat, None)\n",
    "            print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "    \n",
    "    # save\n",
    "    torch.save(model.state_dict(), 'E:/WashU/Research/ICU/modelParams/{}_{}_{}_{}_{}_{}_{}_{}.pth'.format(model.imputeMethod, \n",
    "                                                                                                          model.scaleMethod, \n",
    "                                                                                                          model.resampleMethod, \n",
    "                                                                                                          model.name, \n",
    "                                                                                                          model.num_hiddens, \n",
    "                                                                                                          batch_size, \n",
    "                                                                                                          lr, \n",
    "                                                                                                          num_epoch))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, _ = model(torch.from_numpy(X_train.transpose(1, 0, 2)).float(), torch.from_numpy(delta_train.transpose(1, 0, 2)).float(), None)\n",
    "y_hat = torch.cat((1-outputs,outputs),dim=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(y_hat, torch.from_numpy(np.array(y_train)).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3584, 48, 41)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Auc: 0.4983\n",
      "----------------------------------------\n",
      "Epoch 1/200\n",
      "Train Loss: 0.6931 Train Acc0.5826\n",
      "----------------------------------------\n",
      "Epoch 2/200\n",
      "Train Loss: 0.6931 Train Acc0.6037\n",
      "----------------------------------------\n",
      "Epoch 3/200\n",
      "Train Loss: 0.6931 Train Acc0.6106\n",
      "----------------------------------------\n",
      "Epoch 4/200\n",
      "Train Loss: 0.6931 Train Acc0.6111\n",
      "----------------------------------------\n",
      "Epoch 5/200\n",
      "Train Loss: 0.6929 Train Acc0.6118\n",
      "Val Auc: 0.6713\n",
      "----------------------------------------\n",
      "Epoch 6/200\n",
      "Train Loss: 0.6908 Train Acc0.6121\n",
      "----------------------------------------\n",
      "Epoch 7/200\n",
      "Train Loss: 0.6788 Train Acc0.6212\n",
      "----------------------------------------\n",
      "Epoch 8/200\n",
      "Train Loss: 0.6472 Train Acc0.6609\n",
      "----------------------------------------\n",
      "Epoch 9/200\n",
      "Train Loss: 0.6081 Train Acc0.7068\n",
      "----------------------------------------\n",
      "Epoch 10/200\n",
      "Train Loss: 0.5788 Train Acc0.7247\n",
      "Val Auc: 0.7855\n",
      "----------------------------------------\n",
      "Epoch 11/200\n",
      "Train Loss: 0.5684 Train Acc0.7326\n",
      "----------------------------------------\n",
      "Epoch 12/200\n",
      "Train Loss: 0.5635 Train Acc0.7372\n",
      "----------------------------------------\n",
      "Epoch 13/200\n",
      "Train Loss: 0.5602 Train Acc0.7430\n",
      "----------------------------------------\n",
      "Epoch 14/200\n",
      "Train Loss: 0.5584 Train Acc0.7437\n",
      "----------------------------------------\n",
      "Epoch 15/200\n",
      "Train Loss: 0.5571 Train Acc0.7464\n",
      "Val Auc: 0.7899\n",
      "----------------------------------------\n",
      "Epoch 16/200\n",
      "Train Loss: 0.5557 Train Acc0.7459\n",
      "----------------------------------------\n",
      "Epoch 17/200\n",
      "Train Loss: 0.5550 Train Acc0.7458\n",
      "----------------------------------------\n",
      "Epoch 18/200\n",
      "Train Loss: 0.5544 Train Acc0.7464\n",
      "----------------------------------------\n",
      "Epoch 19/200\n",
      "Train Loss: 0.5528 Train Acc0.7497\n",
      "----------------------------------------\n",
      "Epoch 20/200\n",
      "Train Loss: 0.5515 Train Acc0.7490\n",
      "Val Auc: 0.7900\n",
      "----------------------------------------\n",
      "Epoch 21/200\n",
      "Train Loss: 0.5507 Train Acc0.7513\n",
      "----------------------------------------\n",
      "Epoch 22/200\n",
      "Train Loss: 0.5494 Train Acc0.7541\n",
      "----------------------------------------\n",
      "Epoch 23/200\n",
      "Train Loss: 0.5495 Train Acc0.7555\n",
      "----------------------------------------\n",
      "Epoch 24/200\n",
      "Train Loss: 0.5470 Train Acc0.7555\n",
      "----------------------------------------\n",
      "Epoch 25/200\n",
      "Train Loss: 0.5457 Train Acc0.7571\n",
      "Val Auc: 0.7896\n",
      "----------------------------------------\n",
      "Epoch 26/200\n",
      "Train Loss: 0.5451 Train Acc0.7584\n",
      "----------------------------------------\n",
      "Epoch 27/200\n",
      "Train Loss: 0.5434 Train Acc0.7622\n",
      "----------------------------------------\n",
      "Epoch 28/200\n",
      "Train Loss: 0.5423 Train Acc0.7607\n",
      "----------------------------------------\n",
      "Epoch 29/200\n",
      "Train Loss: 0.5402 Train Acc0.7669\n",
      "----------------------------------------\n",
      "Epoch 30/200\n",
      "Train Loss: 0.5386 Train Acc0.7700\n",
      "Val Auc: 0.7782\n",
      "----------------------------------------\n",
      "Epoch 31/200\n",
      "Train Loss: 0.5362 Train Acc0.7732\n",
      "----------------------------------------\n",
      "Epoch 32/200\n",
      "Train Loss: 0.5348 Train Acc0.7740\n",
      "----------------------------------------\n",
      "Epoch 33/200\n",
      "Train Loss: 0.5309 Train Acc0.7790\n",
      "----------------------------------------\n",
      "Epoch 34/200\n",
      "Train Loss: 0.5307 Train Acc0.7805\n",
      "----------------------------------------\n",
      "Epoch 35/200\n",
      "Train Loss: 0.5290 Train Acc0.7810\n",
      "Val Auc: 0.7922\n",
      "----------------------------------------\n",
      "Epoch 36/200\n",
      "Train Loss: 0.5263 Train Acc0.7847\n",
      "----------------------------------------\n",
      "Epoch 37/200\n",
      "Train Loss: 0.5249 Train Acc0.7875\n",
      "----------------------------------------\n",
      "Epoch 38/200\n",
      "Train Loss: 0.5242 Train Acc0.7881\n",
      "----------------------------------------\n",
      "Epoch 39/200\n",
      "Train Loss: 0.5223 Train Acc0.7888\n",
      "----------------------------------------\n",
      "Epoch 40/200\n",
      "Train Loss: 0.5224 Train Acc0.7891\n",
      "Val Auc: 0.7965\n",
      "----------------------------------------\n",
      "Epoch 41/200\n",
      "Train Loss: 0.5258 Train Acc0.7834\n",
      "----------------------------------------\n",
      "Epoch 42/200\n",
      "Train Loss: 0.5232 Train Acc0.7859\n",
      "----------------------------------------\n",
      "Epoch 43/200\n",
      "Train Loss: 0.5224 Train Acc0.7881\n",
      "----------------------------------------\n",
      "Epoch 44/200\n",
      "Train Loss: 0.5212 Train Acc0.7872\n",
      "----------------------------------------\n",
      "Epoch 45/200\n",
      "Train Loss: 0.5200 Train Acc0.7907\n",
      "Val Auc: 0.8026\n",
      "----------------------------------------\n",
      "Epoch 46/200\n",
      "Train Loss: 0.5156 Train Acc0.7959\n",
      "----------------------------------------\n",
      "Epoch 47/200\n",
      "Train Loss: 0.5162 Train Acc0.7956\n",
      "----------------------------------------\n",
      "Epoch 48/200\n",
      "Train Loss: 0.5136 Train Acc0.7975\n",
      "----------------------------------------\n",
      "Epoch 49/200\n",
      "Train Loss: 0.5134 Train Acc0.7990\n",
      "----------------------------------------\n",
      "Epoch 50/200\n",
      "Train Loss: 0.5144 Train Acc0.7964\n",
      "Val Auc: 0.8066\n",
      "----------------------------------------\n",
      "Epoch 51/200\n",
      "Train Loss: 0.5160 Train Acc0.7951\n",
      "----------------------------------------\n",
      "Epoch 52/200\n",
      "Train Loss: 0.5143 Train Acc0.7954\n",
      "----------------------------------------\n",
      "Epoch 53/200\n",
      "Train Loss: 0.5102 Train Acc0.8003\n",
      "----------------------------------------\n",
      "Epoch 54/200\n",
      "Train Loss: 0.5100 Train Acc0.8018\n",
      "----------------------------------------\n",
      "Epoch 55/200\n",
      "Train Loss: 0.5112 Train Acc0.8008\n",
      "Val Auc: 0.8069\n",
      "----------------------------------------\n",
      "Epoch 56/200\n",
      "Train Loss: 0.5118 Train Acc0.8003\n",
      "----------------------------------------\n",
      "Epoch 57/200\n",
      "Train Loss: 0.5098 Train Acc0.8026\n",
      "----------------------------------------\n",
      "Epoch 58/200\n",
      "Train Loss: 0.5072 Train Acc0.8063\n",
      "----------------------------------------\n",
      "Epoch 59/200\n",
      "Train Loss: 0.5099 Train Acc0.8027\n",
      "----------------------------------------\n",
      "Epoch 60/200\n",
      "Train Loss: 0.5068 Train Acc0.8047\n",
      "Val Auc: 0.8078\n",
      "----------------------------------------\n",
      "Epoch 61/200\n",
      "Train Loss: 0.5044 Train Acc0.8095\n",
      "----------------------------------------\n",
      "Epoch 62/200\n",
      "Train Loss: 0.5041 Train Acc0.8082\n",
      "----------------------------------------\n",
      "Epoch 63/200\n",
      "Train Loss: 0.5032 Train Acc0.8076\n",
      "----------------------------------------\n",
      "Epoch 64/200\n",
      "Train Loss: 0.5038 Train Acc0.8086\n",
      "----------------------------------------\n",
      "Epoch 65/200\n",
      "Train Loss: 0.5028 Train Acc0.8092\n",
      "Val Auc: 0.8014\n",
      "----------------------------------------\n",
      "Epoch 66/200\n",
      "Train Loss: 0.5009 Train Acc0.8110\n",
      "----------------------------------------\n",
      "Epoch 67/200\n",
      "Train Loss: 0.4997 Train Acc0.8129\n",
      "----------------------------------------\n",
      "Epoch 68/200\n",
      "Train Loss: 0.4971 Train Acc0.8152\n",
      "----------------------------------------\n",
      "Epoch 69/200\n",
      "Train Loss: 0.4970 Train Acc0.8172\n",
      "----------------------------------------\n",
      "Epoch 70/200\n",
      "Train Loss: 0.4948 Train Acc0.8199\n",
      "Val Auc: 0.8002\n",
      "----------------------------------------\n",
      "Epoch 71/200\n",
      "Train Loss: 0.4918 Train Acc0.8237\n",
      "----------------------------------------\n",
      "Epoch 72/200\n",
      "Train Loss: 0.4973 Train Acc0.8152\n",
      "----------------------------------------\n",
      "Epoch 73/200\n",
      "Train Loss: 0.4919 Train Acc0.8232\n",
      "----------------------------------------\n",
      "Epoch 74/200\n",
      "Train Loss: 0.4944 Train Acc0.8204\n",
      "----------------------------------------\n",
      "Epoch 75/200\n",
      "Train Loss: 0.4913 Train Acc0.8220\n",
      "Val Auc: 0.7984\n",
      "----------------------------------------\n",
      "Epoch 76/200\n",
      "Train Loss: 0.4915 Train Acc0.8220\n",
      "----------------------------------------\n",
      "Epoch 77/200\n",
      "Train Loss: 0.4914 Train Acc0.8217\n",
      "----------------------------------------\n",
      "Epoch 78/200\n",
      "Train Loss: 0.4884 Train Acc0.8261\n",
      "----------------------------------------\n",
      "Epoch 79/200\n",
      "Train Loss: 0.4873 Train Acc0.8279\n",
      "----------------------------------------\n",
      "Epoch 80/200\n",
      "Train Loss: 0.4882 Train Acc0.8250\n",
      "Val Auc: 0.7988\n",
      "----------------------------------------\n",
      "Epoch 81/200\n",
      "Train Loss: 0.4862 Train Acc0.8290\n",
      "----------------------------------------\n",
      "Epoch 82/200\n",
      "Train Loss: 0.4888 Train Acc0.8246\n",
      "----------------------------------------\n",
      "Epoch 83/200\n",
      "Train Loss: 0.4866 Train Acc0.8277\n",
      "----------------------------------------\n",
      "Epoch 84/200\n",
      "Train Loss: 0.4870 Train Acc0.8272\n",
      "----------------------------------------\n",
      "Epoch 85/200\n",
      "Train Loss: 0.4831 Train Acc0.8308\n",
      "Val Auc: 0.8009\n",
      "----------------------------------------\n",
      "Epoch 86/200\n",
      "Train Loss: 0.4825 Train Acc0.8313\n",
      "----------------------------------------\n",
      "Epoch 87/200\n",
      "Train Loss: 0.4820 Train Acc0.8323\n",
      "----------------------------------------\n",
      "Epoch 88/200\n",
      "Train Loss: 0.4802 Train Acc0.8344\n",
      "----------------------------------------\n",
      "Epoch 89/200\n",
      "Train Loss: 0.4810 Train Acc0.8337\n",
      "----------------------------------------\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4801 Train Acc0.8324\n",
      "Val Auc: 0.8067\n",
      "----------------------------------------\n",
      "Epoch 91/200\n",
      "Train Loss: 0.4804 Train Acc0.8327\n",
      "----------------------------------------\n",
      "Epoch 92/200\n",
      "Train Loss: 0.4809 Train Acc0.8334\n",
      "----------------------------------------\n",
      "Epoch 93/200\n",
      "Train Loss: 0.4784 Train Acc0.8344\n",
      "----------------------------------------\n",
      "Epoch 94/200\n",
      "Train Loss: 0.4781 Train Acc0.8358\n",
      "----------------------------------------\n",
      "Epoch 95/200\n",
      "Train Loss: 0.4760 Train Acc0.8376\n",
      "Val Auc: 0.8063\n",
      "----------------------------------------\n",
      "Epoch 96/200\n",
      "Train Loss: 0.4760 Train Acc0.8373\n",
      "----------------------------------------\n",
      "Epoch 97/200\n",
      "Train Loss: 0.4751 Train Acc0.8386\n",
      "----------------------------------------\n",
      "Epoch 98/200\n",
      "Train Loss: 0.4750 Train Acc0.8391\n",
      "----------------------------------------\n",
      "Epoch 99/200\n",
      "Train Loss: 0.4737 Train Acc0.8407\n",
      "----------------------------------------\n",
      "Epoch 100/200\n",
      "Train Loss: 0.4712 Train Acc0.8423\n",
      "Val Auc: 0.7957\n",
      "----------------------------------------\n",
      "Epoch 101/200\n",
      "Train Loss: 0.4748 Train Acc0.8386\n",
      "----------------------------------------\n",
      "Epoch 102/200\n",
      "Train Loss: 0.4722 Train Acc0.8413\n",
      "----------------------------------------\n",
      "Epoch 103/200\n",
      "Train Loss: 0.4724 Train Acc0.8421\n",
      "----------------------------------------\n",
      "Epoch 104/200\n",
      "Train Loss: 0.4706 Train Acc0.8433\n",
      "----------------------------------------\n",
      "Epoch 105/200\n",
      "Train Loss: 0.4696 Train Acc0.8441\n",
      "Val Auc: 0.7967\n",
      "----------------------------------------\n",
      "Epoch 106/200\n",
      "Train Loss: 0.4684 Train Acc0.8462\n",
      "----------------------------------------\n",
      "Epoch 107/200\n",
      "Train Loss: 0.4677 Train Acc0.8467\n",
      "----------------------------------------\n",
      "Epoch 108/200\n",
      "Train Loss: 0.4708 Train Acc0.8436\n",
      "----------------------------------------\n",
      "Epoch 109/200\n",
      "Train Loss: 0.4666 Train Acc0.8485\n",
      "----------------------------------------\n",
      "Epoch 110/200\n",
      "Train Loss: 0.4647 Train Acc0.8503\n",
      "Val Auc: 0.7957\n",
      "----------------------------------------\n",
      "Epoch 111/200\n",
      "Train Loss: 0.4670 Train Acc0.8470\n",
      "----------------------------------------\n",
      "Epoch 112/200\n",
      "Train Loss: 0.4681 Train Acc0.8456\n",
      "----------------------------------------\n",
      "Epoch 113/200\n",
      "Train Loss: 0.4647 Train Acc0.8511\n",
      "----------------------------------------\n",
      "Epoch 114/200\n",
      "Train Loss: 0.4636 Train Acc0.8514\n",
      "----------------------------------------\n",
      "Epoch 115/200\n",
      "Train Loss: 0.4621 Train Acc0.8527\n",
      "Val Auc: 0.7979\n",
      "----------------------------------------\n",
      "Epoch 116/200\n",
      "Train Loss: 0.4631 Train Acc0.8517\n",
      "----------------------------------------\n",
      "Epoch 117/200\n",
      "Train Loss: 0.4630 Train Acc0.8519\n",
      "----------------------------------------\n",
      "Epoch 118/200\n",
      "Train Loss: 0.4624 Train Acc0.8514\n",
      "----------------------------------------\n",
      "Epoch 119/200\n",
      "Train Loss: 0.4613 Train Acc0.8529\n",
      "----------------------------------------\n",
      "Epoch 120/200\n",
      "Train Loss: 0.4619 Train Acc0.8524\n",
      "Val Auc: 0.7933\n",
      "----------------------------------------\n",
      "Epoch 121/200\n",
      "Train Loss: 0.4614 Train Acc0.8525\n",
      "----------------------------------------\n",
      "Epoch 122/200\n",
      "Train Loss: 0.4593 Train Acc0.8551\n",
      "----------------------------------------\n",
      "Epoch 123/200\n",
      "Train Loss: 0.4611 Train Acc0.8537\n",
      "----------------------------------------\n",
      "Epoch 124/200\n",
      "Train Loss: 0.4614 Train Acc0.8535\n",
      "----------------------------------------\n",
      "Epoch 125/200\n",
      "Train Loss: 0.4591 Train Acc0.8559\n",
      "Val Auc: 0.8001\n",
      "----------------------------------------\n",
      "Epoch 126/200\n",
      "Train Loss: 0.4617 Train Acc0.8525\n",
      "----------------------------------------\n",
      "Epoch 127/200\n",
      "Train Loss: 0.4602 Train Acc0.8553\n",
      "----------------------------------------\n",
      "Epoch 128/200\n",
      "Train Loss: 0.4593 Train Acc0.8551\n",
      "----------------------------------------\n",
      "Epoch 129/200\n",
      "Train Loss: 0.4579 Train Acc0.8561\n",
      "----------------------------------------\n",
      "Epoch 130/200\n",
      "Train Loss: 0.4605 Train Acc0.8532\n",
      "Val Auc: 0.8001\n",
      "----------------------------------------\n",
      "Epoch 131/200\n",
      "Train Loss: 0.4583 Train Acc0.8561\n",
      "----------------------------------------\n",
      "Epoch 132/200\n",
      "Train Loss: 0.4594 Train Acc0.8543\n",
      "----------------------------------------\n",
      "Epoch 133/200\n",
      "Train Loss: 0.4577 Train Acc0.8564\n",
      "----------------------------------------\n",
      "Epoch 134/200\n",
      "Train Loss: 0.4585 Train Acc0.8555\n",
      "----------------------------------------\n",
      "Epoch 135/200\n",
      "Train Loss: 0.4578 Train Acc0.8566\n",
      "Val Auc: 0.7963\n",
      "----------------------------------------\n",
      "Epoch 136/200\n",
      "Train Loss: 0.4567 Train Acc0.8572\n",
      "----------------------------------------\n",
      "Epoch 137/200\n",
      "Train Loss: 0.4570 Train Acc0.8574\n",
      "----------------------------------------\n",
      "Epoch 138/200\n",
      "Train Loss: 0.4580 Train Acc0.8561\n",
      "----------------------------------------\n",
      "Epoch 139/200\n",
      "Train Loss: 0.4550 Train Acc0.8592\n",
      "----------------------------------------\n",
      "Epoch 140/200\n",
      "Train Loss: 0.4554 Train Acc0.8585\n",
      "Val Auc: 0.7927\n",
      "----------------------------------------\n",
      "Epoch 141/200\n",
      "Train Loss: 0.4539 Train Acc0.8608\n",
      "----------------------------------------\n",
      "Epoch 142/200\n",
      "Train Loss: 0.4570 Train Acc0.8563\n",
      "----------------------------------------\n",
      "Epoch 143/200\n",
      "Train Loss: 0.4547 Train Acc0.8592\n",
      "----------------------------------------\n",
      "Epoch 144/200\n",
      "Train Loss: 0.4537 Train Acc0.8606\n",
      "----------------------------------------\n",
      "Epoch 145/200\n",
      "Train Loss: 0.4544 Train Acc0.8595\n",
      "Val Auc: 0.7890\n",
      "----------------------------------------\n",
      "Epoch 146/200\n",
      "Train Loss: 0.4560 Train Acc0.8582\n",
      "----------------------------------------\n",
      "Epoch 147/200\n",
      "Train Loss: 0.4569 Train Acc0.8574\n",
      "----------------------------------------\n",
      "Epoch 148/200\n",
      "Train Loss: 0.4541 Train Acc0.8600\n",
      "----------------------------------------\n",
      "Epoch 149/200\n",
      "Train Loss: 0.4528 Train Acc0.8615\n",
      "----------------------------------------\n",
      "Epoch 150/200\n",
      "Train Loss: 0.4532 Train Acc0.8606\n",
      "Val Auc: 0.7965\n",
      "----------------------------------------\n",
      "Epoch 151/200\n",
      "Train Loss: 0.4543 Train Acc0.8597\n",
      "----------------------------------------\n",
      "Epoch 152/200\n",
      "Train Loss: 0.4533 Train Acc0.8611\n",
      "----------------------------------------\n",
      "Epoch 153/200\n",
      "Train Loss: 0.4538 Train Acc0.8605\n",
      "----------------------------------------\n",
      "Epoch 154/200\n",
      "Train Loss: 0.4541 Train Acc0.8595\n",
      "----------------------------------------\n",
      "Epoch 155/200\n",
      "Train Loss: 0.4526 Train Acc0.8615\n",
      "Val Auc: 0.7944\n",
      "----------------------------------------\n",
      "Epoch 156/200\n",
      "Train Loss: 0.4526 Train Acc0.8611\n",
      "----------------------------------------\n",
      "Epoch 157/200\n",
      "Train Loss: 0.4528 Train Acc0.8610\n",
      "----------------------------------------\n",
      "Epoch 158/200\n",
      "Train Loss: 0.4526 Train Acc0.8611\n",
      "----------------------------------------\n",
      "Epoch 159/200\n",
      "Train Loss: 0.4521 Train Acc0.8619\n",
      "----------------------------------------\n",
      "Epoch 160/200\n",
      "Train Loss: 0.4523 Train Acc0.8611\n",
      "Val Auc: 0.7908\n",
      "----------------------------------------\n",
      "Epoch 161/200\n",
      "Train Loss: 0.4505 Train Acc0.8639\n",
      "----------------------------------------\n",
      "Epoch 162/200\n",
      "Train Loss: 0.4506 Train Acc0.8634\n",
      "----------------------------------------\n",
      "Epoch 163/200\n",
      "Train Loss: 0.4517 Train Acc0.8621\n",
      "----------------------------------------\n",
      "Epoch 164/200\n",
      "Train Loss: 0.4507 Train Acc0.8634\n",
      "----------------------------------------\n",
      "Epoch 165/200\n",
      "Train Loss: 0.4542 Train Acc0.8593\n",
      "Val Auc: 0.7924\n",
      "----------------------------------------\n",
      "Epoch 166/200\n",
      "Train Loss: 0.4527 Train Acc0.8608\n",
      "----------------------------------------\n",
      "Epoch 167/200\n",
      "Train Loss: 0.4504 Train Acc0.8631\n",
      "----------------------------------------\n",
      "Epoch 168/200\n",
      "Train Loss: 0.4506 Train Acc0.8632\n",
      "----------------------------------------\n",
      "Epoch 169/200\n",
      "Train Loss: 0.4489 Train Acc0.8645\n",
      "----------------------------------------\n",
      "Epoch 170/200\n",
      "Train Loss: 0.4480 Train Acc0.8658\n",
      "Val Auc: 0.7959\n",
      "----------------------------------------\n",
      "Epoch 171/200\n",
      "Train Loss: 0.4494 Train Acc0.8647\n",
      "----------------------------------------\n",
      "Epoch 172/200\n",
      "Train Loss: 0.4505 Train Acc0.8636\n",
      "----------------------------------------\n",
      "Epoch 173/200\n",
      "Train Loss: 0.4487 Train Acc0.8650\n",
      "----------------------------------------\n",
      "Epoch 174/200\n",
      "Train Loss: 0.4514 Train Acc0.8621\n",
      "----------------------------------------\n",
      "Epoch 175/200\n",
      "Train Loss: 0.4488 Train Acc0.8649\n",
      "Val Auc: 0.7973\n",
      "----------------------------------------\n",
      "Epoch 176/200\n",
      "Train Loss: 0.4504 Train Acc0.8634\n",
      "----------------------------------------\n",
      "Epoch 177/200\n",
      "Train Loss: 0.4493 Train Acc0.8650\n",
      "----------------------------------------\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4491 Train Acc0.8649\n",
      "----------------------------------------\n",
      "Epoch 179/200\n",
      "Train Loss: 0.4497 Train Acc0.8644\n",
      "----------------------------------------\n",
      "Epoch 180/200\n",
      "Train Loss: 0.4535 Train Acc0.8603\n",
      "Val Auc: 0.7957\n",
      "----------------------------------------\n",
      "Epoch 181/200\n",
      "Train Loss: 0.4461 Train Acc0.8681\n",
      "----------------------------------------\n",
      "Epoch 182/200\n",
      "Train Loss: 0.4465 Train Acc0.8676\n",
      "----------------------------------------\n",
      "Epoch 183/200\n",
      "Train Loss: 0.4474 Train Acc0.8663\n",
      "----------------------------------------\n",
      "Epoch 184/200\n",
      "Train Loss: 0.4480 Train Acc0.8663\n",
      "----------------------------------------\n",
      "Epoch 185/200\n",
      "Train Loss: 0.4479 Train Acc0.8662\n",
      "Val Auc: 0.7895\n",
      "----------------------------------------\n",
      "Epoch 186/200\n",
      "Train Loss: 0.4471 Train Acc0.8665\n",
      "----------------------------------------\n",
      "Epoch 187/200\n",
      "Train Loss: 0.4437 Train Acc0.8704\n",
      "----------------------------------------\n",
      "Epoch 188/200\n",
      "Train Loss: 0.4456 Train Acc0.8683\n",
      "----------------------------------------\n",
      "Epoch 189/200\n",
      "Train Loss: 0.4447 Train Acc0.8688\n",
      "----------------------------------------\n",
      "Epoch 190/200\n",
      "Train Loss: 0.4467 Train Acc0.8673\n",
      "Val Auc: 0.7916\n",
      "----------------------------------------\n",
      "Epoch 191/200\n",
      "Train Loss: 0.4464 Train Acc0.8670\n",
      "----------------------------------------\n",
      "Epoch 192/200\n",
      "Train Loss: 0.4479 Train Acc0.8655\n",
      "----------------------------------------\n",
      "Epoch 193/200\n",
      "Train Loss: 0.4471 Train Acc0.8663\n",
      "----------------------------------------\n",
      "Epoch 194/200\n",
      "Train Loss: 0.4446 Train Acc0.8694\n",
      "----------------------------------------\n",
      "Epoch 195/200\n",
      "Train Loss: 0.4445 Train Acc0.8697\n",
      "Val Auc: 0.7937\n",
      "----------------------------------------\n",
      "Epoch 196/200\n",
      "Train Loss: 0.4465 Train Acc0.8671\n",
      "----------------------------------------\n",
      "Epoch 197/200\n",
      "Train Loss: 0.4453 Train Acc0.8684\n",
      "----------------------------------------\n",
      "Epoch 198/200\n",
      "Train Loss: 0.4425 Train Acc0.8717\n",
      "----------------------------------------\n",
      "Epoch 199/200\n",
      "Train Loss: 0.4433 Train Acc0.8702\n",
      "----------------------------------------\n",
      "Epoch 200/200\n",
      "Train Loss: 0.4450 Train Acc0.8689\n",
      "Val Auc: 0.7896\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUIModel(num_inputs=X_train.shape[2], num_hiddens=64, num_outputs=1, imputeMethod='GAN', scaleMethod='GAN', resampleMethod='None').to(device)\n",
    "model = train_grui_model(model, X_resampled, y_resampled, delta_resampled, X_test, y_test, delta_test, batch_size=32, lr=0.1, num_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score1(method_Pred, ytest):\n",
    "    score1 = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    for i in range (len(ytest)):\n",
    "        if (ytest[i] == 1) & (method_Pred[i] == 1):\n",
    "            TP = TP + 1\n",
    "        if (ytest[i] == 1) & (method_Pred[i] == 0):\n",
    "            FN = FN + 1\n",
    "        if (ytest[i] == 0) & (method_Pred[i] == 1):\n",
    "            FP = FP + 1\n",
    "        if (ytest[i] == 0) & (method_Pred[i] == 0):\n",
    "            TN = TN + 1\n",
    "    if ((TP == 0) & (FN == 0)):\n",
    "        Se = 0\n",
    "    else:\n",
    "        Se = TP/(TP+FN)\n",
    "        \n",
    "    if ((TP == 0) & (FP == 0)):\n",
    "        P = 0\n",
    "    else:\n",
    "        P = TP/(TP+FP)\n",
    "    \n",
    "    if Se > P:\n",
    "        score1 = P\n",
    "    else:\n",
    "        score1 = Se\n",
    "    return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2804878048780488"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, _ = model(X_test, delta_test, None)\n",
    "y_predict = (output > 0.5).float() * 1\n",
    "Score1(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
