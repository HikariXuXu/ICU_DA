{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f4a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fd7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeDataMean(scliedData, MaskMat, meanvalue):\n",
    "    imputedata = []\n",
    "    for i in range(len(scliedData)):\n",
    "        a = np.array(scliedData[i])\n",
    "        b = np.array(scliedData[i]) * np.array(MaskMat[i])\n",
    "        e = b.sum(axis=0)\n",
    "        c = np.array(MaskMat[0])\n",
    "        d = c.sum(axis=0)\n",
    "        d[d==0]=1\n",
    "        mean = b.sum(axis=0)/d\n",
    "        for j in range(a.shape[1]):\n",
    "            if np.all(a[:,j] == -1):\n",
    "                a[:,j]= meanvalue[j]\n",
    "            else:\n",
    "                k = a[:,j]\n",
    "                k[k==-1]= e[j]\n",
    "        imputedata.append(a)\n",
    "    return imputedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f838bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeDataNearest(sliceData, meanvalue):\n",
    "    imputedata = []\n",
    "    for i in range(len(sliceData)):\n",
    "        a = np.array(sliceData[i])\n",
    "        b = pd.DataFrame(np.array(a))\n",
    "        b = b.replace(-1,np.nan)\n",
    "        c = b.count()\n",
    "        for k in range(a.shape[1]):\n",
    "            if c[k] == 0:\n",
    "                b[k] = meanvalue[k]\n",
    "            if c[k] == 1:\n",
    "                b[k] = b[k].interpolate(method ='ffill',axis=0)\n",
    "                b[k] = b[k].interpolate(method ='bfill',axis=0)\n",
    "        b = b.interpolate(method ='nearest',axis=0,limit_direction ='both')\n",
    "        b = b.interpolate(method ='ffill')\n",
    "        b = b.interpolate(method ='bfill')\n",
    "        b = b.values\n",
    "        imputedata.append(b)\n",
    "    return imputedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63fce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeLast(sliceData, meanvalue):\n",
    "    imputedata = []\n",
    "    for i in range(len(sliceData)):\n",
    "        a = np.array(sliceData[i])\n",
    "        for j in range(a.shape[1]):\n",
    "            if np.all(a[:,j] == -1):\n",
    "                a[:,j]= meanvalue[j]\n",
    "        b = pd.DataFrame(np.array(a))\n",
    "        b = b.replace(-1,np.nan)\n",
    "        b = b.interpolate(method ='ffill',axis=0)\n",
    "        b = b.interpolate(method ='bfill',axis=0)\n",
    "        b = b.values\n",
    "        imputedata.append(b)\n",
    "    return imputedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc77bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('E:/WashU/Research/ICU/Data/train/X_train_sliced_norm.pkl','rb')\n",
    "X_train_sliced = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/y_train.pkl','rb')\n",
    "y_train = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_delta_mat.pkl','rb')\n",
    "train_delta_mat = pickle.load(f)\n",
    "f.close()\n",
    "f = open('E:/WashU/Research/ICU/Data/train/train_mask_mat.pkl','rb')\n",
    "train_mask_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('E:/WashU/Research/ICU/Data/mean_norm.pkl','rb')\n",
    "mean = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ad490af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sliced = np.array(imputeDataMean(X_train_sliced, train_delta_mat, mean))\n",
    "\n",
    "X_train = np.array(X_train_sliced[:3600])\n",
    "X_val = np.array(X_train_sliced[3600:])\n",
    "train_delta = np.array(train_delta_mat[:3600])\n",
    "val_delta = np.array(train_delta_mat[3600:])\n",
    "Y_train = np.array(y_train[:3600])\n",
    "Y_val = np.array(y_train[3600:])\n",
    "X_resampled = []\n",
    "y_resampled = []\n",
    "delta_resampled = []\n",
    "y_one_index = np.argwhere(Y_train==1).reshape(-1)\n",
    "for i in np.argwhere(Y_train==0).reshape(-1):\n",
    "    X_resampled.append(X_train[i])\n",
    "    y_resampled.append(Y_train[i])\n",
    "    delta_resampled.append(train_delta[i])\n",
    "    sample_index = np.random.randint(0, len(y_one_index)-1)\n",
    "    X_resampled.append(X_train[y_one_index[sample_index]])\n",
    "    y_resampled.append(Y_train[y_one_index[sample_index]])\n",
    "    delta_resampled.append(train_delta[y_one_index[sample_index]])\n",
    "X_resampled = np.array(X_resampled)\n",
    "delta_resampled = np.array(delta_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0a7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f940486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUICell(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs):\n",
    "        super(GRUICell, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_outputs = num_outputs\n",
    "        def normal(shape):\n",
    "            return torch.randn(size=shape)*0.0001\n",
    "        def three():\n",
    "            return (nn.Parameter(normal((num_inputs, num_hiddens))), \n",
    "                    nn.Parameter(normal((num_hiddens, num_hiddens))), \n",
    "                    nn.Parameter(torch.zeros(num_hiddens)))\n",
    "        self.W_xz, self.W_hz, self.b_z = three() # Parameters of update gate\n",
    "        self.W_xr, self.W_hr, self.b_r = three() # Parameters of reset gate\n",
    "        self.W_xh, self.W_hh, self.b_h = three() # Parameters of candidate hidden state\n",
    "        # Parameters of decay vector\n",
    "        self.W_beta = nn.Parameter(normal((num_inputs, num_hiddens)))\n",
    "        self.b_beta = nn.Parameter(torch.zeros(num_hiddens))\n",
    "        # Parameters of output layer\n",
    "        self.W_hq = nn.Parameter(normal((num_hiddens, num_outputs)))\n",
    "        self.b_q = nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "    def forward(self, X, Delta, H):\n",
    "        beta = torch.exp(torch.minimum(torch.zeros(self.num_hiddens), Delta @ self.W_beta + self.b_beta))\n",
    "        H = beta * H\n",
    "        Z = torch.sigmoid((X @ self.W_xz) + (H @ self.W_hz) + self.b_z)\n",
    "        R = torch.sigmoid((X @ self.W_xr) + (H @ self.W_hr) + self.b_r)\n",
    "        H_tilde = torch.tanh((X @ self.W_xh) + ((R * H) @ self.W_hh) + self.b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        H.detach()\n",
    "        Y = torch.sigmoid(H @ self.W_hq + self.b_q)\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8d50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUIModel(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, imputeMethod, scaleMethod, resampleMethod):\n",
    "        super(GRUIModel, self).__init__()\n",
    "        self.name = 'GRUI'\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.gruicell = GRUICell(num_inputs, num_hiddens, num_outputs)\n",
    "        self.imputeMethod = imputeMethod\n",
    "        self.scaleMethod = scaleMethod\n",
    "        self.resampleMethod = resampleMethod\n",
    "\n",
    "    def forward(self, X, Delta, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[1], self.num_hiddens)\n",
    "        for index in range(X.shape[0]):\n",
    "            Y, H = self.gruicell(X[index], Delta[index], H)\n",
    "        return Y, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8022d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score1(method_Pred, ytest):\n",
    "    score1 = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    for i in range (len(ytest)):\n",
    "        if (ytest[i] == 1) & (method_Pred[i] == 1):\n",
    "            TP = TP + 1\n",
    "        if (ytest[i] == 1) & (method_Pred[i] == 0):\n",
    "            FN = FN + 1\n",
    "        if (ytest[i] == 0) & (method_Pred[i] == 1):\n",
    "            FP = FP + 1\n",
    "        if (ytest[i] == 0) & (method_Pred[i] == 0):\n",
    "            TN = TN + 1\n",
    "    if ((TP == 0) & (FN == 0)):\n",
    "        Se = 0\n",
    "    else:\n",
    "        Se = TP/(TP+FN)\n",
    "        \n",
    "    if ((TP == 0) & (FP == 0)):\n",
    "        P = 0\n",
    "    else:\n",
    "        P = TP/(TP+FP)\n",
    "    \n",
    "    if Se > P:\n",
    "        score1 = P\n",
    "    else:\n",
    "        score1 = Se\n",
    "    return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c883a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grui_model(model, X_train, y_train, train_delta_mat, X_val, y_val, val_delta_mat, batch_size, lr, num_epoch=25):\n",
    "    train_loss_all, train_acc_all = [], []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    threshold = torch.tensor([0.5])\n",
    "    \n",
    "    train_num = X_train.shape[0]\n",
    "    val_num = X_val.shape[0]\n",
    "    X_train = torch.from_numpy(X_train.transpose(1, 0, 2)).float()\n",
    "    X_val = torch.from_numpy(X_val.transpose(1, 0, 2)).float()\n",
    "    train_delta_mat = torch.from_numpy(train_delta_mat.transpose(1, 0, 2)).float()\n",
    "    val_delta_mat = torch.from_numpy(val_delta_mat.transpose(1, 0, 2)).float()\n",
    "    y_train = torch.from_numpy(np.array(y_train)).type(torch.LongTensor)\n",
    "    y_val = torch.from_numpy(np.array(y_val)).type(torch.LongTensor)\n",
    "    \n",
    "    # Compute the AUC of validation set\n",
    "    output, _ = model(X_val, val_delta_mat, None)\n",
    "    print('Val Auc: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy())))\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"-\" * 40)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        \n",
    "        # training stage\n",
    "        train_loss, train_corrects = 0, 0\n",
    "        test_loss, test_corrects = 0, 0\n",
    "        \n",
    "        for step in range(train_num//batch_size+1):\n",
    "            if (step+1)*batch_size <= train_num:\n",
    "                X = X_train[:, int(step*batch_size):int((step+1)*batch_size), :]\n",
    "                y = y_train[int(step*batch_size):int((step+1)*batch_size)]\n",
    "                Delta = train_delta_mat[:, int(step*batch_size):int((step+1)*batch_size), :]\n",
    "            else:\n",
    "                X = X_train[:, int(step*batch_size):, :]\n",
    "                y = y_train[int(step*batch_size):]\n",
    "                Delta = train_delta_mat[:, int(step*batch_size):, :]\n",
    "            \n",
    "            output, _ = model(X, Delta, None)\n",
    "            y_hat = torch.cat((1-output,output),dim=1)\n",
    "            loss = criterion(y_hat, y)\n",
    "            y_predict = (output > threshold).float() * 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(model, 1)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(y)\n",
    "            train_corrects += torch.sum(y_predict.squeeze() == y)\n",
    "        \n",
    "        # Compute the mean of loss and accuracy for every epoch\n",
    "        train_loss_all.append(train_loss / train_num)\n",
    "        train_acc_all.append(train_corrects.double().item() / train_num)\n",
    "        \n",
    "        print(\"Train Loss: {:.4f} Train Acc{:.4f}\".format(train_loss_all[-1], train_acc_all[-1]))\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            # Compute the AUC of validation set\n",
    "            output, _ = model(X_val, val_delta_mat, None)\n",
    "            y_predict = (output > threshold).float() * 1\n",
    "            print('Val Auc: {:.4f}, Val Score 1: {:.4f}'.format(metrics.roc_auc_score(y_val, output.detach().numpy()), Score1(y_predict, y_val)))\n",
    "    \n",
    "    # save\n",
    "    torch.save(model.state_dict(), 'E:/WashU/Research/ICU/modelParams/{}_{}_{}_{}_{}_{}_{}_{}.pth'.format(model.imputeMethod, \n",
    "                                                                                                          model.scaleMethod, \n",
    "                                                                                                          model.resampleMethod, \n",
    "                                                                                                          model.name, \n",
    "                                                                                                          model.num_hiddens, \n",
    "                                                                                                          batch_size, \n",
    "                                                                                                          lr, \n",
    "                                                                                                          num_epoch))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5856684",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Auc: 0.4957\n",
      "----------------------------------------\n",
      "Epoch 1/100\n",
      "Train Loss: 0.6931 Train Acc0.6055\n",
      "----------------------------------------\n",
      "Epoch 2/100\n",
      "Train Loss: 0.6931 Train Acc0.6609\n",
      "----------------------------------------\n",
      "Epoch 3/100\n",
      "Train Loss: 0.6931 Train Acc0.6581\n",
      "----------------------------------------\n",
      "Epoch 4/100\n",
      "Train Loss: 0.6931 Train Acc0.6302\n",
      "----------------------------------------\n",
      "Epoch 5/100\n",
      "Train Loss: 0.6931 Train Acc0.5912\n",
      "Val Auc: 0.7101, Val Score 1: 0.1379\n",
      "----------------------------------------\n",
      "Epoch 6/100\n",
      "Train Loss: 0.6928 Train Acc0.5979\n",
      "----------------------------------------\n",
      "Epoch 7/100\n",
      "Train Loss: 0.6914 Train Acc0.6373\n",
      "----------------------------------------\n",
      "Epoch 8/100\n",
      "Train Loss: 0.6832 Train Acc0.6848\n",
      "----------------------------------------\n",
      "Epoch 9/100\n",
      "Train Loss: 0.6477 Train Acc0.6964\n",
      "----------------------------------------\n",
      "Epoch 10/100\n",
      "Train Loss: 0.5955 Train Acc0.7151\n",
      "Val Auc: 0.7654, Val Score 1: 0.2360\n",
      "----------------------------------------\n",
      "Epoch 11/100\n",
      "Train Loss: 0.5680 Train Acc0.7339\n",
      "----------------------------------------\n",
      "Epoch 12/100\n",
      "Train Loss: 0.5544 Train Acc0.7476\n",
      "----------------------------------------\n",
      "Epoch 13/100\n",
      "Train Loss: 0.5492 Train Acc0.7552\n",
      "----------------------------------------\n",
      "Epoch 14/100\n",
      "Train Loss: 0.5460 Train Acc0.7587\n",
      "----------------------------------------\n",
      "Epoch 15/100\n",
      "Train Loss: 0.5440 Train Acc0.7607\n",
      "Val Auc: 0.8028, Val Score 1: 0.2188\n",
      "----------------------------------------\n",
      "Epoch 16/100\n",
      "Train Loss: 0.5426 Train Acc0.7618\n",
      "----------------------------------------\n",
      "Epoch 17/100\n",
      "Train Loss: 0.5413 Train Acc0.7626\n",
      "----------------------------------------\n",
      "Epoch 18/100\n",
      "Train Loss: 0.5401 Train Acc0.7650\n",
      "----------------------------------------\n",
      "Epoch 19/100\n",
      "Train Loss: 0.5391 Train Acc0.7650\n",
      "----------------------------------------\n",
      "Epoch 20/100\n",
      "Train Loss: 0.5383 Train Acc0.7657\n",
      "Val Auc: 0.8063, Val Score 1: 0.2278\n",
      "----------------------------------------\n",
      "Epoch 21/100\n",
      "Train Loss: 0.5375 Train Acc0.7665\n",
      "----------------------------------------\n",
      "Epoch 22/100\n",
      "Train Loss: 0.5368 Train Acc0.7681\n",
      "----------------------------------------\n",
      "Epoch 23/100\n",
      "Train Loss: 0.5362 Train Acc0.7691\n",
      "----------------------------------------\n",
      "Epoch 24/100\n",
      "Train Loss: 0.5356 Train Acc0.7710\n",
      "----------------------------------------\n",
      "Epoch 25/100\n",
      "Train Loss: 0.5351 Train Acc0.7720\n",
      "Val Auc: 0.8076, Val Score 1: 0.2403\n",
      "----------------------------------------\n",
      "Epoch 26/100\n",
      "Train Loss: 0.5346 Train Acc0.7729\n",
      "----------------------------------------\n",
      "Epoch 27/100\n",
      "Train Loss: 0.5341 Train Acc0.7739\n",
      "----------------------------------------\n",
      "Epoch 28/100\n",
      "Train Loss: 0.5337 Train Acc0.7728\n",
      "----------------------------------------\n",
      "Epoch 29/100\n",
      "Train Loss: 0.5332 Train Acc0.7741\n",
      "----------------------------------------\n",
      "Epoch 30/100\n",
      "Train Loss: 0.5328 Train Acc0.7749\n",
      "Val Auc: 0.8092, Val Score 1: 0.2467\n",
      "----------------------------------------\n",
      "Epoch 31/100\n",
      "Train Loss: 0.5324 Train Acc0.7752\n",
      "----------------------------------------\n",
      "Epoch 32/100\n",
      "Train Loss: 0.5320 Train Acc0.7760\n",
      "----------------------------------------\n",
      "Epoch 33/100\n",
      "Train Loss: 0.5317 Train Acc0.7763\n",
      "----------------------------------------\n",
      "Epoch 34/100\n",
      "Train Loss: 0.5314 Train Acc0.7765\n",
      "----------------------------------------\n",
      "Epoch 35/100\n",
      "Train Loss: 0.5311 Train Acc0.7771\n",
      "Val Auc: 0.8097, Val Score 1: 0.2517\n",
      "----------------------------------------\n",
      "Epoch 36/100\n",
      "Train Loss: 0.5308 Train Acc0.7776\n",
      "----------------------------------------\n",
      "Epoch 37/100\n",
      "Train Loss: 0.5306 Train Acc0.7776\n",
      "----------------------------------------\n",
      "Epoch 38/100\n",
      "Train Loss: 0.5304 Train Acc0.7784\n",
      "----------------------------------------\n",
      "Epoch 39/100\n",
      "Train Loss: 0.5302 Train Acc0.7786\n",
      "----------------------------------------\n",
      "Epoch 40/100\n",
      "Train Loss: 0.5300 Train Acc0.7786\n",
      "Val Auc: 0.8105, Val Score 1: 0.2569\n",
      "----------------------------------------\n",
      "Epoch 41/100\n",
      "Train Loss: 0.5298 Train Acc0.7783\n",
      "----------------------------------------\n",
      "Epoch 42/100\n",
      "Train Loss: 0.5296 Train Acc0.7783\n",
      "----------------------------------------\n",
      "Epoch 43/100\n",
      "Train Loss: 0.5294 Train Acc0.7781\n",
      "----------------------------------------\n",
      "Epoch 44/100\n",
      "Train Loss: 0.5292 Train Acc0.7783\n",
      "----------------------------------------\n",
      "Epoch 45/100\n",
      "Train Loss: 0.5291 Train Acc0.7783\n",
      "Val Auc: 0.8118, Val Score 1: 0.2606\n",
      "----------------------------------------\n",
      "Epoch 46/100\n",
      "Train Loss: 0.5289 Train Acc0.7779\n",
      "----------------------------------------\n",
      "Epoch 47/100\n",
      "Train Loss: 0.5287 Train Acc0.7786\n",
      "----------------------------------------\n",
      "Epoch 48/100\n",
      "Train Loss: 0.5286 Train Acc0.7791\n",
      "----------------------------------------\n",
      "Epoch 49/100\n",
      "Train Loss: 0.5284 Train Acc0.7792\n",
      "----------------------------------------\n",
      "Epoch 50/100\n",
      "Train Loss: 0.5282 Train Acc0.7800\n",
      "Val Auc: 0.8132, Val Score 1: 0.2606\n",
      "----------------------------------------\n",
      "Epoch 51/100\n",
      "Train Loss: 0.5281 Train Acc0.7805\n",
      "----------------------------------------\n",
      "Epoch 52/100\n",
      "Train Loss: 0.5279 Train Acc0.7802\n",
      "----------------------------------------\n",
      "Epoch 53/100\n",
      "Train Loss: 0.5277 Train Acc0.7800\n",
      "----------------------------------------\n",
      "Epoch 54/100\n",
      "Train Loss: 0.5275 Train Acc0.7802\n",
      "----------------------------------------\n",
      "Epoch 55/100\n",
      "Train Loss: 0.5273 Train Acc0.7807\n",
      "Val Auc: 0.8150, Val Score 1: 0.2662\n",
      "----------------------------------------\n",
      "Epoch 56/100\n",
      "Train Loss: 0.5271 Train Acc0.7808\n",
      "----------------------------------------\n",
      "Epoch 57/100\n",
      "Train Loss: 0.5269 Train Acc0.7807\n",
      "----------------------------------------\n",
      "Epoch 58/100\n",
      "Train Loss: 0.5267 Train Acc0.7807\n",
      "----------------------------------------\n",
      "Epoch 59/100\n",
      "Train Loss: 0.5265 Train Acc0.7818\n",
      "----------------------------------------\n",
      "Epoch 60/100\n",
      "Train Loss: 0.5263 Train Acc0.7812\n",
      "Val Auc: 0.8144, Val Score 1: 0.2701\n",
      "----------------------------------------\n",
      "Epoch 61/100\n",
      "Train Loss: 0.5257 Train Acc0.7817\n",
      "----------------------------------------\n",
      "Epoch 62/100\n",
      "Train Loss: 0.5254 Train Acc0.7817\n",
      "----------------------------------------\n",
      "Epoch 63/100\n",
      "Train Loss: 0.5251 Train Acc0.7831\n",
      "----------------------------------------\n",
      "Epoch 64/100\n",
      "Train Loss: 0.5246 Train Acc0.7828\n",
      "----------------------------------------\n",
      "Epoch 65/100\n",
      "Train Loss: 0.5242 Train Acc0.7817\n",
      "Val Auc: 0.8130, Val Score 1: 0.2450\n",
      "----------------------------------------\n",
      "Epoch 66/100\n",
      "Train Loss: 0.5257 Train Acc0.7786\n",
      "----------------------------------------\n",
      "Epoch 67/100\n",
      "Train Loss: 0.5266 Train Acc0.7797\n",
      "----------------------------------------\n",
      "Epoch 68/100\n",
      "Train Loss: 0.5248 Train Acc0.7817\n",
      "----------------------------------------\n",
      "Epoch 69/100\n",
      "Train Loss: 0.5244 Train Acc0.7836\n",
      "----------------------------------------\n",
      "Epoch 70/100\n",
      "Train Loss: 0.5254 Train Acc0.7807\n",
      "Val Auc: 0.8130, Val Score 1: 0.2569\n",
      "----------------------------------------\n",
      "Epoch 71/100\n",
      "Train Loss: 0.5228 Train Acc0.7834\n",
      "----------------------------------------\n",
      "Epoch 72/100\n",
      "Train Loss: 0.5235 Train Acc0.7820\n",
      "----------------------------------------\n",
      "Epoch 73/100\n",
      "Train Loss: 0.5229 Train Acc0.7828\n",
      "----------------------------------------\n",
      "Epoch 74/100\n",
      "Train Loss: 0.5226 Train Acc0.7826\n",
      "----------------------------------------\n",
      "Epoch 75/100\n",
      "Train Loss: 0.5222 Train Acc0.7813\n",
      "Val Auc: 0.8170, Val Score 1: 0.2662\n",
      "----------------------------------------\n",
      "Epoch 76/100\n",
      "Train Loss: 0.5217 Train Acc0.7820\n",
      "----------------------------------------\n",
      "Epoch 77/100\n",
      "Train Loss: 0.5213 Train Acc0.7850\n",
      "----------------------------------------\n",
      "Epoch 78/100\n",
      "Train Loss: 0.5209 Train Acc0.7842\n",
      "----------------------------------------\n",
      "Epoch 79/100\n",
      "Train Loss: 0.5243 Train Acc0.7791\n",
      "----------------------------------------\n",
      "Epoch 80/100\n",
      "Train Loss: 0.5207 Train Acc0.7844\n",
      "Val Auc: 0.8258, Val Score 1: 0.3186\n",
      "----------------------------------------\n",
      "Epoch 81/100\n",
      "Train Loss: 0.5206 Train Acc0.7841\n",
      "----------------------------------------\n",
      "Epoch 82/100\n",
      "Train Loss: 0.5182 Train Acc0.7870\n",
      "----------------------------------------\n",
      "Epoch 83/100\n",
      "Train Loss: 0.5198 Train Acc0.7850\n",
      "----------------------------------------\n",
      "Epoch 84/100\n",
      "Train Loss: 0.5192 Train Acc0.7862\n",
      "----------------------------------------\n",
      "Epoch 85/100\n",
      "Train Loss: 0.5189 Train Acc0.7862\n",
      "Val Auc: 0.8208, Val Score 1: 0.2603\n",
      "----------------------------------------\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5178 Train Acc0.7880\n",
      "----------------------------------------\n",
      "Epoch 87/100\n",
      "Train Loss: 0.5179 Train Acc0.7897\n",
      "----------------------------------------\n",
      "Epoch 88/100\n",
      "Train Loss: 0.5200 Train Acc0.7860\n",
      "----------------------------------------\n",
      "Epoch 89/100\n",
      "Train Loss: 0.5166 Train Acc0.7909\n",
      "----------------------------------------\n",
      "Epoch 90/100\n",
      "Train Loss: 0.5174 Train Acc0.7899\n",
      "Val Auc: 0.8305, Val Score 1: 0.3617\n",
      "----------------------------------------\n",
      "Epoch 91/100\n",
      "Train Loss: 0.5178 Train Acc0.7894\n",
      "----------------------------------------\n",
      "Epoch 92/100\n",
      "Train Loss: 0.5168 Train Acc0.7894\n",
      "----------------------------------------\n",
      "Epoch 93/100\n",
      "Train Loss: 0.5181 Train Acc0.7889\n",
      "----------------------------------------\n",
      "Epoch 94/100\n",
      "Train Loss: 0.5154 Train Acc0.7925\n",
      "----------------------------------------\n",
      "Epoch 95/100\n",
      "Train Loss: 0.5160 Train Acc0.7909\n",
      "Val Auc: 0.8247, Val Score 1: 0.2624\n",
      "----------------------------------------\n",
      "Epoch 96/100\n",
      "Train Loss: 0.5140 Train Acc0.7947\n",
      "----------------------------------------\n",
      "Epoch 97/100\n",
      "Train Loss: 0.5163 Train Acc0.7912\n",
      "----------------------------------------\n",
      "Epoch 98/100\n",
      "Train Loss: 0.5145 Train Acc0.7925\n",
      "----------------------------------------\n",
      "Epoch 99/100\n",
      "Train Loss: 0.5154 Train Acc0.7901\n",
      "----------------------------------------\n",
      "Epoch 100/100\n",
      "Train Loss: 0.5133 Train Acc0.7949\n",
      "Val Auc: 0.8289, Val Score 1: 0.2846\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUIModel(num_inputs=X_train.shape[2], num_hiddens=64, num_outputs=1, imputeMethod='Last', scaleMethod='Norm', resampleMethod='RandomBalance').to(device)\n",
    "model = train_grui_model(model, X_resampled, y_resampled, delta_resampled, X_val, Y_val, val_delta, batch_size=32, lr=0.1, num_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa0116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
